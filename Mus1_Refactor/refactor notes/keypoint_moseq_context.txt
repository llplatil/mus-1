--- File: LICENSE.md ---
# Non-Commercial Research and Academic Use Software License and Terms of Use


Keypoint-MoSeq is a software package that includes original code created by the Harvard researchers listed below (the “Software”), and third-party code that may be obtained by End Users separately. The Software is designed to label behaviors identified from keypoint tracking data through the use of computational modeling and fitting approaches. The Software was developed by Caleb Weinreb, Ph.D. and Sandeep Robert Datta, Ph.D. at Harvard University. It is distributed for free academic and non-commercial research use by the President and Fellows of Harvard College (“Harvard”).

Using the Software indicates your agreement to be bound by the terms of this Software Use Agreement (“Agreement”). Absent your agreement to the terms below, you (the “End User”) have no rights to hold or use the Software whatsoever.

Harvard agrees to grant hereunder a limited non-exclusive license to End User for the use of the Software in the performance of End User’s internal, non-commercial research and academic use at End User’s academic or not-for-profit research institution (“Institution”) on the following terms and conditions:

1. **NO COMMERCIAL USE.** End User shall not use the Software for Commercial use and any such use of the Software is expressly prohibited. “Commercial use” includes, but is not limited to, (i) use of the Software in fee-for-service arrangements, (ii) use of the Software by core facilities or laboratories to provide research services to (or in collaboration with) for-profit third parties for a fee, and (iii) use of the Software in industry-sponsored and/or collaborative research projects in which any commercial rights are granted to the sponsor or collaborator. If End User wishes to use the Software for Commercial use, End User must execute a separate license agreement with Harvard.

_Requests for use of the Software for Commercial use, please contact:_

Office of Technology Development
Harvard University
Smith Campus Center, Suite 727E
1350 Massachusetts Avenue Cambridge, MA 02138 USA Telephone: (617) 495-3067
Facsimile: (617) 495-9568
E-mail: otd@harvard.edu

2. **OWNERSHIP AND COPYRIGHT NOTICE.** Harvard owns all intellectual property in the Software. End User shall gain no ownership to the Software.  End User shall not remove or delete, and shall retain in the Software (including in any modifications to the Software and in any Derivative Works), the copyright, trademark, or other notices pertaining to Software as provided with the Software.

3. **DERIVATIVE WORKS.** End User may create use and distribute Derivative Works, as such term is defined under U.S. copyright laws, provided that any such Derivative Works shall be restricted to non-commercial research and academic use. End User may not distribute Derivative Works to any for-profit third parties for Commercial use.

4. **FEEDBACK.** In order to improve the Software, comments from End Users may be useful. If End User provides Harvard with feedback on the End User’s use of the Software (e.g., any bugs in the Software, the user experience, etc.),  Harvard is permitted to use such information provided by End User in making changes and improvements to the Software without compensation or accounting to End User.

5. **NON ASSERT.** End User acknowledges that Harvard may develop modifications to the Software that may be based on the feedback provided by End User under Section 5 above. Harvard shall not be restricted in any way by End User regarding its use of such information.  End User acknowledges the right of Harvard to prepare, publish, display, reproduce, transmit and or use modifications to the Software that may be substantially similar or functionally equivalent to End User’s modifications and/or improvements if any.  In the event that End User obtains patent protection for any modification or improvement to Software, End User agrees not to allege or enjoin infringement of End User’s patent against Harvard, or any of the researchers, medical or research staff, officers, directors and employees of those institutions.

6. **PUBLICATION & ATTRIBUTION.** End User has the right to publish, present, or share results from the use of the Software.  In accordance with customary academic practice, End User will acknowledge Harvard as the provider of the Software and may cite the relevant reference(s) from the following list of publications:

Wiltschko AB, Johnson MJ, Iurilli G, Peterson RE, Katon JE, Pashkovski SL, Abraira VE, Adams RP and Datta SR. (2015). Mapping sub-second Structure in Behavior. Neuron, 88:1121.

Weinreb, C., Pearl, J.E., Lin, S. et al. Keypoint-MoSeq: parsing behavior by linking point tracking to pose dynamics. Nat Methods 21, 1329–1339 (2024). https://doi.org/10.1038/s41592-024-02318-2

7.** NO WARRANTIES.** THE SOFTWARE IS PROVIDED "AS IS." TO THE FULLEST EXTENT PERMITTED BY LAW, HARVARD HEREBY DISCLAIMS ALL WARRANTIES OF ANY KIND (EXPRESS, IMPLIED OR OTHERWISE) REGARDING THE SOFTWARE, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OWNERSHIP, AND NON-INFRINGEMENT.  HARVARD MAKES NO WARRANTY ABOUT THE ACCURACY, RELIABILITY, COMPLETENESS, TIMELINESS, SUFFICIENCY OR QUALITY OF THE SOFTWARE.  HARVARD DOES NOT WARRANT THAT THE SOFTWARE WILL OPERATE WITHOUT ERROR OR INTERRUPTION.

8. **LIMITATIONS OF LIABILITY AND REMEDIES.** USE OF THE SOFTWARE IS AT END USER’S OWN RISK. IF END USER IS DISSATISFIED WITH THE SOFTWARE, ITS EXCLUSIVE REMEDY IS TO STOP USING IT.  IN NO EVENT SHALL HARVARD BE LIABLE TO END USER OR ITS INSTITUTION, IN CONTRACT, TORT OR OTHERWISE, FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR OTHER DAMAGES OF ANY KIND WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE SOFTWARE, EVEN IF HARVARD IS NEGLIGENT OR OTHERWISE AT FAULT, AND REGARDLESS OF WHETHER HARVARD IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.

9. **INDEMNIFICATION.** To the extent permitted by law, End User shall indemnify, defend and hold harmless Harvard, their corporate affiliates, current or future directors, trustees, officers, faculty, medical and professional staff, employees, students and agents and their respective successors, heirs and assigns (the "Indemnitees"), against any liability, damage, loss or expense (including reasonable attorney's fees and expenses of litigation) incurred by or imposed upon the Indemnitees or any one of them in connection with any claims, suits, actions, demands or judgments arising from End User’s breach of this Agreement or its Institution’s use of the Software except to the extent caused by the gross negligence or willful misconduct of Harvard. This indemnification provision shall survive expiration or termination of this Agreement.

10. **GOVERNING LAW.** This Agreement shall be construed and governed by the laws of the Commonwealth of Massachusetts regardless of otherwise applicable choice of law standards.

11. **NON-USE OF NAME.**  Nothing in this License and Terms of Use shall be construed as granting End Users or their Institutions any rights or licenses to use any trademarks, service marks or logos associated with the Software.  End User may not use the terms “Harvard” (or a substantially similar term) in any way that is inconsistent with the permitted uses described herein. End Users may not use any name or emblem of Harvard or any of its schools or subdivisions for any purpose, or to falsely suggest any relationship between End User (or its Institution) and Harvard, or in any manner that would infringe or violate any of its rights.

12. End User represents and warrants that it has the legal authority to enter into this License and Terms of Use on behalf of itself and its Institution.

                                                                  ***      




--- File: .readthedocs.yml ---
# .readthedocs.yml
# Read the Docs configuration file
# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details

# Required
version: 2

# Build documentation in the docs/ directory with Sphinx
sphinx:
  configuration: docs/source/conf.py

# Optionally set the version of Python and requirements required to build your docs
build:
  os: ubuntu-22.04
  tools:
    python: "3.10"

python:
  install:
    - requirements: docs/requirements.txt
    - method: pip
      path: .

--- File: README.md ---
# Keypoint MoSeq 

![logo](docs/source/_static/logo.jpg)

Motion Sequencing (MoSeq) is an unsupervised machine learning method for animal behavior analysis. Given behavioral recordings, MoSeq learns a set of stereotyped movement patterns and when they occur over time. This package provides tools for fitting a MoSeq model to keypoint tracking data [(Weinreb et al., 2023)](https://www.biorxiv.org/content/10.1101/2023.03.16.532307v1). 

## [Documentation](https://keypoint-moseq.readthedocs.io/en/latest/)

- [Colab](https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb)

- [Installation](https://keypoint-moseq.readthedocs.io/en/latest/install.html)

- [Modeling Tutorial](https://keypoint-moseq.readthedocs.io/en/latest/modeling.html)

- [Keypoint-MoSeq paper](https://www.nature.com/articles/s41592-024-02318-2)

- [Slack workspace](https://join.slack.com/t/moseqworkspace/shared_invite/zt-151x0shoi-z4J0_g_5rwJDlO1IfCU34A)

- [MoSeq homepage](https://dattalab.github.io/moseq2-website/index.html)


# License
MoSeq is freely available for academic use under a license provided by Harvard University. Please refer to the license file for details. If you are interested in using MoSeq for commercial purposes please contact Bob Datta directly at srdatta@hms.harvard.edu, who will put you in touch with the appropriate people in the Harvard Technology Transfer office.



--- File: setup.py ---
import setuptools
import versioneer

with open("README.md", "r", encoding="utf-8") as f:
    long_description = f.read()

setuptools.setup(
    name="keypoint-moseq",
    version=versioneer.get_version(),
    cmdclass=versioneer.get_cmdclass(),
)


--- File: .gitignore ---
**/.DS_Store
testing
update_pypi.sh

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# PEP 582; used by e.g. github.com/David-OConnor/pyflow
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/
.DS_Store
*.DS_Store
*.vscode/*

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/


--- File: .gitattributes ---
keypoint_moseq/_version.py export-subst


--- File: setup.cfg ---
[metadata]
name = keypoint-moseq
author = Caleb Weinreb
author_email = calebsw@gmail.com
url = https://github.com/dattalab/keypoint-moseq
classifiers =
    Programming Language :: Python :: 3
    Operating System :: OS Independent

[options]
packages = find:
include_package_data = True
python_requires = >=3.10
install_requires =
    seaborn==0.13.0
    cytoolz
    matplotlib==3.8.4
    tqdm
    ipykernel
    imageio[ffmpeg]
    statsmodels
    pyyaml
    vidio
    holoviews[recommended]
    bokeh
    pandas
    tables
    bokeh==2.4.3
    panel==0.14.4
    holoviews==1.15.4
    networkx
    sleap_io
    pynwb
    ndx_pose
    plotly
    ipython_genutils
    tabulate
    commentjson
    jax-moseq
    numpy<=1.26.4

[options.extras_require]
dev = 
    sphinx
    sphinx-rtd-theme
    autodocsumm
    myst-nb

cuda = 
    jax-moseq[cuda]

[options.package_data]
* = *.md

[versioneer]
VCS = git
style = pep440
versionfile_source = keypoint_moseq/_version.py
versionfile_build = keypoint_moseq/_version.py
tag_prefix =
parentdir_prefix = 

--- File: versioneer.py ---
# Version: 0.28
"""The Versioneer - like a rocketeer, but for versions.

The Versioneer
==============

* like a rocketeer, but for versions!
* https://github.com/python-versioneer/python-versioneer
* Brian Warner
* License: Public Domain (Unlicense)
* Compatible with: Python 3.7, 3.8, 3.9, 3.10 and pypy3
* [![Latest Version][pypi-image]][pypi-url]
* [![Build Status][travis-image]][travis-url]

This is a tool for managing a recorded version number in setuptools-based
python projects. The goal is to remove the tedious and error-prone "update
the embedded version string" step from your release process. Making a new
release should be as easy as recording a new tag in your version-control
system, and maybe making new tarballs.


## Quick Install

Versioneer provides two installation modes. The "classic" vendored mode installs
a copy of versioneer into your repository. The experimental build-time dependency mode
is intended to allow you to skip this step and simplify the process of upgrading.

### Vendored mode

* `pip install versioneer` to somewhere in your $PATH
   * A [conda-forge recipe](https://github.com/conda-forge/versioneer-feedstock) is
     available, so you can also use `conda install -c conda-forge versioneer`
* add a `[tool.versioneer]` section to your `pyproject.toml` or a
  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))
   * Note that you will need to add `tomli; python_version < "3.11"` to your
     build-time dependencies if you use `pyproject.toml`
* run `versioneer install --vendor` in your source tree, commit the results
* verify version information with `python setup.py version`

### Build-time dependency mode

* `pip install versioneer` to somewhere in your $PATH
   * A [conda-forge recipe](https://github.com/conda-forge/versioneer-feedstock) is
     available, so you can also use `conda install -c conda-forge versioneer`
* add a `[tool.versioneer]` section to your `pyproject.toml` or a
  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))
* add `versioneer` (with `[toml]` extra, if configuring in `pyproject.toml`)
  to the `requires` key of the `build-system` table in `pyproject.toml`:
  ```toml
  [build-system]
  requires = ["setuptools", "versioneer[toml]"]
  build-backend = "setuptools.build_meta"
  ```
* run `versioneer install --no-vendor` in your source tree, commit the results
* verify version information with `python setup.py version`

## Version Identifiers

Source trees come from a variety of places:

* a version-control system checkout (mostly used by developers)
* a nightly tarball, produced by build automation
* a snapshot tarball, produced by a web-based VCS browser, like github's
  "tarball from tag" feature
* a release tarball, produced by "setup.py sdist", distributed through PyPI

Within each source tree, the version identifier (either a string or a number,
this tool is format-agnostic) can come from a variety of places:

* ask the VCS tool itself, e.g. "git describe" (for checkouts), which knows
  about recent "tags" and an absolute revision-id
* the name of the directory into which the tarball was unpacked
* an expanded VCS keyword ($Id$, etc)
* a `_version.py` created by some earlier build step

For released software, the version identifier is closely related to a VCS
tag. Some projects use tag names that include more than just the version
string (e.g. "myproject-1.2" instead of just "1.2"), in which case the tool
needs to strip the tag prefix to extract the version identifier. For
unreleased software (between tags), the version identifier should provide
enough information to help developers recreate the same tree, while also
giving them an idea of roughly how old the tree is (after version 1.2, before
version 1.3). Many VCS systems can report a description that captures this,
for example `git describe --tags --dirty --always` reports things like
"0.7-1-g574ab98-dirty" to indicate that the checkout is one revision past the
0.7 tag, has a unique revision id of "574ab98", and is "dirty" (it has
uncommitted changes).

The version identifier is used for multiple purposes:

* to allow the module to self-identify its version: `myproject.__version__`
* to choose a name and prefix for a 'setup.py sdist' tarball

## Theory of Operation

Versioneer works by adding a special `_version.py` file into your source
tree, where your `__init__.py` can import it. This `_version.py` knows how to
dynamically ask the VCS tool for version information at import time.

`_version.py` also contains `$Revision$` markers, and the installation
process marks `_version.py` to have this marker rewritten with a tag name
during the `git archive` command. As a result, generated tarballs will
contain enough information to get the proper version.

To allow `setup.py` to compute a version too, a `versioneer.py` is added to
the top level of your source tree, next to `setup.py` and the `setup.cfg`
that configures it. This overrides several distutils/setuptools commands to
compute the version when invoked, and changes `setup.py build` and `setup.py
sdist` to replace `_version.py` with a small static file that contains just
the generated version data.

## Installation

See [INSTALL.md](./INSTALL.md) for detailed installation instructions.

## Version-String Flavors

Code which uses Versioneer can learn about its version string at runtime by
importing `_version` from your main `__init__.py` file and running the
`get_versions()` function. From the "outside" (e.g. in `setup.py`), you can
import the top-level `versioneer.py` and run `get_versions()`.

Both functions return a dictionary with different flavors of version
information:

* `['version']`: A condensed version string, rendered using the selected
  style. This is the most commonly used value for the project's version
  string. The default "pep440" style yields strings like `0.11`,
  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the "Styles" section
  below for alternative styles.

* `['full-revisionid']`: detailed revision identifier. For Git, this is the
  full SHA1 commit id, e.g. "1076c978a8d3cfc70f408fe5974aa6c092c949ac".

* `['date']`: Date and time of the latest `HEAD` commit. For Git, it is the
  commit date in ISO 8601 format. This will be None if the date is not
  available.

* `['dirty']`: a boolean, True if the tree has uncommitted changes. Note that
  this is only accurate if run in a VCS checkout, otherwise it is likely to
  be False or None

* `['error']`: if the version string could not be computed, this will be set
  to a string describing the problem, otherwise it will be None. It may be
  useful to throw an exception in setup.py if this is set, to avoid e.g.
  creating tarballs with a version string of "unknown".

Some variants are more useful than others. Including `full-revisionid` in a
bug report should allow developers to reconstruct the exact code being tested
(or indicate the presence of local changes that should be shared with the
developers). `version` is suitable for display in an "about" box or a CLI
`--version` output: it can be easily compared against release notes and lists
of bugs fixed in various releases.

The installer adds the following text to your `__init__.py` to place a basic
version in `YOURPROJECT.__version__`:

    from ._version import get_versions
    __version__ = get_versions()['version']
    del get_versions

## Styles

The setup.cfg `style=` configuration controls how the VCS information is
rendered into a version string.

The default style, "pep440", produces a PEP440-compliant string, equal to the
un-prefixed tag name for actual releases, and containing an additional "local
version" section with more detail for in-between builds. For Git, this is
TAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags
--dirty --always`. For example "0.11+2.g1076c97.dirty" indicates that the
tree is like the "1076c97" commit but has uncommitted changes (".dirty"), and
that this commit is two revisions ("+2") beyond the "0.11" tag. For released
software (exactly equal to a known tag), the identifier will only contain the
stripped tag, e.g. "0.11".

Other styles are available. See [details.md](details.md) in the Versioneer
source tree for descriptions.

## Debugging

Versioneer tries to avoid fatal errors: if something goes wrong, it will tend
to return a version of "0+unknown". To investigate the problem, run `setup.py
version`, which will run the version-lookup code in a verbose mode, and will
display the full contents of `get_versions()` (including the `error` string,
which may help identify what went wrong).

## Known Limitations

Some situations are known to cause problems for Versioneer. This details the
most significant ones. More can be found on Github
[issues page](https://github.com/python-versioneer/python-versioneer/issues).

### Subprojects

Versioneer has limited support for source trees in which `setup.py` is not in
the root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are
two common reasons why `setup.py` might not be in the root:

* Source trees which contain multiple subprojects, such as
  [Buildbot](https://github.com/buildbot/buildbot), which contains both
  "master" and "slave" subprojects, each with their own `setup.py`,
  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI
  distributions (and upload multiple independently-installable tarballs).
* Source trees whose main purpose is to contain a C library, but which also
  provide bindings to Python (and perhaps other languages) in subdirectories.

Versioneer will look for `.git` in parent directories, and most operations
should get the right version string. However `pip` and `setuptools` have bugs
and implementation details which frequently cause `pip install .` from a
subproject directory to fail to find a correct version string (so it usually
defaults to `0+unknown`).

`pip install --editable .` should work correctly. `setup.py install` might
work too.

Pip-8.1.1 is known to have this problem, but hopefully it will get fixed in
some later version.

[Bug #38](https://github.com/python-versioneer/python-versioneer/issues/38) is tracking
this issue. The discussion in
[PR #61](https://github.com/python-versioneer/python-versioneer/pull/61) describes the
issue from the Versioneer side in more detail.
[pip PR#3176](https://github.com/pypa/pip/pull/3176) and
[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve
pip to let Versioneer work correctly.

Versioneer-0.16 and earlier only looked for a `.git` directory next to the
`setup.cfg`, so subprojects were completely unsupported with those releases.

### Editable installs with setuptools <= 18.5

`setup.py develop` and `pip install --editable .` allow you to install a
project into a virtualenv once, then continue editing the source code (and
test) without re-installing after every change.

"Entry-point scripts" (`setup(entry_points={"console_scripts": ..})`) are a
convenient way to specify executable scripts that should be installed along
with the python package.

These both work as expected when using modern setuptools. When using
setuptools-18.5 or earlier, however, certain operations will cause
`pkg_resources.DistributionNotFound` errors when running the entrypoint
script, which must be resolved by re-installing the package. This happens
when the install happens with one version, then the egg_info data is
regenerated while a different version is checked out. Many setup.py commands
cause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into
a different virtualenv), so this can be surprising.

[Bug #83](https://github.com/python-versioneer/python-versioneer/issues/83) describes
this one, but upgrading to a newer version of setuptools should probably
resolve it.


## Updating Versioneer

To upgrade your project to a new release of Versioneer, do the following:

* install the new Versioneer (`pip install -U versioneer` or equivalent)
* edit `setup.cfg` and `pyproject.toml`, if necessary,
  to include any new configuration settings indicated by the release notes.
  See [UPGRADING](./UPGRADING.md) for details.
* re-run `versioneer install --[no-]vendor` in your source tree, to replace
  `SRC/_version.py`
* commit any changed files

## Future Directions

This tool is designed to make it easily extended to other version-control
systems: all VCS-specific components are in separate directories like
src/git/ . The top-level `versioneer.py` script is assembled from these
components by running make-versioneer.py . In the future, make-versioneer.py
will take a VCS name as an argument, and will construct a version of
`versioneer.py` that is specific to the given VCS. It might also take the
configuration arguments that are currently provided manually during
installation by editing setup.py . Alternatively, it might go the other
direction and include code from all supported VCS systems, reducing the
number of intermediate scripts.

## Similar projects

* [setuptools_scm](https://github.com/pypa/setuptools_scm/) - a non-vendored build-time
  dependency
* [minver](https://github.com/jbweston/miniver) - a lightweight reimplementation of
  versioneer
* [versioningit](https://github.com/jwodder/versioningit) - a PEP 518-based setuptools
  plugin

## License

To make Versioneer easier to embed, all its code is dedicated to the public
domain. The `_version.py` that it creates is also in the public domain.
Specifically, both are released under the "Unlicense", as described in
https://unlicense.org/.

[pypi-image]: https://img.shields.io/pypi/v/versioneer.svg
[pypi-url]: https://pypi.python.org/pypi/versioneer/
[travis-image]:
https://img.shields.io/travis/com/python-versioneer/python-versioneer.svg
[travis-url]: https://travis-ci.com/github/python-versioneer/python-versioneer

"""
# pylint:disable=invalid-name,import-outside-toplevel,missing-function-docstring
# pylint:disable=missing-class-docstring,too-many-branches,too-many-statements
# pylint:disable=raise-missing-from,too-many-lines,too-many-locals,import-error
# pylint:disable=too-few-public-methods,redefined-outer-name,consider-using-with
# pylint:disable=attribute-defined-outside-init,too-many-arguments

import configparser
import errno
import json
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import Callable, Dict
import functools

have_tomllib = True
if sys.version_info >= (3, 11):
    import tomllib
else:
    try:
        import tomli as tomllib
    except ImportError:
        have_tomllib = False


class VersioneerConfig:
    """Container for Versioneer configuration parameters."""


def get_root():
    """Get the project root directory.

    We require that all commands are run from the project root, i.e. the
    directory that contains setup.py, setup.cfg, and versioneer.py .
    """
    root = os.path.realpath(os.path.abspath(os.getcwd()))
    setup_py = os.path.join(root, "setup.py")
    versioneer_py = os.path.join(root, "versioneer.py")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        # allow 'python path/to/setup.py COMMAND'
        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))
        setup_py = os.path.join(root, "setup.py")
        versioneer_py = os.path.join(root, "versioneer.py")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        err = (
            "Versioneer was unable to run the project root directory. "
            "Versioneer requires setup.py to be executed from "
            "its immediate directory (like 'python setup.py COMMAND'), "
            "or in a way that lets it use sys.argv[0] to find the root "
            "(like 'python path/to/setup.py COMMAND')."
        )
        raise VersioneerBadRootError(err)
    try:
        # Certain runtime workflows (setup.py install/develop in a setuptools
        # tree) execute all dependencies in a single python process, so
        # "versioneer" may be imported multiple times, and python's shared
        # module-import table will cache the first one. So we can't use
        # os.path.dirname(__file__), as that will find whichever
        # versioneer.py was first imported, even in later projects.
        my_path = os.path.realpath(os.path.abspath(__file__))
        me_dir = os.path.normcase(os.path.splitext(my_path)[0])
        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])
        if me_dir != vsr_dir and "VERSIONEER_PEP518" not in globals():
            print(
                "Warning: build in %s is using versioneer.py from %s"
                % (os.path.dirname(my_path), versioneer_py)
            )
    except NameError:
        pass
    return root


def get_config_from_root(root):
    """Read the project setup.cfg file to determine Versioneer config."""
    # This might raise OSError (if setup.cfg is missing), or
    # configparser.NoSectionError (if it lacks a [versioneer] section), or
    # configparser.NoOptionError (if it lacks "VCS="). See the docstring at
    # the top of versioneer.py for instructions on writing your setup.cfg .
    root = Path(root)
    pyproject_toml = root / "pyproject.toml"
    setup_cfg = root / "setup.cfg"
    section = None
    if pyproject_toml.exists() and have_tomllib:
        try:
            with open(pyproject_toml, "rb") as fobj:
                pp = tomllib.load(fobj)
            section = pp["tool"]["versioneer"]
        except (tomllib.TOMLDecodeError, KeyError):
            pass
    if not section:
        parser = configparser.ConfigParser()
        with open(setup_cfg) as cfg_file:
            parser.read_file(cfg_file)
        parser.get("versioneer", "VCS")  # raise error if missing

        section = parser["versioneer"]

    cfg = VersioneerConfig()
    cfg.VCS = section["VCS"]
    cfg.style = section.get("style", "")
    cfg.versionfile_source = section.get("versionfile_source")
    cfg.versionfile_build = section.get("versionfile_build")
    cfg.tag_prefix = section.get("tag_prefix")
    if cfg.tag_prefix in ("''", '""', None):
        cfg.tag_prefix = ""
    cfg.parentdir_prefix = section.get("parentdir_prefix")
    cfg.verbose = section.get("verbose")
    return cfg


class NotThisMethod(Exception):
    """Exception raised if a method is not valid for the current scenario."""


# these dictionaries contain VCS-specific tools
LONG_VERSION_PY: Dict[str, str] = {}
HANDLERS: Dict[str, Dict[str, Callable]] = {}


def register_vcs_handler(vcs, method):  # decorator
    """Create decorator to mark a method as the handler of a VCS."""

    def decorate(f):
        """Store f in HANDLERS[vcs][method]."""
        HANDLERS.setdefault(vcs, {})[method] = f
        return f

    return decorate


def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):
    """Call the given command(s)."""
    assert isinstance(commands, list)
    process = None

    popen_kwargs = {}
    if sys.platform == "win32":
        # This hides the console window if pythonw.exe is used
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        popen_kwargs["startupinfo"] = startupinfo

    for command in commands:
        try:
            dispcmd = str([command] + args)
            # remember shell=False, so use git.cmd on windows, not just git
            process = subprocess.Popen(
                [command] + args,
                cwd=cwd,
                env=env,
                stdout=subprocess.PIPE,
                stderr=(subprocess.PIPE if hide_stderr else None),
                **popen_kwargs,
            )
            break
        except OSError:
            e = sys.exc_info()[1]
            if e.errno == errno.ENOENT:
                continue
            if verbose:
                print("unable to run %s" % dispcmd)
                print(e)
            return None, None
    else:
        if verbose:
            print("unable to find command, tried %s" % (commands,))
        return None, None
    stdout = process.communicate()[0].strip().decode()
    if process.returncode != 0:
        if verbose:
            print("unable to run %s (error)" % dispcmd)
            print("stdout was %s" % stdout)
        return None, process.returncode
    return stdout, process.returncode


LONG_VERSION_PY[
    "git"
] = r'''
# This file helps to compute a version number in source trees obtained from
# git-archive tarball (such as those provided by githubs download-from-tag
# feature). Distribution tarballs (built by setup.py sdist) and build
# directories (produced by setup.py build) will contain a much shorter file
# that just contains the computed version number.

# This file is released into the public domain.
# Generated by versioneer-0.28
# https://github.com/python-versioneer/python-versioneer

"""Git implementation of _version.py."""

import errno
import os
import re
import subprocess
import sys
from typing import Callable, Dict
import functools


def get_keywords():
    """Get the keywords needed to look up the version information."""
    # these strings will be replaced by git during git-archive.
    # setup.py/versioneer.py will grep for the variable names, so they must
    # each be defined on a line of their own. _version.py will just call
    # get_keywords().
    git_refnames = "%(DOLLAR)sFormat:%%d%(DOLLAR)s"
    git_full = "%(DOLLAR)sFormat:%%H%(DOLLAR)s"
    git_date = "%(DOLLAR)sFormat:%%ci%(DOLLAR)s"
    keywords = {"refnames": git_refnames, "full": git_full, "date": git_date}
    return keywords


class VersioneerConfig:
    """Container for Versioneer configuration parameters."""


def get_config():
    """Create, populate and return the VersioneerConfig() object."""
    # these strings are filled in when 'setup.py versioneer' creates
    # _version.py
    cfg = VersioneerConfig()
    cfg.VCS = "git"
    cfg.style = "%(STYLE)s"
    cfg.tag_prefix = "%(TAG_PREFIX)s"
    cfg.parentdir_prefix = "%(PARENTDIR_PREFIX)s"
    cfg.versionfile_source = "%(VERSIONFILE_SOURCE)s"
    cfg.verbose = False
    return cfg


class NotThisMethod(Exception):
    """Exception raised if a method is not valid for the current scenario."""


LONG_VERSION_PY: Dict[str, str] = {}
HANDLERS: Dict[str, Dict[str, Callable]] = {}


def register_vcs_handler(vcs, method):  # decorator
    """Create decorator to mark a method as the handler of a VCS."""
    def decorate(f):
        """Store f in HANDLERS[vcs][method]."""
        if vcs not in HANDLERS:
            HANDLERS[vcs] = {}
        HANDLERS[vcs][method] = f
        return f
    return decorate


def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,
                env=None):
    """Call the given command(s)."""
    assert isinstance(commands, list)
    process = None

    popen_kwargs = {}
    if sys.platform == "win32":
        # This hides the console window if pythonw.exe is used
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        popen_kwargs["startupinfo"] = startupinfo

    for command in commands:
        try:
            dispcmd = str([command] + args)
            # remember shell=False, so use git.cmd on windows, not just git
            process = subprocess.Popen([command] + args, cwd=cwd, env=env,
                                       stdout=subprocess.PIPE,
                                       stderr=(subprocess.PIPE if hide_stderr
                                               else None), **popen_kwargs)
            break
        except OSError:
            e = sys.exc_info()[1]
            if e.errno == errno.ENOENT:
                continue
            if verbose:
                print("unable to run %%s" %% dispcmd)
                print(e)
            return None, None
    else:
        if verbose:
            print("unable to find command, tried %%s" %% (commands,))
        return None, None
    stdout = process.communicate()[0].strip().decode()
    if process.returncode != 0:
        if verbose:
            print("unable to run %%s (error)" %% dispcmd)
            print("stdout was %%s" %% stdout)
        return None, process.returncode
    return stdout, process.returncode


def versions_from_parentdir(parentdir_prefix, root, verbose):
    """Try to determine the version from the parent directory name.

    Source tarballs conventionally unpack into a directory that includes both
    the project name and a version string. We will also support searching up
    two directory levels for an appropriately named parent directory
    """
    rootdirs = []

    for _ in range(3):
        dirname = os.path.basename(root)
        if dirname.startswith(parentdir_prefix):
            return {"version": dirname[len(parentdir_prefix):],
                    "full-revisionid": None,
                    "dirty": False, "error": None, "date": None}
        rootdirs.append(root)
        root = os.path.dirname(root)  # up a level

    if verbose:
        print("Tried directories %%s but none started with prefix %%s" %%
              (str(rootdirs), parentdir_prefix))
    raise NotThisMethod("rootdir doesn't start with parentdir_prefix")


@register_vcs_handler("git", "get_keywords")
def git_get_keywords(versionfile_abs):
    """Extract version information from the given file."""
    # the code embedded in _version.py can just fetch the value of these
    # keywords. When used from setup.py, we don't want to import _version.py,
    # so we do it with a regexp instead. This function is not used from
    # _version.py.
    keywords = {}
    try:
        with open(versionfile_abs, "r") as fobj:
            for line in fobj:
                if line.strip().startswith("git_refnames ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["refnames"] = mo.group(1)
                if line.strip().startswith("git_full ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["full"] = mo.group(1)
                if line.strip().startswith("git_date ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["date"] = mo.group(1)
    except OSError:
        pass
    return keywords


@register_vcs_handler("git", "keywords")
def git_versions_from_keywords(keywords, tag_prefix, verbose):
    """Get version information from git keywords."""
    if "refnames" not in keywords:
        raise NotThisMethod("Short version file found")
    date = keywords.get("date")
    if date is not None:
        # Use only the last line.  Previous lines may contain GPG signature
        # information.
        date = date.splitlines()[-1]

        # git-2.2.0 added "%%cI", which expands to an ISO-8601 -compliant
        # datestamp. However we prefer "%%ci" (which expands to an "ISO-8601
        # -like" string, which we must then edit to make compliant), because
        # it's been around since git-1.5.3, and it's too difficult to
        # discover which version we're using, or to work around using an
        # older one.
        date = date.strip().replace(" ", "T", 1).replace(" ", "", 1)
    refnames = keywords["refnames"].strip()
    if refnames.startswith("$Format"):
        if verbose:
            print("keywords are unexpanded, not using")
        raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
    refs = {r.strip() for r in refnames.strip("()").split(",")}
    # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
    # just "foo-1.0". If we see a "tag: " prefix, prefer those.
    TAG = "tag: "
    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %%d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like "release" and
        # "stabilization", as well as "HEAD" and "master".
        tags = {r for r in refs if re.search(r'\d', r)}
        if verbose:
            print("discarding '%%s', no digits" %% ",".join(refs - tags))
    if verbose:
        print("likely tags: %%s" %% ",".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. "2.0" over "2.0rc1"
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix):]
            # Filter out refs that exactly match prefix or that don't start
            # with a number once the prefix is stripped (mostly a concern
            # when prefix is '')
            if not re.match(r'\d', r):
                continue
            if verbose:
                print("picking %%s" %% r)
            return {"version": r,
                    "full-revisionid": keywords["full"].strip(),
                    "dirty": False, "error": None,
                    "date": date}
    # no suitable tags, so version is "0+unknown", but full hex is still there
    if verbose:
        print("no suitable tags, using unknown + full revision id")
    return {"version": "0+unknown",
            "full-revisionid": keywords["full"].strip(),
            "dirty": False, "error": "no suitable tags", "date": None}


@register_vcs_handler("git", "pieces_from_vcs")
def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):
    """Get version from 'git describe' in the root of the source tree.

    This only gets called if the git-archive 'subst' keywords were *not*
    expanded, and _version.py hasn't already been rewritten with a short
    version string, meaning we're inside a checked out source tree.
    """
    GITS = ["git"]
    if sys.platform == "win32":
        GITS = ["git.cmd", "git.exe"]

    # GIT_DIR can interfere with correct operation of Versioneer.
    # It may be intended to be passed to the Versioneer-versioned project,
    # but that should not change where we get our version from.
    env = os.environ.copy()
    env.pop("GIT_DIR", None)
    runner = functools.partial(runner, env=env)

    _, rc = runner(GITS, ["rev-parse", "--git-dir"], cwd=root,
                   hide_stderr=not verbose)
    if rc != 0:
        if verbose:
            print("Directory %%s not under git control" %% root)
        raise NotThisMethod("'git rev-parse --git-dir' returned error")

    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]
    # if there isn't one, this yields HEX[-dirty] (no NUM)
    describe_out, rc = runner(GITS, [
        "describe", "--tags", "--dirty", "--always", "--long",
        "--match", f"{tag_prefix}[[:digit:]]*"
    ], cwd=root)
    # --long was added in git-1.5.5
    if describe_out is None:
        raise NotThisMethod("'git describe' failed")
    describe_out = describe_out.strip()
    full_out, rc = runner(GITS, ["rev-parse", "HEAD"], cwd=root)
    if full_out is None:
        raise NotThisMethod("'git rev-parse' failed")
    full_out = full_out.strip()

    pieces = {}
    pieces["long"] = full_out
    pieces["short"] = full_out[:7]  # maybe improved later
    pieces["error"] = None

    branch_name, rc = runner(GITS, ["rev-parse", "--abbrev-ref", "HEAD"],
                             cwd=root)
    # --abbrev-ref was added in git-1.6.3
    if rc != 0 or branch_name is None:
        raise NotThisMethod("'git rev-parse --abbrev-ref' returned error")
    branch_name = branch_name.strip()

    if branch_name == "HEAD":
        # If we aren't exactly on a branch, pick a branch which represents
        # the current commit. If all else fails, we are on a branchless
        # commit.
        branches, rc = runner(GITS, ["branch", "--contains"], cwd=root)
        # --contains was added in git-1.5.4
        if rc != 0 or branches is None:
            raise NotThisMethod("'git branch --contains' returned error")
        branches = branches.split("\n")

        # Remove the first line if we're running detached
        if "(" in branches[0]:
            branches.pop(0)

        # Strip off the leading "* " from the list of branches.
        branches = [branch[2:] for branch in branches]
        if "master" in branches:
            branch_name = "master"
        elif not branches:
            branch_name = None
        else:
            # Pick the first branch that is returned. Good or bad.
            branch_name = branches[0]

    pieces["branch"] = branch_name

    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]
    # TAG might have hyphens.
    git_describe = describe_out

    # look for -dirty suffix
    dirty = git_describe.endswith("-dirty")
    pieces["dirty"] = dirty
    if dirty:
        git_describe = git_describe[:git_describe.rindex("-dirty")]

    # now we have TAG-NUM-gHEX or HEX

    if "-" in git_describe:
        # TAG-NUM-gHEX
        mo = re.search(r'^(.+)-(\d+)-g([0-9a-f]+)$', git_describe)
        if not mo:
            # unparsable. Maybe git-describe is misbehaving?
            pieces["error"] = ("unable to parse git-describe output: '%%s'"
                               %% describe_out)
            return pieces

        # tag
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = "tag '%%s' doesn't start with prefix '%%s'"
                print(fmt %% (full_tag, tag_prefix))
            pieces["error"] = ("tag '%%s' doesn't start with prefix '%%s'"
                               %% (full_tag, tag_prefix))
            return pieces
        pieces["closest-tag"] = full_tag[len(tag_prefix):]

        # distance: number of commits since tag
        pieces["distance"] = int(mo.group(2))

        # commit: short hex revision ID
        pieces["short"] = mo.group(3)

    else:
        # HEX: no tags
        pieces["closest-tag"] = None
        out, rc = runner(GITS, ["rev-list", "HEAD", "--left-right"], cwd=root)
        pieces["distance"] = len(out.split())  # total number of commits

    # commit date: see ISO-8601 comment in git_versions_from_keywords()
    date = runner(GITS, ["show", "-s", "--format=%%ci", "HEAD"], cwd=root)[0].strip()
    # Use only the last line.  Previous lines may contain GPG signature
    # information.
    date = date.splitlines()[-1]
    pieces["date"] = date.strip().replace(" ", "T", 1).replace(" ", "", 1)

    return pieces


def plus_or_dot(pieces):
    """Return a + if we don't already have one, else return a ."""
    if "+" in pieces.get("closest-tag", ""):
        return "."
    return "+"


def render_pep440(pieces):
    """Build up version string, with post-release "local version identifier".

    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you
    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty

    Exceptions:
    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += plus_or_dot(pieces)
            rendered += "%%d.g%%s" %% (pieces["distance"], pieces["short"])
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0+untagged.%%d.g%%s" %% (pieces["distance"],
                                          pieces["short"])
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def render_pep440_branch(pieces):
    """TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .

    The ".dev0" means not master branch. Note that .dev0 sorts backwards
    (a feature branch will appear "older" than the master branch).

    Exceptions:
    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            if pieces["branch"] != "master":
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "%%d.g%%s" %% (pieces["distance"], pieces["short"])
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0"
        if pieces["branch"] != "master":
            rendered += ".dev0"
        rendered += "+untagged.%%d.g%%s" %% (pieces["distance"],
                                          pieces["short"])
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def pep440_split_post(ver):
    """Split pep440 version string at the post-release segment.

    Returns the release segments before the post-release and the
    post-release version number (or -1 if no post-release segment is present).
    """
    vc = str.split(ver, ".post")
    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None


def render_pep440_pre(pieces):
    """TAG[.postN.devDISTANCE] -- No -dirty.

    Exceptions:
    1: no tags. 0.post0.devDISTANCE
    """
    if pieces["closest-tag"]:
        if pieces["distance"]:
            # update the post release segment
            tag_version, post_version = pep440_split_post(pieces["closest-tag"])
            rendered = tag_version
            if post_version is not None:
                rendered += ".post%%d.dev%%d" %% (post_version + 1, pieces["distance"])
            else:
                rendered += ".post0.dev%%d" %% (pieces["distance"])
        else:
            # no commits, use the tag as the version
            rendered = pieces["closest-tag"]
    else:
        # exception #1
        rendered = "0.post0.dev%%d" %% pieces["distance"]
    return rendered


def render_pep440_post(pieces):
    """TAG[.postDISTANCE[.dev0]+gHEX] .

    The ".dev0" means dirty. Note that .dev0 sorts backwards
    (a dirty tree will appear "older" than the corresponding clean one),
    but you shouldn't be releasing software with -dirty anyways.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%%d" %% pieces["distance"]
            if pieces["dirty"]:
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "g%%s" %% pieces["short"]
    else:
        # exception #1
        rendered = "0.post%%d" %% pieces["distance"]
        if pieces["dirty"]:
            rendered += ".dev0"
        rendered += "+g%%s" %% pieces["short"]
    return rendered


def render_pep440_post_branch(pieces):
    """TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The ".dev0" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%%d" %% pieces["distance"]
            if pieces["branch"] != "master":
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "g%%s" %% pieces["short"]
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0.post%%d" %% pieces["distance"]
        if pieces["branch"] != "master":
            rendered += ".dev0"
        rendered += "+g%%s" %% pieces["short"]
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def render_pep440_old(pieces):
    """TAG[.postDISTANCE[.dev0]] .

    The ".dev0" means dirty.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%%d" %% pieces["distance"]
            if pieces["dirty"]:
                rendered += ".dev0"
    else:
        # exception #1
        rendered = "0.post%%d" %% pieces["distance"]
        if pieces["dirty"]:
            rendered += ".dev0"
    return rendered


def render_git_describe(pieces):
    """TAG[-DISTANCE-gHEX][-dirty].

    Like 'git describe --tags --dirty --always'.

    Exceptions:
    1: no tags. HEX[-dirty]  (note: no 'g' prefix)
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"]:
            rendered += "-%%d-g%%s" %% (pieces["distance"], pieces["short"])
    else:
        # exception #1
        rendered = pieces["short"]
    if pieces["dirty"]:
        rendered += "-dirty"
    return rendered


def render_git_describe_long(pieces):
    """TAG-DISTANCE-gHEX[-dirty].

    Like 'git describe --tags --dirty --always -long'.
    The distance/hash is unconditional.

    Exceptions:
    1: no tags. HEX[-dirty]  (note: no 'g' prefix)
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        rendered += "-%%d-g%%s" %% (pieces["distance"], pieces["short"])
    else:
        # exception #1
        rendered = pieces["short"]
    if pieces["dirty"]:
        rendered += "-dirty"
    return rendered


def render(pieces, style):
    """Render the given version pieces into the requested style."""
    if pieces["error"]:
        return {"version": "unknown",
                "full-revisionid": pieces.get("long"),
                "dirty": None,
                "error": pieces["error"],
                "date": None}

    if not style or style == "default":
        style = "pep440"  # the default

    if style == "pep440":
        rendered = render_pep440(pieces)
    elif style == "pep440-branch":
        rendered = render_pep440_branch(pieces)
    elif style == "pep440-pre":
        rendered = render_pep440_pre(pieces)
    elif style == "pep440-post":
        rendered = render_pep440_post(pieces)
    elif style == "pep440-post-branch":
        rendered = render_pep440_post_branch(pieces)
    elif style == "pep440-old":
        rendered = render_pep440_old(pieces)
    elif style == "git-describe":
        rendered = render_git_describe(pieces)
    elif style == "git-describe-long":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError("unknown style '%%s'" %% style)

    return {"version": rendered, "full-revisionid": pieces["long"],
            "dirty": pieces["dirty"], "error": None,
            "date": pieces.get("date")}


def get_versions():
    """Get version information or return default if unable to do so."""
    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have
    # __file__, we can work backwards from there to the root. Some
    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which
    # case we can only use expanded keywords.

    cfg = get_config()
    verbose = cfg.verbose

    try:
        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,
                                          verbose)
    except NotThisMethod:
        pass

    try:
        root = os.path.realpath(__file__)
        # versionfile_source is the relative path from the top of the source
        # tree (where the .git directory might live) to this file. Invert
        # this to find the root from __file__.
        for _ in cfg.versionfile_source.split('/'):
            root = os.path.dirname(root)
    except NameError:
        return {"version": "0+unknown", "full-revisionid": None,
                "dirty": None,
                "error": "unable to find root of source tree",
                "date": None}

    try:
        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)
        return render(pieces, cfg.style)
    except NotThisMethod:
        pass

    try:
        if cfg.parentdir_prefix:
            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)
    except NotThisMethod:
        pass

    return {"version": "0+unknown", "full-revisionid": None,
            "dirty": None,
            "error": "unable to compute version", "date": None}
'''


@register_vcs_handler("git", "get_keywords")
def git_get_keywords(versionfile_abs):
    """Extract version information from the given file."""
    # the code embedded in _version.py can just fetch the value of these
    # keywords. When used from setup.py, we don't want to import _version.py,
    # so we do it with a regexp instead. This function is not used from
    # _version.py.
    keywords = {}
    try:
        with open(versionfile_abs, "r") as fobj:
            for line in fobj:
                if line.strip().startswith("git_refnames ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["refnames"] = mo.group(1)
                if line.strip().startswith("git_full ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["full"] = mo.group(1)
                if line.strip().startswith("git_date ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["date"] = mo.group(1)
    except OSError:
        pass
    return keywords


@register_vcs_handler("git", "keywords")
def git_versions_from_keywords(keywords, tag_prefix, verbose):
    """Get version information from git keywords."""
    if "refnames" not in keywords:
        raise NotThisMethod("Short version file found")
    date = keywords.get("date")
    if date is not None:
        # Use only the last line.  Previous lines may contain GPG signature
        # information.
        date = date.splitlines()[-1]

        # git-2.2.0 added "%cI", which expands to an ISO-8601 -compliant
        # datestamp. However we prefer "%ci" (which expands to an "ISO-8601
        # -like" string, which we must then edit to make compliant), because
        # it's been around since git-1.5.3, and it's too difficult to
        # discover which version we're using, or to work around using an
        # older one.
        date = date.strip().replace(" ", "T", 1).replace(" ", "", 1)
    refnames = keywords["refnames"].strip()
    if refnames.startswith("$Format"):
        if verbose:
            print("keywords are unexpanded, not using")
        raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
    refs = {r.strip() for r in refnames.strip("()").split(",")}
    # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
    # just "foo-1.0". If we see a "tag: " prefix, prefer those.
    TAG = "tag: "
    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like "release" and
        # "stabilization", as well as "HEAD" and "master".
        tags = {r for r in refs if re.search(r"\d", r)}
        if verbose:
            print("discarding '%s', no digits" % ",".join(refs - tags))
    if verbose:
        print("likely tags: %s" % ",".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. "2.0" over "2.0rc1"
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix) :]
            # Filter out refs that exactly match prefix or that don't start
            # with a number once the prefix is stripped (mostly a concern
            # when prefix is '')
            if not re.match(r"\d", r):
                continue
            if verbose:
                print("picking %s" % r)
            return {
                "version": r,
                "full-revisionid": keywords["full"].strip(),
                "dirty": False,
                "error": None,
                "date": date,
            }
    # no suitable tags, so version is "0+unknown", but full hex is still there
    if verbose:
        print("no suitable tags, using unknown + full revision id")
    return {
        "version": "0+unknown",
        "full-revisionid": keywords["full"].strip(),
        "dirty": False,
        "error": "no suitable tags",
        "date": None,
    }


@register_vcs_handler("git", "pieces_from_vcs")
def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):
    """Get version from 'git describe' in the root of the source tree.

    This only gets called if the git-archive 'subst' keywords were *not*
    expanded, and _version.py hasn't already been rewritten with a short
    version string, meaning we're inside a checked out source tree.
    """
    GITS = ["git"]
    if sys.platform == "win32":
        GITS = ["git.cmd", "git.exe"]

    # GIT_DIR can interfere with correct operation of Versioneer.
    # It may be intended to be passed to the Versioneer-versioned project,
    # but that should not change where we get our version from.
    env = os.environ.copy()
    env.pop("GIT_DIR", None)
    runner = functools.partial(runner, env=env)

    _, rc = runner(GITS, ["rev-parse", "--git-dir"], cwd=root, hide_stderr=not verbose)
    if rc != 0:
        if verbose:
            print("Directory %s not under git control" % root)
        raise NotThisMethod("'git rev-parse --git-dir' returned error")

    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]
    # if there isn't one, this yields HEX[-dirty] (no NUM)
    describe_out, rc = runner(
        GITS,
        [
            "describe",
            "--tags",
            "--dirty",
            "--always",
            "--long",
            "--match",
            f"{tag_prefix}[[:digit:]]*",
        ],
        cwd=root,
    )
    # --long was added in git-1.5.5
    if describe_out is None:
        raise NotThisMethod("'git describe' failed")
    describe_out = describe_out.strip()
    full_out, rc = runner(GITS, ["rev-parse", "HEAD"], cwd=root)
    if full_out is None:
        raise NotThisMethod("'git rev-parse' failed")
    full_out = full_out.strip()

    pieces = {}
    pieces["long"] = full_out
    pieces["short"] = full_out[:7]  # maybe improved later
    pieces["error"] = None

    branch_name, rc = runner(GITS, ["rev-parse", "--abbrev-ref", "HEAD"], cwd=root)
    # --abbrev-ref was added in git-1.6.3
    if rc != 0 or branch_name is None:
        raise NotThisMethod("'git rev-parse --abbrev-ref' returned error")
    branch_name = branch_name.strip()

    if branch_name == "HEAD":
        # If we aren't exactly on a branch, pick a branch which represents
        # the current commit. If all else fails, we are on a branchless
        # commit.
        branches, rc = runner(GITS, ["branch", "--contains"], cwd=root)
        # --contains was added in git-1.5.4
        if rc != 0 or branches is None:
            raise NotThisMethod("'git branch --contains' returned error")
        branches = branches.split("\n")

        # Remove the first line if we're running detached
        if "(" in branches[0]:
            branches.pop(0)

        # Strip off the leading "* " from the list of branches.
        branches = [branch[2:] for branch in branches]
        if "master" in branches:
            branch_name = "master"
        elif not branches:
            branch_name = None
        else:
            # Pick the first branch that is returned. Good or bad.
            branch_name = branches[0]

    pieces["branch"] = branch_name

    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]
    # TAG might have hyphens.
    git_describe = describe_out

    # look for -dirty suffix
    dirty = git_describe.endswith("-dirty")
    pieces["dirty"] = dirty
    if dirty:
        git_describe = git_describe[: git_describe.rindex("-dirty")]

    # now we have TAG-NUM-gHEX or HEX

    if "-" in git_describe:
        # TAG-NUM-gHEX
        mo = re.search(r"^(.+)-(\d+)-g([0-9a-f]+)$", git_describe)
        if not mo:
            # unparsable. Maybe git-describe is misbehaving?
            pieces["error"] = "unable to parse git-describe output: '%s'" % describe_out
            return pieces

        # tag
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = "tag '%s' doesn't start with prefix '%s'"
                print(fmt % (full_tag, tag_prefix))
            pieces["error"] = "tag '%s' doesn't start with prefix '%s'" % (
                full_tag,
                tag_prefix,
            )
            return pieces
        pieces["closest-tag"] = full_tag[len(tag_prefix) :]

        # distance: number of commits since tag
        pieces["distance"] = int(mo.group(2))

        # commit: short hex revision ID
        pieces["short"] = mo.group(3)

    else:
        # HEX: no tags
        pieces["closest-tag"] = None
        out, rc = runner(GITS, ["rev-list", "HEAD", "--left-right"], cwd=root)
        pieces["distance"] = len(out.split())  # total number of commits

    # commit date: see ISO-8601 comment in git_versions_from_keywords()
    date = runner(GITS, ["show", "-s", "--format=%ci", "HEAD"], cwd=root)[0].strip()
    # Use only the last line.  Previous lines may contain GPG signature
    # information.
    date = date.splitlines()[-1]
    pieces["date"] = date.strip().replace(" ", "T", 1).replace(" ", "", 1)

    return pieces


def do_vcs_install(versionfile_source, ipy):
    """Git-specific installation logic for Versioneer.

    For Git, this means creating/changing .gitattributes to mark _version.py
    for export- subst keyword substitution.
    """
    GITS = ["git"]
    if sys.platform == "win32":
        GITS = ["git.cmd", "git.exe"]
    files = [versionfile_source]
    if ipy:
        files.append(ipy)
    if "VERSIONEER_PEP518" not in globals():
        try:
            my_path = __file__
            if my_path.endswith((".pyc", ".pyo")):
                my_path = os.path.splitext(my_path)[0] + ".py"
            versioneer_file = os.path.relpath(my_path)
        except NameError:
            versioneer_file = "versioneer.py"
        files.append(versioneer_file)
    present = False
    try:
        with open(".gitattributes", "r") as fobj:
            for line in fobj:
                if line.strip().startswith(versionfile_source):
                    if "export-subst" in line.strip().split()[1:]:
                        present = True
                        break
    except OSError:
        pass
    if not present:
        with open(".gitattributes", "a+") as fobj:
            fobj.write(f"{versionfile_source} export-subst\n")
        files.append(".gitattributes")
    run_command(GITS, ["add", "--"] + files)


def versions_from_parentdir(parentdir_prefix, root, verbose):
    """Try to determine the version from the parent directory name.

    Source tarballs conventionally unpack into a directory that includes both
    the project name and a version string. We will also support searching up
    two directory levels for an appropriately named parent directory
    """
    rootdirs = []

    for _ in range(3):
        dirname = os.path.basename(root)
        if dirname.startswith(parentdir_prefix):
            return {
                "version": dirname[len(parentdir_prefix) :],
                "full-revisionid": None,
                "dirty": False,
                "error": None,
                "date": None,
            }
        rootdirs.append(root)
        root = os.path.dirname(root)  # up a level

    if verbose:
        print(
            "Tried directories %s but none started with prefix %s"
            % (str(rootdirs), parentdir_prefix)
        )
    raise NotThisMethod("rootdir doesn't start with parentdir_prefix")


SHORT_VERSION_PY = """
# This file was generated by 'versioneer.py' (0.28) from
# revision-control system data, or from the parent directory name of an
# unpacked source archive. Distribution tarballs contain a pre-generated copy
# of this file.

import json

version_json = '''
%s
'''  # END VERSION_JSON


def get_versions():
    return json.loads(version_json)
"""


def versions_from_file(filename):
    """Try to determine the version from _version.py if present."""
    try:
        with open(filename) as f:
            contents = f.read()
    except OSError:
        raise NotThisMethod("unable to read _version.py")
    mo = re.search(
        r"version_json = '''\n(.*)'''  # END VERSION_JSON",
        contents,
        re.M | re.S,
    )
    if not mo:
        mo = re.search(
            r"version_json = '''\r\n(.*)'''  # END VERSION_JSON",
            contents,
            re.M | re.S,
        )
    if not mo:
        raise NotThisMethod("no version_json in _version.py")
    return json.loads(mo.group(1))


def write_to_version_file(filename, versions):
    """Write the given version number to the given _version.py file."""
    os.unlink(filename)
    contents = json.dumps(versions, sort_keys=True, indent=1, separators=(",", ": "))
    with open(filename, "w") as f:
        f.write(SHORT_VERSION_PY % contents)

    print("set %s to '%s'" % (filename, versions["version"]))


def plus_or_dot(pieces):
    """Return a + if we don't already have one, else return a ."""
    if "+" in pieces.get("closest-tag", ""):
        return "."
    return "+"


def render_pep440(pieces):
    """Build up version string, with post-release "local version identifier".

    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you
    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty

    Exceptions:
    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += plus_or_dot(pieces)
            rendered += "%d.g%s" % (pieces["distance"], pieces["short"])
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0+untagged.%d.g%s" % (pieces["distance"], pieces["short"])
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def render_pep440_branch(pieces):
    """TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .

    The ".dev0" means not master branch. Note that .dev0 sorts backwards
    (a feature branch will appear "older" than the master branch).

    Exceptions:
    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            if pieces["branch"] != "master":
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "%d.g%s" % (pieces["distance"], pieces["short"])
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0"
        if pieces["branch"] != "master":
            rendered += ".dev0"
        rendered += "+untagged.%d.g%s" % (pieces["distance"], pieces["short"])
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def pep440_split_post(ver):
    """Split pep440 version string at the post-release segment.

    Returns the release segments before the post-release and the post-release
    version number (or -1 if no post-release segment is present).
    """
    vc = str.split(ver, ".post")
    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None


def render_pep440_pre(pieces):
    """TAG[.postN.devDISTANCE] -- No -dirty.

    Exceptions:
    1: no tags. 0.post0.devDISTANCE
    """
    if pieces["closest-tag"]:
        if pieces["distance"]:
            # update the post release segment
            tag_version, post_version = pep440_split_post(pieces["closest-tag"])
            rendered = tag_version
            if post_version is not None:
                rendered += ".post%d.dev%d" % (
                    post_version + 1,
                    pieces["distance"],
                )
            else:
                rendered += ".post0.dev%d" % (pieces["distance"])
        else:
            # no commits, use the tag as the version
            rendered = pieces["closest-tag"]
    else:
        # exception #1
        rendered = "0.post0.dev%d" % pieces["distance"]
    return rendered


def render_pep440_post(pieces):
    """TAG[.postDISTANCE[.dev0]+gHEX] .

    The ".dev0" means dirty. Note that .dev0 sorts backwards
    (a dirty tree will appear "older" than the corresponding clean one),
    but you shouldn't be releasing software with -dirty anyways.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%d" % pieces["distance"]
            if pieces["dirty"]:
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "g%s" % pieces["short"]
    else:
        # exception #1
        rendered = "0.post%d" % pieces["distance"]
        if pieces["dirty"]:
            rendered += ".dev0"
        rendered += "+g%s" % pieces["short"]
    return rendered


def render_pep440_post_branch(pieces):
    """TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The ".dev0" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%d" % pieces["distance"]
            if pieces["branch"] != "master":
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "g%s" % pieces["short"]
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0.post%d" % pieces["distance"]
        if pieces["branch"] != "master":
            rendered += ".dev0"
        rendered += "+g%s" % pieces["short"]
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def render_pep440_old(pieces):
    """TAG[.postDISTANCE[.dev0]] .

    The ".dev0" means dirty.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%d" % pieces["distance"]
            if pieces["dirty"]:
                rendered += ".dev0"
    else:
        # exception #1
        rendered = "0.post%d" % pieces["distance"]
        if pieces["dirty"]:
            rendered += ".dev0"
    return rendered


def render_git_describe(pieces):
    """TAG[-DISTANCE-gHEX][-dirty].

    Like 'git describe --tags --dirty --always'.

    Exceptions:
    1: no tags. HEX[-dirty]  (note: no 'g' prefix)
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"]:
            rendered += "-%d-g%s" % (pieces["distance"], pieces["short"])
    else:
        # exception #1
        rendered = pieces["short"]
    if pieces["dirty"]:
        rendered += "-dirty"
    return rendered


def render_git_describe_long(pieces):
    """TAG-DISTANCE-gHEX[-dirty].

    Like 'git describe --tags --dirty --always -long'.
    The distance/hash is unconditional.

    Exceptions:
    1: no tags. HEX[-dirty]  (note: no 'g' prefix)
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        rendered += "-%d-g%s" % (pieces["distance"], pieces["short"])
    else:
        # exception #1
        rendered = pieces["short"]
    if pieces["dirty"]:
        rendered += "-dirty"
    return rendered


def render(pieces, style):
    """Render the given version pieces into the requested style."""
    if pieces["error"]:
        return {
            "version": "unknown",
            "full-revisionid": pieces.get("long"),
            "dirty": None,
            "error": pieces["error"],
            "date": None,
        }

    if not style or style == "default":
        style = "pep440"  # the default

    if style == "pep440":
        rendered = render_pep440(pieces)
    elif style == "pep440-branch":
        rendered = render_pep440_branch(pieces)
    elif style == "pep440-pre":
        rendered = render_pep440_pre(pieces)
    elif style == "pep440-post":
        rendered = render_pep440_post(pieces)
    elif style == "pep440-post-branch":
        rendered = render_pep440_post_branch(pieces)
    elif style == "pep440-old":
        rendered = render_pep440_old(pieces)
    elif style == "git-describe":
        rendered = render_git_describe(pieces)
    elif style == "git-describe-long":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError("unknown style '%s'" % style)

    return {
        "version": rendered,
        "full-revisionid": pieces["long"],
        "dirty": pieces["dirty"],
        "error": None,
        "date": pieces.get("date"),
    }


class VersioneerBadRootError(Exception):
    """The project root directory is unknown or missing key files."""


def get_versions(verbose=False):
    """Get the project version from whatever source is available.

    Returns dict with two keys: 'version' and 'full'.
    """
    if "versioneer" in sys.modules:
        # see the discussion in cmdclass.py:get_cmdclass()
        del sys.modules["versioneer"]

    root = get_root()
    cfg = get_config_from_root(root)

    assert cfg.VCS is not None, "please set [versioneer]VCS= in setup.cfg"
    handlers = HANDLERS.get(cfg.VCS)
    assert handlers, "unrecognized VCS '%s'" % cfg.VCS
    verbose = verbose or cfg.verbose
    assert cfg.versionfile_source is not None, "please set versioneer.versionfile_source"
    assert cfg.tag_prefix is not None, "please set versioneer.tag_prefix"

    versionfile_abs = os.path.join(root, cfg.versionfile_source)

    # extract version from first of: _version.py, VCS command (e.g. 'git
    # describe'), parentdir. This is meant to work for developers using a
    # source checkout, for users of a tarball created by 'setup.py sdist',
    # and for users of a tarball/zipball created by 'git archive' or github's
    # download-from-tag feature or the equivalent in other VCSes.

    get_keywords_f = handlers.get("get_keywords")
    from_keywords_f = handlers.get("keywords")
    if get_keywords_f and from_keywords_f:
        try:
            keywords = get_keywords_f(versionfile_abs)
            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)
            if verbose:
                print("got version from expanded keyword %s" % ver)
            return ver
        except NotThisMethod:
            pass

    try:
        ver = versions_from_file(versionfile_abs)
        if verbose:
            print("got version from file %s %s" % (versionfile_abs, ver))
        return ver
    except NotThisMethod:
        pass

    from_vcs_f = handlers.get("pieces_from_vcs")
    if from_vcs_f:
        try:
            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)
            ver = render(pieces, cfg.style)
            if verbose:
                print("got version from VCS %s" % ver)
            return ver
        except NotThisMethod:
            pass

    try:
        if cfg.parentdir_prefix:
            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)
            if verbose:
                print("got version from parentdir %s" % ver)
            return ver
    except NotThisMethod:
        pass

    if verbose:
        print("unable to compute version")

    return {
        "version": "0+unknown",
        "full-revisionid": None,
        "dirty": None,
        "error": "unable to compute version",
        "date": None,
    }


def get_version():
    """Get the short version string for this project."""
    return get_versions()["version"]


def get_cmdclass(cmdclass=None):
    """Get the custom setuptools subclasses used by Versioneer.

    If the package uses a different cmdclass (e.g. one from numpy), it should
    be provide as an argument.
    """
    if "versioneer" in sys.modules:
        del sys.modules["versioneer"]
        # this fixes the "python setup.py develop" case (also 'install' and
        # 'easy_install .'), in which subdependencies of the main project are
        # built (using setup.py bdist_egg) in the same python process. Assume
        # a main project A and a dependency B, which use different versions
        # of Versioneer. A's setup.py imports A's Versioneer, leaving it in
        # sys.modules by the time B's setup.py is executed, causing B to run
        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a
        # sandbox that restores sys.modules to it's pre-build state, so the
        # parent is protected against the child's "import versioneer". By
        # removing ourselves from sys.modules here, before the child build
        # happens, we protect the child from the parent's versioneer too.
        # Also see https://github.com/python-versioneer/python-versioneer/issues/52

    cmds = {} if cmdclass is None else cmdclass.copy()

    # we add "version" to setuptools
    from setuptools import Command

    class cmd_version(Command):
        description = "report generated version string"
        user_options = []
        boolean_options = []

        def initialize_options(self):
            pass

        def finalize_options(self):
            pass

        def run(self):
            vers = get_versions(verbose=True)
            print("Version: %s" % vers["version"])
            print(" full-revisionid: %s" % vers.get("full-revisionid"))
            print(" dirty: %s" % vers.get("dirty"))
            print(" date: %s" % vers.get("date"))
            if vers["error"]:
                print(" error: %s" % vers["error"])

    cmds["version"] = cmd_version

    # we override "build_py" in setuptools
    #
    # most invocation pathways end up running build_py:
    #  distutils/build -> build_py
    #  distutils/install -> distutils/build ->..
    #  setuptools/bdist_wheel -> distutils/install ->..
    #  setuptools/bdist_egg -> distutils/install_lib -> build_py
    #  setuptools/install -> bdist_egg ->..
    #  setuptools/develop -> ?
    #  pip install:
    #   copies source tree to a tempdir before running egg_info/etc
    #   if .git isn't copied too, 'git describe' will fail
    #   then does setup.py bdist_wheel, or sometimes setup.py install
    #  setup.py egg_info -> ?

    # pip install -e . and setuptool/editable_wheel will invoke build_py
    # but the build_py command is not expected to copy any files.

    # we override different "build_py" commands for both environments
    if "build_py" in cmds:
        _build_py = cmds["build_py"]
    else:
        from setuptools.command.build_py import build_py as _build_py

    class cmd_build_py(_build_py):
        def run(self):
            root = get_root()
            cfg = get_config_from_root(root)
            versions = get_versions()
            _build_py.run(self)
            if getattr(self, "editable_mode", False):
                # During editable installs `.py` and data files are
                # not copied to build_lib
                return
            # now locate _version.py in the new build/ directory and replace
            # it with an updated value
            if cfg.versionfile_build:
                target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)
                print("UPDATING %s" % target_versionfile)
                write_to_version_file(target_versionfile, versions)

    cmds["build_py"] = cmd_build_py

    if "build_ext" in cmds:
        _build_ext = cmds["build_ext"]
    else:
        from setuptools.command.build_ext import build_ext as _build_ext

    class cmd_build_ext(_build_ext):
        def run(self):
            root = get_root()
            cfg = get_config_from_root(root)
            versions = get_versions()
            _build_ext.run(self)
            if self.inplace:
                # build_ext --inplace will only build extensions in
                # build/lib<..> dir with no _version.py to write to.
                # As in place builds will already have a _version.py
                # in the module dir, we do not need to write one.
                return
            # now locate _version.py in the new build/ directory and replace
            # it with an updated value
            if not cfg.versionfile_build:
                return
            target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)
            if not os.path.exists(target_versionfile):
                print(
                    f"Warning: {target_versionfile} does not exist, skipping "
                    "version update. This can happen if you are running build_ext "
                    "without first running build_py."
                )
                return
            print("UPDATING %s" % target_versionfile)
            write_to_version_file(target_versionfile, versions)

    cmds["build_ext"] = cmd_build_ext

    if "cx_Freeze" in sys.modules:  # cx_freeze enabled?
        from cx_Freeze.dist import build_exe as _build_exe

        # nczeczulin reports that py2exe won't like the pep440-style string
        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.
        # setup(console=[{
        #   "version": versioneer.get_version().split("+", 1)[0], # FILEVERSION
        #   "product_version": versioneer.get_version(),
        #   ...

        class cmd_build_exe(_build_exe):
            def run(self):
                root = get_root()
                cfg = get_config_from_root(root)
                versions = get_versions()
                target_versionfile = cfg.versionfile_source
                print("UPDATING %s" % target_versionfile)
                write_to_version_file(target_versionfile, versions)

                _build_exe.run(self)
                os.unlink(target_versionfile)
                with open(cfg.versionfile_source, "w") as f:
                    LONG = LONG_VERSION_PY[cfg.VCS]
                    f.write(
                        LONG
                        % {
                            "DOLLAR": "$",
                            "STYLE": cfg.style,
                            "TAG_PREFIX": cfg.tag_prefix,
                            "PARENTDIR_PREFIX": cfg.parentdir_prefix,
                            "VERSIONFILE_SOURCE": cfg.versionfile_source,
                        }
                    )

        cmds["build_exe"] = cmd_build_exe
        del cmds["build_py"]

    if "py2exe" in sys.modules:  # py2exe enabled?
        try:
            from py2exe.setuptools_buildexe import py2exe as _py2exe
        except ImportError:
            from py2exe.distutils_buildexe import py2exe as _py2exe

        class cmd_py2exe(_py2exe):
            def run(self):
                root = get_root()
                cfg = get_config_from_root(root)
                versions = get_versions()
                target_versionfile = cfg.versionfile_source
                print("UPDATING %s" % target_versionfile)
                write_to_version_file(target_versionfile, versions)

                _py2exe.run(self)
                os.unlink(target_versionfile)
                with open(cfg.versionfile_source, "w") as f:
                    LONG = LONG_VERSION_PY[cfg.VCS]
                    f.write(
                        LONG
                        % {
                            "DOLLAR": "$",
                            "STYLE": cfg.style,
                            "TAG_PREFIX": cfg.tag_prefix,
                            "PARENTDIR_PREFIX": cfg.parentdir_prefix,
                            "VERSIONFILE_SOURCE": cfg.versionfile_source,
                        }
                    )

        cmds["py2exe"] = cmd_py2exe

    # sdist farms its file list building out to egg_info
    if "egg_info" in cmds:
        _egg_info = cmds["egg_info"]
    else:
        from setuptools.command.egg_info import egg_info as _egg_info

    class cmd_egg_info(_egg_info):
        def find_sources(self):
            # egg_info.find_sources builds the manifest list and writes it
            # in one shot
            super().find_sources()

            # Modify the filelist and normalize it
            root = get_root()
            cfg = get_config_from_root(root)
            self.filelist.append("versioneer.py")
            if cfg.versionfile_source:
                # There are rare cases where versionfile_source might not be
                # included by default, so we must be explicit
                self.filelist.append(cfg.versionfile_source)
            self.filelist.sort()
            self.filelist.remove_duplicates()

            # The write method is hidden in the manifest_maker instance that
            # generated the filelist and was thrown away
            # We will instead replicate their final normalization (to unicode,
            # and POSIX-style paths)
            from setuptools import unicode_utils

            normalized = [
                unicode_utils.filesys_decode(f).replace(os.sep, "/") for f in self.filelist.files
            ]

            manifest_filename = os.path.join(self.egg_info, "SOURCES.txt")
            with open(manifest_filename, "w") as fobj:
                fobj.write("\n".join(normalized))

    cmds["egg_info"] = cmd_egg_info

    # we override different "sdist" commands for both environments
    if "sdist" in cmds:
        _sdist = cmds["sdist"]
    else:
        from setuptools.command.sdist import sdist as _sdist

    class cmd_sdist(_sdist):
        def run(self):
            versions = get_versions()
            self._versioneer_generated_versions = versions
            # unless we update this, the command will keep using the old
            # version
            self.distribution.metadata.version = versions["version"]
            return _sdist.run(self)

        def make_release_tree(self, base_dir, files):
            root = get_root()
            cfg = get_config_from_root(root)
            _sdist.make_release_tree(self, base_dir, files)
            # now locate _version.py in the new base_dir directory
            # (remembering that it may be a hardlink) and replace it with an
            # updated value
            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)
            print("UPDATING %s" % target_versionfile)
            write_to_version_file(target_versionfile, self._versioneer_generated_versions)

    cmds["sdist"] = cmd_sdist

    return cmds


CONFIG_ERROR = """
setup.cfg is missing the necessary Versioneer configuration. You need
a section like:

 [versioneer]
 VCS = git
 style = pep440
 versionfile_source = src/myproject/_version.py
 versionfile_build = myproject/_version.py
 tag_prefix =
 parentdir_prefix = myproject-

You will also need to edit your setup.py to use the results:

 import versioneer
 setup(version=versioneer.get_version(),
       cmdclass=versioneer.get_cmdclass(), ...)

Please read the docstring in ./versioneer.py for configuration instructions,
edit setup.cfg, and re-run the installer or 'python versioneer.py setup'.
"""

SAMPLE_CONFIG = """
# See the docstring in versioneer.py for instructions. Note that you must
# re-run 'versioneer.py setup' after changing this section, and commit the
# resulting files.

[versioneer]
#VCS = git
#style = pep440
#versionfile_source =
#versionfile_build =
#tag_prefix =
#parentdir_prefix =

"""

OLD_SNIPPET = """
from ._version import get_versions
__version__ = get_versions()['version']
del get_versions
"""

INIT_PY_SNIPPET = """
from . import {0}
__version__ = {0}.get_versions()['version']
"""


def do_setup():
    """Do main VCS-independent setup function for installing Versioneer."""
    root = get_root()
    try:
        cfg = get_config_from_root(root)
    except (
        OSError,
        configparser.NoSectionError,
        configparser.NoOptionError,
    ) as e:
        if isinstance(e, (OSError, configparser.NoSectionError)):
            print("Adding sample versioneer config to setup.cfg", file=sys.stderr)
            with open(os.path.join(root, "setup.cfg"), "a") as f:
                f.write(SAMPLE_CONFIG)
        print(CONFIG_ERROR, file=sys.stderr)
        return 1

    print(" creating %s" % cfg.versionfile_source)
    with open(cfg.versionfile_source, "w") as f:
        LONG = LONG_VERSION_PY[cfg.VCS]
        f.write(
            LONG
            % {
                "DOLLAR": "$",
                "STYLE": cfg.style,
                "TAG_PREFIX": cfg.tag_prefix,
                "PARENTDIR_PREFIX": cfg.parentdir_prefix,
                "VERSIONFILE_SOURCE": cfg.versionfile_source,
            }
        )

    ipy = os.path.join(os.path.dirname(cfg.versionfile_source), "__init__.py")
    if os.path.exists(ipy):
        try:
            with open(ipy, "r") as f:
                old = f.read()
        except OSError:
            old = ""
        module = os.path.splitext(os.path.basename(cfg.versionfile_source))[0]
        snippet = INIT_PY_SNIPPET.format(module)
        if OLD_SNIPPET in old:
            print(" replacing boilerplate in %s" % ipy)
            with open(ipy, "w") as f:
                f.write(old.replace(OLD_SNIPPET, snippet))
        elif snippet not in old:
            print(" appending to %s" % ipy)
            with open(ipy, "a") as f:
                f.write(snippet)
        else:
            print(" %s unmodified" % ipy)
    else:
        print(" %s doesn't exist, ok" % ipy)
        ipy = None

    # Make VCS-specific changes. For git, this means creating/changing
    # .gitattributes to mark _version.py for export-subst keyword
    # substitution.
    do_vcs_install(cfg.versionfile_source, ipy)
    return 0


def scan_setup_py():
    """Validate the contents of setup.py against Versioneer's expectations."""
    found = set()
    setters = False
    errors = 0
    with open("setup.py", "r") as f:
        for line in f.readlines():
            if "import versioneer" in line:
                found.add("import")
            if "versioneer.get_cmdclass()" in line:
                found.add("cmdclass")
            if "versioneer.get_version()" in line:
                found.add("get_version")
            if "versioneer.VCS" in line:
                setters = True
            if "versioneer.versionfile_source" in line:
                setters = True
    if len(found) != 3:
        print("")
        print("Your setup.py appears to be missing some important items")
        print("(but I might be wrong). Please make sure it has something")
        print("roughly like the following:")
        print("")
        print(" import versioneer")
        print(" setup( version=versioneer.get_version(),")
        print("        cmdclass=versioneer.get_cmdclass(),  ...)")
        print("")
        errors += 1
    if setters:
        print("You should remove lines like 'versioneer.VCS = ' and")
        print("'versioneer.versionfile_source = ' . This configuration")
        print("now lives in setup.cfg, and should be removed from setup.py")
        print("")
        errors += 1
    return errors


def setup_command():
    """Set up Versioneer and exit with appropriate error code."""
    errors = do_setup()
    errors += scan_setup_py()
    sys.exit(1 if errors else 0)


if __name__ == "__main__":
    cmd = sys.argv[1]
    if cmd == "setup":
        setup_command()


--- File: NOTICE.md ---
Keypoint-MoSeq also can use the inputs from other keypoint algorithms (as shown in [Weinreb et al. 2023](https://www.biorxiv.org/content/10.1101/2023.03.16.532307v1)),
such as DeepLabCut, DeepLabCut SuperAnimal models, and SLEAP. But note they have other licenses:

- DeepLabCut is licensed under a LGPL-3.0 license. https://github.com/DeepLabCut/DeepLabCut. 
- SuperAnimal model weights are non-commerical use only. Please check model cards on HuggingFace carefully. https://huggingface.co/mwmathis
- SLEAP is released under a Clear BSD License and is intended for research/academic use only. https://github.com/talmolab/sleap
- Simple-HRNet is licensed under a GPL-3.0 license. https://github.com/stefanopini/simple-HRNet.


--- File: keypoint_moseq/analysis.py ---
from keypoint_moseq.util import filter_angle
from keypoint_moseq.io import load_results
from math import ceil
from matplotlib.lines import Line2D
from cytoolz import sliding_window
import networkx as nx
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from statsmodels.stats.multitest import multipletests
from itertools import combinations
from copy import deepcopy
from glob import glob
import panel as pn
from jax_moseq.utils import get_durations, get_frequencies

pn.extension("plotly", "tabulator")
na = np.newaxis


def get_syllable_names(project_dir, model_name, syllable_ixs):
    """Get syllable names from syll_info.csv file. Labels consist of the
    syllable index, followed by the syllable label, if it exists.

    Parameters
    ----------
    project_dir : str
        the path to the project directory
    model_name : str
        the name of the model directory
    syllable_ixs : list
        list of syllable indices to get names for

    Returns
    -------
    names: list of str
        list of syllable names
    """
    labels = {ix: f"{ix}" for ix in syllable_ixs}
    syll_info_path = os.path.join(project_dir, model_name, "syll_info.csv")
    if os.path.exists(syll_info_path):
        syll_info_df = pd.read_csv(syll_info_path, index_col=False).fillna("")

        for ix in syllable_ixs:
            if len(syll_info_df[syll_info_df.syllable == ix].label.values[0]) > 0:
                labels[ix] = f"{ix} ({syll_info_df[syll_info_df.syllable == ix].label.values[0]})"
    names = [labels[ix] for ix in syllable_ixs]
    return names


def generate_index(project_dir, model_name, index_filepath):
    """Generate index file as a csv.

    Parameters
    ----------
    project_dir : str
        path to project directory
    model_name : str
        model directory name
    index_filepath : str
        path to index file
    """

    # load model results
    results_dict = load_results(project_dir, model_name)

    # check if file exists
    if os.path.exists(index_filepath):
        index_df = pd.read_csv(index_filepath, index_col=False)

        # all files are created
        if len(index_df) == len(results_dict.keys()):
            return
        else:
            # subset all the files
            files = index_df.name.values
            # find the missing file in results dict that's not in index
            for i in results_dict.keys():
                if i not in files:
                    index_df.loc[len(index_df.index)] = [i, "default"]
            # write index dataframe
            index_df.to_csv(index_filepath, index=False)
    else:
        # generate a new index file
        results_dict = load_results(project_dir, model_name)
        index_df = pd.DataFrame({"name": list(results_dict.keys()), "group": "default"})
        # write index dataframe
        index_df.to_csv(index_filepath, index=False)


def interactive_group_setting(project_dir, model_name):
    """Start the interactive group setting widget.

    Parameters
    ----------
    project_dir : str
        the path to the project directory
    model_name : str
        the name of the model directory
    """

    index_filepath = os.path.join(project_dir, "index.csv")

    if not os.path.exists(index_filepath):
        generate_index(project_dir, model_name, index_filepath)

    # making the interactive dataframe
    # open index dataframe

    # make a tabulator dataframe
    summary_data = pd.read_csv(index_filepath, index_col=False)

    titles = {"name": "recording name", "group": "group"}

    editors = {
        "name": None,
        "group": {
            "type": "textarea",
            "elementAttributes": {
                "maxlength": "100",
                "onkeydown": "if(event.keyCode == 13 && !event.shiftKey){this.blur();}",
            },
            "selectContents": True,
            "verticalNavigation": "editor",
            "shiftEnterSubmit": True,
        },
    }

    widths = {"name": 400}
    base_configuration = {"clipboard": "copy"}

    summary_table = pn.widgets.Tabulator(
        summary_data,
        editors=editors,
        layout="fit_data_table",
        selectable=1,
        show_index=False,
        titles=titles,
        widths=widths,
        configuration=base_configuration,
    )
    button = pn.widgets.Button(name="Save group info", button_type="primary")

    # call back function to save the index file
    def save_index(summary_data):
        # create index file from csv
        data_to_save = summary_data.copy()
        # remove newlines
        data_to_save["group"] = data_to_save["group"].str.strip()
        data_to_save.to_csv(index_filepath, index=False)

    # button click action
    def b(event, save=True):
        save_index(summary_data)

    button.on_click(b)

    return pn.Row(summary_table, pn.Column(button))


def compute_moseq_df(project_dir, model_name, *, fps=30, smooth_heading=True):
    """Compute moseq dataframe from results dict that contains all kinematic
    values by frame.

    Parameters
    ----------
    project_dir : str
        the path to the project directory
    model_name : str
        the name of the model directory
    results_dict : dict
        dictionary of results from model fitting
    use_bodyparts : bool
        boolean flag whether to include data for bodyparts
    smooth_heading : bool, optional
        boolean flag whether smooth the computed heading, by default True

    Returns
    -------
    moseq_df : pandas.DataFrame
        the dataframe that contains kinematic data for each frame
    """

    # load model results
    results_dict = load_results(project_dir, model_name)

    # load index file
    index_filepath = os.path.join(project_dir, "index.csv")
    if os.path.exists(index_filepath):
        index_data = pd.read_csv(index_filepath, index_col=False)
    else:
        print(
            "index.csv not found, if you want to include group information for each video, please run the Assign Groups widget first"
        )

    recording_name = []
    centroid = []
    velocity = []
    heading = []
    angular_velocity = []
    syllables = []
    frame_index = []
    s_group = []

    for k, v in results_dict.items():
        n_frame = v["centroid"].shape[0]
        recording_name.append([str(k)] * n_frame)
        centroid.append(v["centroid"])
        # velocity is pixel per second
        velocity.append(
            np.concatenate(
                (
                    [0],
                    np.sqrt(np.square(np.diff(v["centroid"], axis=0)).sum(axis=1)) * fps,
                )
            )
        )

        if index_data is not None:
            # find the group for each recording from index data
            s_group.append([index_data[index_data["name"] == k]["group"].values[0]] * n_frame)
        else:
            # no index data
            s_group.append(["default"] * n_frame)
        frame_index.append(np.arange(n_frame))

        if smooth_heading:
            recording_heading = filter_angle(v["heading"])
        else:
            recording_heading = v["heading"]

        # heading in radian
        heading.append(recording_heading)

        # compute angular velocity (radian per second)
        gaussian_smoothed_heading = filter_angle(recording_heading, size=3, method="gaussian")
        angular_velocity.append(np.concatenate(([0], np.diff(gaussian_smoothed_heading) * fps)))

        # add syllable data
        syllables.append(v["syllable"])

    # construct dataframe
    moseq_df = pd.DataFrame(np.concatenate(recording_name), columns=["name"])
    column_names = (
        ["centroid_x", "centroid_y"]
        if centroid[0].shape[1] == 2
        else ["centroid_x", "centroid_y", "centroid_z"]
    )
    moseq_df = pd.concat(
        [
            moseq_df,
            pd.DataFrame(np.concatenate(centroid), columns=column_names),
        ],
        axis=1,
    )
    moseq_df["heading"] = np.concatenate(heading)
    moseq_df["angular_velocity"] = np.concatenate(angular_velocity)
    moseq_df["velocity_px_s"] = np.concatenate(velocity)
    moseq_df["syllable"] = np.concatenate(syllables)
    moseq_df["frame_index"] = np.concatenate(frame_index)
    moseq_df["group"] = np.concatenate(s_group)

    # compute syllable onset
    change = np.diff(moseq_df["syllable"]) != 0
    indices = np.where(change)[0]
    indices += 1
    indices = np.concatenate(([0], indices))

    onset = np.full(moseq_df.shape[0], False)
    onset[indices] = True
    moseq_df["onset"] = onset
    return moseq_df


def compute_stats_df(
    project_dir,
    model_name,
    moseq_df,
    min_frequency=0.005,
    groupby=["group", "name"],
    fps=30,
):
    """Summary statistics for syllable frequencies and kinematic values.

    Parameters
    ----------
    moseq_df : pandas.DataFrame
        the dataframe that contains kinematic data for each frame
    threshold : float, optional
        usge threshold for the syllable to be included, by default 0.005
    groupby : list, optional
        the list of column names to group by, by default ['group', 'name']
    fps : int, optional
        frame per second information of the recording, by default 30

    Returns
    -------
    stats_df : pandas.DataFrame
        the summary statistics dataframe for syllable frequencies and kinematic values
    """
    # compute runlength encoding for syllables

    # load model results
    results_dict = load_results(project_dir, model_name)
    syllables = {k: res["syllable"] for k, res in results_dict.items()}
    # frequencies is array of frequencies for sorted syllables [syll_0, syll_1...]
    frequencies = get_frequencies(syllables)
    syll_include = np.where(frequencies > min_frequency)[0]

    # add group information
    # load index file
    index_filepath = os.path.join(project_dir, "index.csv")
    if os.path.exists(index_filepath):
        index_df = pd.read_csv(index_filepath, index_col=False)
    else:
        print(
            "index.csv not found, if you want to include group information for each video, please run the Assign Groups widget first"
        )

    # construct frequency dataframe
    # syllable frequencies within one session add up to 1
    frequency_df = []
    for k, v in results_dict.items():
        syll_freq = get_frequencies(v["syllable"])
        df = pd.DataFrame(
            {
                "name": k,
                "group": index_df[index_df["name"] == k]["group"].values[0],
                "syllable": np.arange(len(syll_freq)),
                "frequency": syll_freq,
            }
        )
        frequency_df.append(df)
    frequency_df = pd.concat(frequency_df)
    if "name" not in groupby:
        frequency_df.drop(columns=["name"], inplace=True)

    # filter out syllables that are used less than threshold in all recordings
    filtered_df = moseq_df[moseq_df["syllable"].isin(syll_include)].copy()

    # TODO: hard-coded heading for now, could add other scalars
    features = filtered_df.groupby(groupby + ["syllable"])[
        ["heading", "angular_velocity", "velocity_px_s"]
    ].agg(["mean", "std", "min", "max"])

    features.columns = ["_".join(col).strip() for col in features.columns.values]
    features.reset_index(inplace=True)

    # get durations
    trials = filtered_df["onset"].cumsum()
    trials.name = "trials"
    durations = filtered_df.groupby(groupby + ["syllable"] + [trials])["onset"].count()
    # average duration in seconds
    durations = durations.groupby(groupby + ["syllable"]).mean() / fps
    durations.name = "duration"
    # only keep the columns we need
    durations = durations.fillna(0).reset_index()[groupby + ["syllable", "duration"]]

    stats_df = pd.merge(features, frequency_df, on=groupby + ["syllable"])
    stats_df = pd.merge(stats_df, durations, on=groupby + ["syllable"])
    return stats_df


def generate_syll_info(project_dir, model_name, syll_info_path):
    # parse model results
    model_results = load_results(project_dir, model_name)
    unique_sylls = np.unique(np.concatenate([file["syllable"] for file in model_results.values()]))
    # construct the syllable dictionary
    # in the non interactive version there won't be any group info
    syll_info_df = pd.DataFrame(
        {
            "syllable": unique_sylls,
            "label": [""] * len(unique_sylls),
            "short_description": [""] * len(unique_sylls),
        }
    )

    grid_movies = glob(os.path.join(project_dir, model_name, "grid_movies", "*.mp4"))
    assert len(grid_movies) > 0, (
        "No grid movies found. Please run `generate_grid_movies` as described in the docs: "
        "https://keypoint-moseq.readthedocs.io/en/latest/modeling.html#visualization"
    )
    # make movie paths into a dataframe
    movie_df = pd.DataFrame(
        {
            "syllable": [
                int(os.path.splitext(os.path.basename(movie_path))[0][8:])
                for movie_path in grid_movies
            ],
            "movie_path": grid_movies,
        }
    )

    syll_info_df.merge(movie_df, on="syllable", how="outer").fillna("").to_csv(
        syll_info_path, index=False
    )


def label_syllables(project_dir, model_name, moseq_df):
    """Label syllables in the syllable grid movie.

    Parameters
    ----------
    project_dir : str
        the path to the project directory
    model_name : str
        the name of the model directory
    """

    # construct the syllable info path
    syll_info_path = os.path.join(project_dir, model_name, "syll_info.csv")

    # generate a new syll_info csv file
    if not os.path.exists(syll_info_path):
        # generate the syllable info csv file
        generate_syll_info(project_dir, model_name, syll_info_path)

    # ensure there is grid movies
    grid_movies = glob(os.path.join(project_dir, model_name, "grid_movies", "*.mp4"))
    assert len(grid_movies) > 0, (
        "No grid movies found. Please run `generate_grid_movies` as described in the docs: "
        "https://keypoint-moseq.readthedocs.io/en/latest/modeling.html#visualization"
    )

    # load syll_info
    syll_info_df = pd.read_csv(syll_info_path, index_col=False).fillna("")
    # split into with movie and without movie
    syll_info_df_with_movie = syll_info_df[syll_info_df.movie_path.str.contains(".mp4")].copy()
    syll_info_df_without_movie = syll_info_df[~syll_info_df.movie_path.str.contains(".mp4")].copy()

    # create select widget only include the ones with a movie
    select = pn.widgets.Select(
        name="Select", options=sorted(list(syll_info_df_with_movie.syllable))
    )

    # call back function to create video displayer
    def show_movie(syllable):
        movie_path = syll_info_df_with_movie[
            syll_info_df_with_movie.syllable == select.value
        ].movie_path.values[0]
        return pn.pane.Video(movie_path, width=500, loop=False)

    # dynamic video displayer
    ivideo = pn.bind(show_movie, syllable=select)

    # create the labeler dataframe
    # only include the syllable that have grid movies
    include = syll_info_df_with_movie.syllable.values
    syll_df = moseq_df[["syllable"]].groupby("syllable").mean().reset_index().copy()
    syll_df = syll_df[syll_df.syllable.isin(include)]

    # get labels and description from syll info
    syll_df = syll_df.merge(
        syll_info_df_with_movie[["syllable", "label", "short_description"]]
    ).copy()

    # set up interactive table
    titles = {
        "syllable": "syllable",
        "label": "label",
        "short_description": "short description",
    }
    editors = {
        "name": None,
        "label": {
            "type": "textarea",
            "elementAttributes": {
                "maxlength": "100",
                "onkeydown": "if(event.keyCode == 13 && !event.shiftKey){this.blur();}",
            },
            "selectContents": True,
            "verticalNavigation": "editor",
            "shiftEnterSubmit": True,
        },
        "short description": {
            "type": "textarea",
            "elementAttributes": {"maxlength": "200"},
            "selectContents": True,
            "verticalNavigation": "editor",
            "shiftEnterSubmit": True,
        },
    }

    base_configuration = {"clipboard": "copy"}

    widths = {"syllable": 100}
    summary_table = pn.widgets.Tabulator(
        syll_df,
        titles=titles,
        editors=editors,
        layout="fit_data_table",
        selectable=1,
        show_index=False,
        widths=widths,
        configuration=base_configuration,
    )

    button = pn.widgets.Button(name="Save syllable info", button_type="primary")

    # call back function to save the index file
    def save_index(syll_df):
        # create index file from csv
        temp_df = syll_df.copy()
        temp_df["label"] = temp_df["label"].str.strip()
        temp_df["short_description"] = temp_df["short_description"].str.strip()
        temp_df = temp_df.merge(
            syll_info_df_with_movie[["syllable", "movie_path"]], on="syllable"
        ).copy()
        pd.concat([temp_df, syll_info_df_without_movie]).fillna("").to_csv(
            syll_info_path, index=False
        )

    # button click action
    def b(event, save=True):
        save_index(syll_df)

    button.on_click(b)

    # bind everything together
    return pn.Row(pn.Column(select, ivideo), pn.Column(summary_table, pn.Column(button)))


def get_tie_correction(x, N_m):
    """Assign tied rank values to the average of the ranks they would have
    received if they had not been tied for Kruskal-Wallis helper function.

    Parameters
    ----------
    x : pd.Series
        syllable usages for a single recording.
    N_m : int
        Number of total recordings.

    Returns
    -------
    corrected_rank : float
        average of the inputted tied ranks.
    """

    vc = x.value_counts()
    tie_sum = 0
    if (vc > 1).any():
        tie_sum += np.sum(vc[vc != 1] ** 3 - vc[vc != 1])
    return tie_sum / (12.0 * (N_m - 1))


def run_manual_KW_test(
    df_usage,
    merged_usages_all,
    num_groups,
    n_per_group,
    cum_group_idx,
    n_perm=10000,
    seed=42,
):
    """Run a manual Kruskal-Wallis test compare the results agree with the
    scipy.stats.kruskal function.

    Parameters
    ----------
    df_usage : pandas.DataFrame
        DataFrame with syllable usages. shape = (N_m, n_syllables)
    merged_usages_all : np.array
        numpy array format of the df_usage DataFrame.
    num_groups : int
        Number of unique groups
    n_per_group : list
        list of value counts for recordings per group. len == num_groups.
    cum_group_idx : list
        list of indices for different groups. len == num_groups + 1.
    n_perm : int, optional
        Number of permuted samples to generate, by default 10000
    seed : int, optional
        Random seed used to initialize the pseudo-random number generator, by default 42

    Returns
    -------
    h_all : np.array
        Array of H-stats computed for given n_syllables; shape = (n_perms, N_s)
    real_ranks : np.array
        Array of syllable ranks, shape = (N_m, n_syllables)
    X_ties : np.array
        1-D list of tied ranks, where if value > 0, then rank is tied. len(X_ties) = n_syllables
    """

    N_m, N_s = merged_usages_all.shape

    # create random index array n_perm times
    rnd = np.random.RandomState(seed=seed)
    perm = rnd.rand(n_perm, N_m).argsort(-1)

    # get degrees of freedom
    dof = num_groups - 1

    real_ranks = np.apply_along_axis(stats.rankdata, 0, merged_usages_all)
    X_ties = df_usage.apply(get_tie_correction, 0, N_m=N_m).values
    KW_tie_correct = np.apply_along_axis(stats.tiecorrect, 0, real_ranks)

    # rank data
    perm_ranks = real_ranks[perm]

    # get square of sums for each group
    ssbn = np.zeros((n_perm, N_s))
    for i in range(num_groups):
        ssbn += perm_ranks[:, cum_group_idx[i] : cum_group_idx[i + 1]].sum(1) ** 2 / n_per_group[i]

    # h-statistic
    h_all = 12.0 / (N_m * (N_m + 1)) * ssbn - 3 * (N_m + 1)
    h_all /= KW_tie_correct
    p_vals = stats.chi2.sf(h_all, df=dof)

    # check that results agree
    p_i = np.random.randint(n_perm)
    s_i = np.random.randint(N_s)
    kr = stats.kruskal(
        *np.array_split(merged_usages_all[perm[p_i, :], s_i], np.cumsum(n_per_group[:-1]))
    )
    assert (kr.statistic == h_all[p_i, s_i]) & (
        kr.pvalue == p_vals[p_i, s_i]
    ), "manual KW is incorrect"

    return h_all, real_ranks, X_ties


def dunns_z_test_permute_within_group_pairs(
    df_usage, vc, real_ranks, X_ties, N_m, group_names, rnd, n_perm
):
    """Run Dunn's z-test statistic on combinations of all group pairs, handling
    pre- computed tied ranks.

    Parameters
    ----------
    df_usage : pandas.DataFrame
        DataFrame containing only pre-computed syllable stats.
    vc : pd.Series
        value counts of recordings in each group.
    real_ranks : np.array
        Array of syllable ranks.
    X_ties : np.array
        1-D list of tied ranks, where if value > 0, then rank is tied
    N_m : int
        Number of recordings.
    group_names : pd.Index
        Index list of unique group names.
    rnd : np.random.RandomState
        Pseudo-random number generator.
    n_perm : int
        Number of permuted samples to generate.

    Returns
    -------
    null_zs_within_group : dict
        dict of group pair keys paired with vector of Dunn's z-test statistics of the null hypothesis.
    real_zs_within_group : dict
        dict of group pair keys paired with vector of Dunn's z-test statistics
    """

    null_zs_within_group = {}
    real_zs_within_group = {}

    A = N_m * (N_m + 1.0) / 12.0

    for i_n, j_n in combinations(group_names, 2):
        is_i = df_usage.group == i_n
        is_j = df_usage.group == j_n

        n_mice = is_i.sum() + is_j.sum()

        ranks_perm = real_ranks[(is_i | is_j)][rnd.rand(n_perm, n_mice).argsort(-1)]
        diff = np.abs(
            ranks_perm[:, : is_i.sum(), :].mean(1) - ranks_perm[:, is_i.sum() :, :].mean(1)
        )
        B = 1.0 / vc.loc[i_n] + 1.0 / vc.loc[j_n]

        # also do for real data
        group_ranks = real_ranks[(is_i | is_j)]
        real_diff = np.abs(
            group_ranks[: is_i.sum(), :].mean(0) - group_ranks[is_i.sum() :, :].mean(0)
        )

        # add to dict
        pair = (i_n, j_n)
        null_zs_within_group[pair] = diff / np.sqrt((A - X_ties) * B)
        real_zs_within_group[pair] = real_diff / np.sqrt((A - X_ties) * B)

    return null_zs_within_group, real_zs_within_group


def compute_pvalues_for_group_pairs(
    real_zs_within_group,
    null_zs,
    df_k_real,
    group_names,
    n_perm=10000,
    thresh=0.05,
    mc_method="fdr_bh",
):
    """Adjust the p-values from Dunn's z-test statistics and computes the
    resulting significant syllables with the adjusted p-values.

    Parameters
    ----------
    real_zs_within_group : dict
        dict of group pair keys paired with vector of Dunn's z-test statistics
    null_zs : dict
        dict of group pair keys paired with vector of Dunn's z-test statistics of the null hypothesis.
    df_k_real : pandas.DataFrame
        DataFrame of KW test results.
    group_names : pd.Index
        Index list of unique group names.
    n_perm : int, optional
        Number of permuted samples to generate, by default 10000
    thresh : float, optional
        Alpha threshold to consider syllable significant, by default 0.05
    mc_method : str, optional
        Multiple Corrections method to use, by default "fdr_bh"
    verbose : bool, optional
        indicates whether to print out the significant syllable results, by default False

    Returns
    -------
    df_pval_corrected : pandas.DataFrame
        DataFrame containing Dunn's test results with corrected p-values.
    significant_syllables : list
        List of corrected KW significant syllables (syllables with p-values < thresh).
    """

    # do empirical p-val calculation for all group permutation

    p_vals_allperm = {}
    for pair in combinations(group_names, 2):
        p_vals_allperm[pair] = ((null_zs[pair] > real_zs_within_group[pair]).sum(0) + 1) / n_perm

    # summarize into df
    df_pval = pd.DataFrame(p_vals_allperm)

    def correct_p(x):
        return multipletests(x, alpha=thresh, method=mc_method)[1]

    df_pval_corrected = df_pval.apply(correct_p, axis=1, result_type="broadcast")

    return df_pval_corrected, ((df_pval_corrected[df_k_real.is_sig] < thresh).sum(0))


def run_kruskal(
    stats_df,
    statistic="frequency",
    n_perm=10000,
    seed=42,
    thresh=0.05,
    mc_method="fdr_bh",
):
    """Run Kruskal-Wallis test on syllable usage data.

    Parameters
    ----------
    stats_df : pandas.DataFrame
        DataFrame containing syllable usage data.
    statistic : str, optional
        Statistic to use for KW test, by default 'frequency'
    n_perm : int, optional
        Number of permutations to run, by default 10000
    seed : int, optional
        Random seed, by default 42
    thresh : float, optional
        Alpha threshold to consider syllable significant, by default 0.05
    mc_method : str, optional
        Multiple Corrections method to use, by default "fdr_bh"

    Returns
    -------
    df_k_real : pandas.DataFrame
        DataFrame containing KW test results.
    df_pval_corrected : pandas.DataFrame
        DataFrame containing Dunn's test results with corrected p-values.
    significant_syllables : list
        List of corrected KW significant syllables (syllables with p-values < thresh).
    """
    rnd = np.random.RandomState(seed=seed)
    # get grouped mean data
    grouped_data = (
        stats_df.pivot_table(index=["group", "name"], columns="syllable", values=statistic)
        .replace(np.nan, 0)
        .reset_index()
    )
    # compute KW constants
    vc = grouped_data.group.value_counts().loc[grouped_data.group.unique()]
    n_per_group = vc.values
    group_names = vc.index

    cum_group_idx = np.insert(np.cumsum(n_per_group), 0, 0)
    num_groups = len(group_names)

    # get all syllable usage data
    df_only_stats = grouped_data.drop(["group", "name"], axis=1)
    syllable_data = grouped_data.drop(["group", "name"], axis=1).values

    N_m, N_s = syllable_data.shape
    # Run KW and return H-stats
    h_all, real_ranks, X_ties = run_manual_KW_test(
        df_usage=df_only_stats,
        merged_usages_all=syllable_data,
        num_groups=num_groups,
        n_per_group=n_per_group,
        cum_group_idx=cum_group_idx,
        n_perm=n_perm,
        seed=seed,
    )

    # find the real k_real
    df_k_real = pd.DataFrame(
        [
            stats.kruskal(*np.array_split(syllable_data[:, s_i], np.cumsum(n_per_group[:-1])))
            for s_i in range(N_s)
        ]
    )

    # multiple test correction
    df_k_real["p_adj"] = multipletests(
        ((h_all > df_k_real.statistic.values).sum(0) + 1) / n_perm,
        alpha=thresh,
        method=mc_method,
    )[1]

    # return significant syllables based on the threshold
    df_k_real["is_sig"] = df_k_real["p_adj"] <= thresh

    # Run Dunn's z-test statistics
    (
        null_zs_within_group,
        real_zs_within_group,
    ) = dunns_z_test_permute_within_group_pairs(
        grouped_data, vc, real_ranks, X_ties, N_m, group_names, rnd, n_perm
    )

    # Compute p-values from Dunn's z-score statistics
    df_pair_corrected_pvalues, _ = compute_pvalues_for_group_pairs(
        real_zs_within_group,
        null_zs_within_group,
        df_k_real,
        group_names,
        n_perm,
        thresh,
        mc_method,
    )

    # combine Dunn's test results into single DataFrame
    df_z = pd.DataFrame(real_zs_within_group)
    df_z.index = df_z.index.set_names("syllable")
    dunn_results_df = df_z.reset_index().melt(id_vars=[("syllable", "")])
    dunn_results_df.rename(columns={"variable_0": "group1", "variable_1": "group2"}, inplace=True)

    # Get intersecting significant syllables between
    intersect_sig_syllables = {}
    for pair in df_pair_corrected_pvalues.columns.tolist():
        intersect_sig_syllables[pair] = np.where(
            (df_pair_corrected_pvalues[pair] < thresh) & (df_k_real.is_sig)
        )[0]

    return df_k_real, dunn_results_df, intersect_sig_syllables


# frequency plot stuff
def sort_syllables_by_stat_difference(stats_df, ctrl_group, exp_group, stat="frequency"):
    """Sort syllables by the difference in the stat between the control and
    experimental group.

    Parameters
    ----------
    stats_df : pandas.DataFrame
        the complete dataframe that contains kinematic data for each frame
    ctrl_group : str
        the name of the control group
    exp_group : str
        the name of the experimental group
    stat : str, optional
        the statistic to use for finding the syllable differences between two groups, by default 'frequency'

    Returns
    -------
    list
        ordering list of syllables based on the difference in the stat between the control and experimental group
    """

    # Prepare DataFrame
    mutation_df = (
        stats_df.drop(
            [
                col
                for col, dtype in stats_df.dtypes.items()
                if (dtype == "object" and col not in ["group", "syllable"])
            ],
            axis=1,
        )
        .groupby(["group", "syllable"])
        .mean()
    )

    # Get groups to measure mutation by
    control_df = mutation_df.loc[ctrl_group]
    exp_df = mutation_df.loc[exp_group]

    # compute mean difference at each syll frequency and reorder based on difference
    ordering = (exp_df[stat] - control_df[stat]).sort_values(ascending=False).index

    return list(ordering)


def sort_syllables_by_stat(stats_df, stat="frequency"):
    """Sort sylllabes by the stat and return the ordering and label mapping.

    Parameters
    ----------
    stats_df : pandas.DataFrame
        the stats dataframe that contains kinematic data and the syllable label for each recording and each syllable
    stat : str, optional
        the statistic to sort on, by default 'frequency'

    Returns
    -------
    ordering : list
        the list of syllables sorted by the stat
    relabel_mapping : dict
        the mapping from the syllable to the new plotting label
    """

    # stats_df frequency normalized by session
    # mean frequency by syllable don't always refect the ordering from reindexing
    # use the syllable label as ordering instead
    if stat == "frequency":
        ordering = sorted(stats_df.syllable.unique())
    else:
        ordering = (
            stats_df.drop(
                [col for col, dtype in stats_df.dtypes.items() if dtype == "object"],
                axis=1,
            )
            .groupby("syllable")
            .mean()
            .sort_values(by=stat, ascending=False)
            .index
        )

    # Get sorted ordering
    ordering = list(ordering)

    # Get order mapping
    relabel_mapping = {o: i for i, o in enumerate(ordering)}

    return ordering, relabel_mapping


def _validate_and_order_syll_stats_params(
    complete_df,
    stat="frequency",
    order="stat",
    groups=None,
    ctrl_group=None,
    exp_group=None,
    colors=None,
    figsize=(10, 5),
):
    if not isinstance(figsize, (tuple, list)):
        print(
            "Invalid figsize. Input a integer-tuple or list of len(figsize) = 2. Setting figsize to (10, 5)"
        )
        figsize = (10, 5)

    unique_groups = complete_df["group"].unique()

    if groups is None or len(groups) == 0:
        groups = unique_groups
    elif isinstance(groups, str):
        groups = [groups]

    if isinstance(groups, (list, tuple, np.ndarray)):
        diff = set(groups) - set(unique_groups)
        if len(diff) > 0:
            groups = unique_groups

    if stat.lower() not in complete_df.columns:
        raise ValueError(
            f"Invalid stat entered: {stat}. Must be a column in the supplied dataframe."
        )

    if order == "stat":
        ordering, _ = sort_syllables_by_stat(complete_df, stat=stat)
    elif order == "diff":
        if (
            ctrl_group is None
            or exp_group is None
            or not np.all(np.isin([ctrl_group, exp_group], groups))
        ):
            raise ValueError(
                f"Attempting to sort by {stat} differences, but {ctrl_group} or {exp_group} not in {groups}."
            )
        ordering = sort_syllables_by_stat_difference(complete_df, ctrl_group, exp_group, stat=stat)
    if colors is None:
        colors = []
    if len(colors) == 0 or len(colors) != len(groups):
        colors = sns.color_palette(n_colors=len(groups))

    return np.array(ordering), groups, colors, figsize


def save_analysis_figure(fig, plot_name, project_dir, model_name, save_dir):
    """Save an analysis figure.

    The figure is saved as both a .png and .pdf, either to `save_dir` if it is
    provided, or else to `project_dir/model_name/figures`.
    """
    if save_dir is None:
        save_dir = os.path.join(project_dir, model_name, "figures")
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, plot_name)
    fig.savefig(save_path + ".png", dpi=300)
    fig.savefig(save_path + ".pdf", dpi=300)
    print(f"Saved figure to {save_path}.png")


def plot_syll_stats_with_sem(
    stats_df,
    project_dir,
    model_name,
    save_dir=None,
    plot_sig=True,
    thresh=0.05,
    stat="frequency",
    order="stat",
    groups=None,
    ctrl_group=None,
    exp_group=None,
    colors=None,
    join=False,
    figsize=(8, 4),
):
    """Plot syllable statistics with standard error of the mean.

    Parameters
    ----------
    stats_df : pandas.DataFrame
        the dataframe that contains kinematic data and the syllable label
    project_dir : str
        the project directory
    model_name : str
        the model directory name
    save_dir : str
        the path to save the analysis plots
    plot_sig : bool, optional
        whether to plot the significant syllables, by default True
    thresh : float, optional
        the threshold for significance, by default 0.05
    stat : str, optional
        the statistic to plot, by default 'frequency'
    order : str, optional
        the ordering of the syllables, by default 'stat'
    groups : list, optional
        the list of groups to plot, by default None
    ctrl_group : str, optional
        the control group, by default None
    exp_group : str, optional
        the experimental group, by default None
    colors : list, optional
        the list of colors to use for each group, by default None
    join : bool, optional
        whether to join the points with a line, by default False
    figsize : tuple, optional
        the figure size, by default (8, 4)

    Returns
    -------
    fig : matplotlib.figure.Figure
        the figure object
    legend : matplotlib.legend.Legend
        the legend object
    """

    # get significant syllables
    sig_sylls = None
    if groups is None:
        groups = stats_df["group"].unique()

    if plot_sig and len(stats_df["group"].unique()) > 1:
        # run kruskal wallis and dunn's test
        _, _, sig_pairs = run_kruskal(stats_df, statistic=stat, thresh=thresh)
        # plot significant syllables for control and experimental group when user specify something
        if ctrl_group in groups and exp_group in groups:
            # check if the group pair is in the sig pairs dict
            if (ctrl_group, exp_group) in sig_pairs.keys():
                sig_sylls = sig_pairs.get((ctrl_group, exp_group))
            # flip the order of the groups
            else:
                sig_sylls = sig_pairs.get((exp_group, ctrl_group))
        else:
            # plot everything if no group pair is specified
            sig_sylls = sig_pairs

    xlabel = f"Syllables sorted by {stat}"
    if order == "diff":
        xlabel += " difference"
    ordering, groups, colors, figsize = _validate_and_order_syll_stats_params(
        stats_df,
        stat=stat,
        order=order,
        groups=groups,
        ctrl_group=ctrl_group,
        exp_group=exp_group,
        colors=colors,
        figsize=figsize,
    )

    fig, ax = plt.subplots(1, 1, figsize=figsize)

    # plot each group's stat data separately, computes groupwise SEM, and orders data based on the stat/ordering parameters
    hue = "group" if groups is not None else None
    ax = sns.pointplot(
        data=stats_df,
        x="syllable",
        y=stat,
        hue=hue,
        order=ordering,
        errorbar=("ci", 68),
        ax=ax,
        hue_order=groups,
        palette=colors,
    )

    # where some data has already been plotted to ax
    handles, labels = ax.get_legend_handles_labels()

    # add syllable labels if they exist
    syll_names = get_syllable_names(project_dir, model_name, ordering)
    plt.xticks(range(len(syll_names)), syll_names, rotation=90)

    # if a list of significant syllables is given, mark the syllables above the x-axis
    if sig_sylls is not None:
        init_y = -0.05
        # plot all sig syllables when no reasonable control and experimental group is specified
        if isinstance(sig_sylls, dict):
            for key in sig_sylls.keys():
                markings = []
                for s in sig_sylls[key]:
                    markings.append(np.where(ordering == s)[0])
                if len(markings) > 0:
                    markings = np.concatenate(markings)
                    plt.scatter(markings, [init_y] * len(markings), color="r", marker="*")
                    plt.text(
                        plt.xlim()[1],
                        init_y,
                        f"{key[0]} vs. {key[1]} - Total {len(sig_sylls[key])} S.S.",
                    )
                    init_y += -0.05
                else:
                    print("No significant syllables found.")
        else:
            markings = []
            for s in sig_sylls:
                if s in ordering:
                    markings.append(np.where(ordering == s)[0])
                else:
                    continue
            if len(markings) > 0:
                markings = np.concatenate(markings)
                plt.scatter(markings, [-0.05] * len(markings), color="r", marker="*")
            else:
                print("No significant syllables found.")

        # manually define a new patch
        patch = Line2D(
            [],
            [],
            color="red",
            marker="*",
            markersize=9,
            label="Significant Syllable",
        )
        handles.append(patch)

    # add legend and axis labels
    legend = ax.legend(handles=handles, frameon=False, bbox_to_anchor=(1, 1))
    plt.xlabel(xlabel, fontsize=12)
    sns.despine()

    # save the figure
    plot_name = f"{stat}_{order}_stats"
    save_analysis_figure(fig, plot_name, project_dir, model_name, save_dir)
    return fig, legend


# transition matrix
def get_transitions(label_sequence):
    """Get the syllable transitions and their locations.

    Parameters
    ----------
    label_sequence : np.ndarray
        the sequence of syllable labels for a recording

    Returns
    -------
    transitions : np.ndarray
        the sequence of syllable transitions
    locs : np.ndarray
        the locations of the syllable transitions
    """

    arr = deepcopy(label_sequence)

    # get syllable transition locations
    locs = np.where(arr[1:] != arr[:-1])[0] + 1
    transitions = arr[locs]

    return transitions, locs


def n_gram_transition_matrix(labels, n=2, max_label=99):
    """The transition matrix for n-grams.

    Parameters
    ----------
    labels : list or np.ndarray
        recording state lists
    n : int, optional
        the number of successive states in the sequence, by default 2
    max_label : int, optional
        the maximum number of the syllable labels to include, by default 99

    Returns
    -------
    trans_mat : np.ndarray
        the transition matrices for the n-grams
    """
    trans_mat = np.zeros((max_label,) * n, dtype="float")
    for loc in sliding_window(n, labels):
        if any(l >= max_label for l in loc):
            continue
        trans_mat[loc] += 1
    return trans_mat


def normalize_transition_matrix(init_matrix, normalize):
    """Normalize the transition matrices.

    Parameters
    ----------
    init_matrix : numpy.ndarray
        the initial transition matrix to be normalized
    normalize : str
        the method to normalize the transition matrix

    Returns
    -------
    init_matrix : numpy.ndarray
        the trnasition matrix normalized by the method specified
    """
    if normalize is None or normalize not in ("bigram", "rows", "columns"):
        return init_matrix
    if normalize == "bigram":
        init_matrix /= init_matrix.sum()
    elif normalize == "rows":
        init_matrix /= init_matrix.sum(axis=1, keepdims=True)
    elif normalize == "columns":
        init_matrix /= init_matrix.sum(axis=0, keepdims=True)

    return init_matrix


def get_transition_matrix(
    labels,
    max_syllable=100,
    normalize="bigram",
    smoothing=0.0,
    combine=False,
    disable_output=False,
) -> list:
    """Compute the transition matrix for the syllable labels.

    Parameters
    ----------
    labels : list or np.ndarray
        syllable labels per recording
    max_syllable : int, optional
        the maximum number of syllables to include, by default 100
    normalize : str, optional
        the method to normalize the transition matrix, by default 'bigram'
    smoothing : float, optional
        the smoothing value (pseudo count) to add to the transition matrix, by default 0.0
    combine : bool, optional
        whether to combine the transition matrices for all the recordings, by default False
    disable_output : bool, optional
        whether to disable the progress bar, by default False

    Returns
    -------
    all_mats : list
        the list of transition matrices for each recording
    """
    if not isinstance(labels[0], (list, np.ndarray, pd.Series)):
        labels = [labels]

    # Compute a singular transition matrix
    if combine:
        init_matrix = []

        for v in labels:
            # Get syllable transitions
            transitions = get_transitions(v)[0]

            trans_mat = n_gram_transition_matrix(transitions, n=2, max_label=max_syllable)
            init_matrix.append(trans_mat)

        init_matrix = np.sum(init_matrix, axis=0) + smoothing
        all_mats = normalize_transition_matrix(init_matrix, normalize)
    else:
        # Compute a transition matrix for each recording label list
        all_mats = []
        for v in labels:
            # Get syllable transitions
            transitions = get_transitions(v)[0]

            trans_mat = (
                n_gram_transition_matrix(transitions, n=2, max_label=max_syllable) + smoothing
            )

            # Normalize matrix
            init_matrix = normalize_transition_matrix(trans_mat, normalize)
            all_mats.append(init_matrix)

    return all_mats


def get_group_trans_mats(labels, label_group, group, syll_include, normalize="bigram"):
    """Get the transition matrices for each group.

    Parameters
    ----------
    labels : list or np.ndarray
        recording state lists
    label_group : list or np.ndarray
        the group labels for each recording
    group : list or np.ndarray
        the groups in the project
    max_sylls : int
        the maximum number of syllables to include
    normalize : str, optional
        the method to normalize the transition matrix, by default 'bigram'

    Returns
    -------
    trans_mats : list
        the list of transition matrices for each group
    frequencies : list
        the list of syllable frequencies for each group
    """
    trans_mats = []
    frequencies = []

    # Computing transition matrices for each given group
    for plt_group in group:
        # list of syll labels in recordings in the group
        use_labels = [lbl for lbl, grp in zip(labels, label_group) if grp == plt_group]
        # find stack np array shape
        row_num = len(use_labels)
        max_len = max([len(lbl) for lbl in use_labels])
        # Get recordings to include in trans_mat
        # subset only syllable included
        trans_mats.append(
            get_transition_matrix(use_labels, normalize=normalize, combine=True)[syll_include, :][
                :, syll_include
            ]
        )

        # Getting frequency information for node scaling
        group_frequencies = get_frequencies(use_labels)[syll_include]

        frequencies.append(group_frequencies)
    return trans_mats, frequencies


def visualize_transition_bigram(
    project_dir,
    model_name,
    group,
    trans_mats,
    syll_include,
    save_dir=None,
    normalize="bigram",
    figsize=(12, 6),
    show_syllable_names=True,
):
    """Visualize the transition matrices for each group.

    Parameters
    ----------
    group : list or np.ndarray
        the groups in the project
    trans_mats : list
        the list of transition matrices for each group
    normalize : str, optional
        the method to normalize the transition matrix, by default 'bigram'
    figsize : tuple, optional
        the figure size, by default (12,6)
    show_syllable_names : bool, optional
        whether to show just syllable indexes (False) or syllable indexes and
        names (True)
    """

    # syllable info path
    syll_info_path = os.path.join(project_dir, model_name, "syll_info.csv")
    # initialize syllable names
    syll_names = [f"{ix}" for ix in syll_include]

    if show_syllable_names:
        if os.path.exists(syll_info_path):
            syll_names = get_syllable_names(project_dir, model_name, syll_include)

    # infer max_syllables
    max_syllables = trans_mats[0].shape[0]

    fig, ax = plt.subplots(1, len(group), figsize=figsize, sharex=False, sharey=True)
    title_map = dict(bigram="Bigram", columns="Incoming", rows="Outgoing")
    color_lim = max([x.max() for x in trans_mats])
    if len(group) == 1:
        axs = [ax]
    else:
        axs = ax.flat
    for i, g in enumerate(group):
        h = axs[i].imshow(
            trans_mats[i][:max_syllables, :max_syllables],
            cmap="cubehelix",
            vmax=color_lim,
        )
        if i == 0:
            axs[i].set_ylabel("Incoming syllable")
            plt.yticks(np.arange(len(syll_include)), syll_names)
        cb = fig.colorbar(h, ax=axs[i], fraction=0.046, pad=0.04)
        cb.set_label(f"{title_map[normalize]} transition probability")
        axs[i].set_xlabel("Outgoing syllable")
        axs[i].set_title(g)
        axs[i].set_xticks(np.arange(len(syll_include)), syll_names, rotation=90)

    # save the figure
    plot_name = "transition_matrices"
    save_analysis_figure(fig, plot_name, project_dir, model_name, save_dir)


def generate_transition_matrices(project_dir, model_name, normalize="bigram", min_frequency=0.005):
    """Generate the transition matrices for each recording.

    Parameters
    ----------
    progress_paths : dict
        the dictionary of paths to the files in the analysis progress
    normalize : str, optional
        the method to normalize the transition matrix, by default 'bigram'

    Returns
    -------
    trans_mats : list
        the list of transition matrices for each group
    """
    trans_mats, usages = None, None
    # index file
    index_file = os.path.join(project_dir, "index.csv")
    if not os.path.exists(index_file):
        generate_index(project_dir, model_name, index_file)

    index_data = pd.read_csv(index_file, index_col=False)

    label_group = list(index_data.group.values)
    recordings = list(index_data.name.values)
    group = sorted(list(index_data.group.unique()))
    print("Group(s):", ", ".join(group))

    # load model reuslts
    results_dict = load_results(project_dir, model_name)

    # filter out syllables by freqency
    model_labels = [results_dict[recording]["syllable"] for recording in recordings]
    frequencies = get_frequencies(model_labels)
    syll_include = np.where(frequencies > min_frequency)[0]

    trans_mats, usages = get_group_trans_mats(
        model_labels,
        label_group,
        group,
        syll_include=syll_include,
        normalize=normalize,
    )
    return trans_mats, usages, group, syll_include


def plot_transition_graph_group(
    project_dir,
    model_name,
    groups,
    trans_mats,
    usages,
    syll_include,
    save_dir=None,
    layout="circular",
    node_scaling=2000,
    show_syllable_names=False,
):
    """Plot the transition graph for each group.

    Parameters
    ----------
    groups : list
        the list of groups to plot
    trans_mats : list
        the list of transition matrices for each group
    usages : list
        the list of syllable usage for each group
    layout : str, optional
        the layout of the graph, by default 'circular'
    node_scaling : int, optional
        the scaling factor for the node size, by default 2000,
    show_syllable_names : bool, optional
        whether to show just syllable indexes (False) or syllable indexes and
        names (True)
    """
    if show_syllable_names:
        syll_names = get_syllable_names(project_dir, model_name, syll_include)
    else:
        syll_names = [f"{ix}" for ix in syll_include]

    n_row = ceil(len(groups) / 2)
    fig, all_axes = plt.subplots(n_row, 2, figsize=(20, 10 * n_row))
    ax = all_axes.flat

    for i in range(len(groups)):
        G = nx.from_numpy_array(trans_mats[i] * 100)
        widths = nx.get_edge_attributes(G, "weight")
        if layout == "circular":
            pos = nx.circular_layout(G)
        else:
            pos = nx.spring_layout(G)
        # get node list
        nodelist = G.nodes()
        # normalize the usage values
        sum_usages = sum(usages[i])
        normalized_usages = np.array([u / sum_usages for u in usages[i]]) * node_scaling + 1000
        nx.draw_networkx_nodes(
            G,
            pos,
            nodelist=nodelist,
            node_size=normalized_usages,
            node_color="white",
            edgecolors="red",
            ax=ax[i],
        )
        nx.draw_networkx_edges(
            G,
            pos,
            edgelist=widths.keys(),
            width=list(widths.values()),
            edge_color="black",
            ax=ax[i],
            alpha=0.6,
        )
        nx.draw_networkx_labels(
            G,
            pos=pos,
            labels=dict(zip(nodelist, syll_names)),
            font_color="black",
            ax=ax[i],
        )
        ax[i].set_title(groups[i])
    # turn off the axis spines
    for sub_ax in ax:
        sub_ax.axis("off")

    # save the figure
    plot_name = "transition_graphs"
    save_analysis_figure(fig, plot_name, project_dir, model_name, save_dir)


def plot_transition_graph_difference(
    project_dir,
    model_name,
    groups,
    trans_mats,
    usages,
    syll_include,
    save_dir=None,
    layout="circular",
    node_scaling=3000,
    show_syllable_names=False,
):
    """Plot the difference of transition graph between groups.

    Parameters
    ----------
    groups : list
        the list of groups to plot
    trans_mats : list
        the list of transition matrices for each group
    usages : list
        the list of syllable usage for each group
    layout : str, optional
        the layout of the graph, by default 'circular'
    node_scaling : int, optional
        the scaling factor for the node size, by default 3000
    show_syllable_names : bool, optional
        whether to show just syllable indexes (False) or syllable indexes and
        names (True)
    """
    if show_syllable_names:
        syll_names = get_syllable_names(project_dir, model_name, syll_include)
    else:
        syll_names = [f"{ix}" for ix in syll_include]

    # find combinations
    group_combinations = list(combinations(groups, 2))

    # create group index dict
    group_idx_dict = {group: idx for idx, group in enumerate(groups)}

    # Figure out the number of rows for the plot
    n_row = ceil(len(group_combinations) / 2)
    fig, all_axes = plt.subplots(n_row, 2, figsize=(16, 8 * n_row))
    ax = all_axes.flat

    for i, pair in enumerate(group_combinations):
        left_ind = group_idx_dict[pair[0]]
        right_ind = group_idx_dict[pair[1]]
        # left tm minus right tm
        tm_diff = trans_mats[left_ind] - trans_mats[right_ind]
        # left usage minus right usage
        usages_diff = np.array(list(usages[left_ind])) - np.array(list(usages[right_ind]))
        normlized_usg_abs_diff = (
            np.abs(usages_diff) / np.abs(usages_diff).sum()
        ) * node_scaling + 500

        G = nx.from_numpy_array(tm_diff * 1000)
        if layout == "circular":
            pos = nx.circular_layout(G)
        else:
            G_for_spring = nx.from_numpy_array(np.mean(trans_mats, axis=0))
            pos = nx.spring_layout(G_for_spring, iterations=500)

        nodelist = G.nodes()
        widths = nx.get_edge_attributes(G, "weight")

        nx.draw_networkx_nodes(
            G,
            pos,
            nodelist=nodelist,
            node_size=normlized_usg_abs_diff,
            node_color="white",
            edgecolors=["blue" if u > 0 else "red" for u in usages_diff],
            ax=ax[i],
        )
        nx.draw_networkx_edges(
            G,
            pos,
            edgelist=widths.keys(),
            width=np.abs(list(widths.values())),
            edge_color=["blue" if u > 0 else "red" for u in widths.values()],
            ax=ax[i],
            alpha=0.6,
        )
        nx.draw_networkx_labels(
            G,
            pos=pos,
            labels=dict(zip(nodelist, syll_names)),
            font_color="black",
            ax=ax[i],
        )
        ax[i].set_title(pair[0] + " - " + pair[1])

    # turn off the axis spines
    for sub_ax in ax:
        sub_ax.axis("off")
    # add legend
    legend_elements = [
        Line2D([0], [0], color="r", lw=2, label=f"Up-regulated transistion"),
        Line2D([0], [0], color="b", lw=2, label=f"Down-regulated transistion"),
        Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            label=f"Up-regulated usage",
            markerfacecolor="w",
            markeredgecolor="r",
            markersize=10,
        ),
        Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            label=f"Down-regulated usage",
            markerfacecolor="w",
            markeredgecolor="b",
            markersize=10,
        ),
    ]
    plt.legend(handles=legend_elements, loc="upper left", borderaxespad=0)

    # save the figure
    plot_name = "transition_graphs_diff"
    save_analysis_figure(fig, plot_name, project_dir, model_name, save_dir)


--- File: keypoint_moseq/_version.py ---
# This file helps to compute a version number in source trees obtained from
# git-archive tarball (such as those provided by githubs download-from-tag
# feature). Distribution tarballs (built by setup.py sdist) and build
# directories (produced by setup.py build) will contain a much shorter file
# that just contains the computed version number.

# This file is released into the public domain.
# Generated by versioneer-0.28
# https://github.com/python-versioneer/python-versioneer
"""Git implementation of _version.py."""

import errno
import os
import re
import subprocess
import sys
from typing import Callable, Dict
import functools


def get_keywords():
    """Get the keywords needed to look up the version information."""
    # these strings will be replaced by git during git-archive.
    # setup.py/versioneer.py will grep for the variable names, so they must
    # each be defined on a line of their own. _version.py will just call
    # get_keywords().
    git_refnames = "$Format:%d$"
    git_full = "$Format:%H$"
    git_date = "$Format:%ci$"
    keywords = {"refnames": git_refnames, "full": git_full, "date": git_date}
    return keywords


class VersioneerConfig:
    """Container for Versioneer configuration parameters."""


def get_config():
    """Create, populate and return the VersioneerConfig() object."""
    # these strings are filled in when 'setup.py versioneer' creates
    # _version.py
    cfg = VersioneerConfig()
    cfg.VCS = "git"
    cfg.style = "pep440"
    cfg.tag_prefix = ""
    cfg.parentdir_prefix = ""
    cfg.versionfile_source = "keypoint_moseq/_version.py"
    cfg.verbose = False
    return cfg


class NotThisMethod(Exception):
    """Exception raised if a method is not valid for the current scenario."""


LONG_VERSION_PY: Dict[str, str] = {}
HANDLERS: Dict[str, Dict[str, Callable]] = {}


def register_vcs_handler(vcs, method):  # decorator
    """Create decorator to mark a method as the handler of a VCS."""

    def decorate(f):
        """Store f in HANDLERS[vcs][method]."""
        if vcs not in HANDLERS:
            HANDLERS[vcs] = {}
        HANDLERS[vcs][method] = f
        return f

    return decorate


def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):
    """Call the given command(s)."""
    assert isinstance(commands, list)
    process = None

    popen_kwargs = {}
    if sys.platform == "win32":
        # This hides the console window if pythonw.exe is used
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        popen_kwargs["startupinfo"] = startupinfo

    for command in commands:
        try:
            dispcmd = str([command] + args)
            # remember shell=False, so use git.cmd on windows, not just git
            process = subprocess.Popen(
                [command] + args,
                cwd=cwd,
                env=env,
                stdout=subprocess.PIPE,
                stderr=(subprocess.PIPE if hide_stderr else None),
                **popen_kwargs,
            )
            break
        except OSError:
            e = sys.exc_info()[1]
            if e.errno == errno.ENOENT:
                continue
            if verbose:
                print("unable to run %s" % dispcmd)
                print(e)
            return None, None
    else:
        if verbose:
            print("unable to find command, tried %s" % (commands,))
        return None, None
    stdout = process.communicate()[0].strip().decode()
    if process.returncode != 0:
        if verbose:
            print("unable to run %s (error)" % dispcmd)
            print("stdout was %s" % stdout)
        return None, process.returncode
    return stdout, process.returncode


def versions_from_parentdir(parentdir_prefix, root, verbose):
    """Try to determine the version from the parent directory name.

    Source tarballs conventionally unpack into a directory that includes both
    the project name and a version string. We will also support searching up
    two directory levels for an appropriately named parent directory
    """
    rootdirs = []

    for _ in range(3):
        dirname = os.path.basename(root)
        if dirname.startswith(parentdir_prefix):
            return {
                "version": dirname[len(parentdir_prefix) :],
                "full-revisionid": None,
                "dirty": False,
                "error": None,
                "date": None,
            }
        rootdirs.append(root)
        root = os.path.dirname(root)  # up a level

    if verbose:
        print(
            "Tried directories %s but none started with prefix %s"
            % (str(rootdirs), parentdir_prefix)
        )
    raise NotThisMethod("rootdir doesn't start with parentdir_prefix")


@register_vcs_handler("git", "get_keywords")
def git_get_keywords(versionfile_abs):
    """Extract version information from the given file."""
    # the code embedded in _version.py can just fetch the value of these
    # keywords. When used from setup.py, we don't want to import _version.py,
    # so we do it with a regexp instead. This function is not used from
    # _version.py.
    keywords = {}
    try:
        with open(versionfile_abs, "r") as fobj:
            for line in fobj:
                if line.strip().startswith("git_refnames ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["refnames"] = mo.group(1)
                if line.strip().startswith("git_full ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["full"] = mo.group(1)
                if line.strip().startswith("git_date ="):
                    mo = re.search(r'=\s*"(.*)"', line)
                    if mo:
                        keywords["date"] = mo.group(1)
    except OSError:
        pass
    return keywords


@register_vcs_handler("git", "keywords")
def git_versions_from_keywords(keywords, tag_prefix, verbose):
    """Get version information from git keywords."""
    if "refnames" not in keywords:
        raise NotThisMethod("Short version file found")
    date = keywords.get("date")
    if date is not None:
        # Use only the last line.  Previous lines may contain GPG signature
        # information.
        date = date.splitlines()[-1]

        # git-2.2.0 added "%cI", which expands to an ISO-8601 -compliant
        # datestamp. However we prefer "%ci" (which expands to an "ISO-8601
        # -like" string, which we must then edit to make compliant), because
        # it's been around since git-1.5.3, and it's too difficult to
        # discover which version we're using, or to work around using an
        # older one.
        date = date.strip().replace(" ", "T", 1).replace(" ", "", 1)
    refnames = keywords["refnames"].strip()
    if refnames.startswith("$Format"):
        if verbose:
            print("keywords are unexpanded, not using")
        raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
    refs = {r.strip() for r in refnames.strip("()").split(",")}
    # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
    # just "foo-1.0". If we see a "tag: " prefix, prefer those.
    TAG = "tag: "
    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like "release" and
        # "stabilization", as well as "HEAD" and "master".
        tags = {r for r in refs if re.search(r"\d", r)}
        if verbose:
            print("discarding '%s', no digits" % ",".join(refs - tags))
    if verbose:
        print("likely tags: %s" % ",".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. "2.0" over "2.0rc1"
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix) :]
            # Filter out refs that exactly match prefix or that don't start
            # with a number once the prefix is stripped (mostly a concern
            # when prefix is '')
            if not re.match(r"\d", r):
                continue
            if verbose:
                print("picking %s" % r)
            return {
                "version": r,
                "full-revisionid": keywords["full"].strip(),
                "dirty": False,
                "error": None,
                "date": date,
            }
    # no suitable tags, so version is "0+unknown", but full hex is still there
    if verbose:
        print("no suitable tags, using unknown + full revision id")
    return {
        "version": "0+unknown",
        "full-revisionid": keywords["full"].strip(),
        "dirty": False,
        "error": "no suitable tags",
        "date": None,
    }


@register_vcs_handler("git", "pieces_from_vcs")
def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):
    """Get version from 'git describe' in the root of the source tree.

    This only gets called if the git-archive 'subst' keywords were *not*
    expanded, and _version.py hasn't already been rewritten with a short
    version string, meaning we're inside a checked out source tree.
    """
    GITS = ["git"]
    if sys.platform == "win32":
        GITS = ["git.cmd", "git.exe"]

    # GIT_DIR can interfere with correct operation of Versioneer.
    # It may be intended to be passed to the Versioneer-versioned project,
    # but that should not change where we get our version from.
    env = os.environ.copy()
    env.pop("GIT_DIR", None)
    runner = functools.partial(runner, env=env)

    _, rc = runner(GITS, ["rev-parse", "--git-dir"], cwd=root, hide_stderr=not verbose)
    if rc != 0:
        if verbose:
            print("Directory %s not under git control" % root)
        raise NotThisMethod("'git rev-parse --git-dir' returned error")

    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]
    # if there isn't one, this yields HEX[-dirty] (no NUM)
    describe_out, rc = runner(
        GITS,
        [
            "describe",
            "--tags",
            "--dirty",
            "--always",
            "--long",
            "--match",
            f"{tag_prefix}[[:digit:]]*",
        ],
        cwd=root,
    )
    # --long was added in git-1.5.5
    if describe_out is None:
        raise NotThisMethod("'git describe' failed")
    describe_out = describe_out.strip()
    full_out, rc = runner(GITS, ["rev-parse", "HEAD"], cwd=root)
    if full_out is None:
        raise NotThisMethod("'git rev-parse' failed")
    full_out = full_out.strip()

    pieces = {}
    pieces["long"] = full_out
    pieces["short"] = full_out[:7]  # maybe improved later
    pieces["error"] = None

    branch_name, rc = runner(GITS, ["rev-parse", "--abbrev-ref", "HEAD"], cwd=root)
    # --abbrev-ref was added in git-1.6.3
    if rc != 0 or branch_name is None:
        raise NotThisMethod("'git rev-parse --abbrev-ref' returned error")
    branch_name = branch_name.strip()

    if branch_name == "HEAD":
        # If we aren't exactly on a branch, pick a branch which represents
        # the current commit. If all else fails, we are on a branchless
        # commit.
        branches, rc = runner(GITS, ["branch", "--contains"], cwd=root)
        # --contains was added in git-1.5.4
        if rc != 0 or branches is None:
            raise NotThisMethod("'git branch --contains' returned error")
        branches = branches.split("\n")

        # Remove the first line if we're running detached
        if "(" in branches[0]:
            branches.pop(0)

        # Strip off the leading "* " from the list of branches.
        branches = [branch[2:] for branch in branches]
        if "master" in branches:
            branch_name = "master"
        elif not branches:
            branch_name = None
        else:
            # Pick the first branch that is returned. Good or bad.
            branch_name = branches[0]

    pieces["branch"] = branch_name

    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]
    # TAG might have hyphens.
    git_describe = describe_out

    # look for -dirty suffix
    dirty = git_describe.endswith("-dirty")
    pieces["dirty"] = dirty
    if dirty:
        git_describe = git_describe[: git_describe.rindex("-dirty")]

    # now we have TAG-NUM-gHEX or HEX

    if "-" in git_describe:
        # TAG-NUM-gHEX
        mo = re.search(r"^(.+)-(\d+)-g([0-9a-f]+)$", git_describe)
        if not mo:
            # unparsable. Maybe git-describe is misbehaving?
            pieces["error"] = "unable to parse git-describe output: '%s'" % describe_out
            return pieces

        # tag
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = "tag '%s' doesn't start with prefix '%s'"
                print(fmt % (full_tag, tag_prefix))
            pieces["error"] = "tag '%s' doesn't start with prefix '%s'" % (
                full_tag,
                tag_prefix,
            )
            return pieces
        pieces["closest-tag"] = full_tag[len(tag_prefix) :]

        # distance: number of commits since tag
        pieces["distance"] = int(mo.group(2))

        # commit: short hex revision ID
        pieces["short"] = mo.group(3)

    else:
        # HEX: no tags
        pieces["closest-tag"] = None
        out, rc = runner(GITS, ["rev-list", "HEAD", "--left-right"], cwd=root)
        pieces["distance"] = len(out.split())  # total number of commits

    # commit date: see ISO-8601 comment in git_versions_from_keywords()
    date = runner(GITS, ["show", "-s", "--format=%ci", "HEAD"], cwd=root)[0].strip()
    # Use only the last line.  Previous lines may contain GPG signature
    # information.
    date = date.splitlines()[-1]
    pieces["date"] = date.strip().replace(" ", "T", 1).replace(" ", "", 1)

    return pieces


def plus_or_dot(pieces):
    """Return a + if we don't already have one, else return a ."""
    if "+" in pieces.get("closest-tag", ""):
        return "."
    return "+"


def render_pep440(pieces):
    """Build up version string, with post-release "local version identifier".

    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you
    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty

    Exceptions:
    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += plus_or_dot(pieces)
            rendered += "%d.g%s" % (pieces["distance"], pieces["short"])
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0+untagged.%d.g%s" % (pieces["distance"], pieces["short"])
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def render_pep440_branch(pieces):
    """TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .

    The ".dev0" means not master branch. Note that .dev0 sorts backwards
    (a feature branch will appear "older" than the master branch).

    Exceptions:
    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            if pieces["branch"] != "master":
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "%d.g%s" % (pieces["distance"], pieces["short"])
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0"
        if pieces["branch"] != "master":
            rendered += ".dev0"
        rendered += "+untagged.%d.g%s" % (pieces["distance"], pieces["short"])
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def pep440_split_post(ver):
    """Split pep440 version string at the post-release segment.

    Returns the release segments before the post-release and the post-release
    version number (or -1 if no post-release segment is present).
    """
    vc = str.split(ver, ".post")
    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None


def render_pep440_pre(pieces):
    """TAG[.postN.devDISTANCE] -- No -dirty.

    Exceptions:
    1: no tags. 0.post0.devDISTANCE
    """
    if pieces["closest-tag"]:
        if pieces["distance"]:
            # update the post release segment
            tag_version, post_version = pep440_split_post(pieces["closest-tag"])
            rendered = tag_version
            if post_version is not None:
                rendered += ".post%d.dev%d" % (
                    post_version + 1,
                    pieces["distance"],
                )
            else:
                rendered += ".post0.dev%d" % (pieces["distance"])
        else:
            # no commits, use the tag as the version
            rendered = pieces["closest-tag"]
    else:
        # exception #1
        rendered = "0.post0.dev%d" % pieces["distance"]
    return rendered


def render_pep440_post(pieces):
    """TAG[.postDISTANCE[.dev0]+gHEX] .

    The ".dev0" means dirty. Note that .dev0 sorts backwards
    (a dirty tree will appear "older" than the corresponding clean one),
    but you shouldn't be releasing software with -dirty anyways.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%d" % pieces["distance"]
            if pieces["dirty"]:
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "g%s" % pieces["short"]
    else:
        # exception #1
        rendered = "0.post%d" % pieces["distance"]
        if pieces["dirty"]:
            rendered += ".dev0"
        rendered += "+g%s" % pieces["short"]
    return rendered


def render_pep440_post_branch(pieces):
    """TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The ".dev0" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%d" % pieces["distance"]
            if pieces["branch"] != "master":
                rendered += ".dev0"
            rendered += plus_or_dot(pieces)
            rendered += "g%s" % pieces["short"]
            if pieces["dirty"]:
                rendered += ".dirty"
    else:
        # exception #1
        rendered = "0.post%d" % pieces["distance"]
        if pieces["branch"] != "master":
            rendered += ".dev0"
        rendered += "+g%s" % pieces["short"]
        if pieces["dirty"]:
            rendered += ".dirty"
    return rendered


def render_pep440_old(pieces):
    """TAG[.postDISTANCE[.dev0]] .

    The ".dev0" means dirty.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"] or pieces["dirty"]:
            rendered += ".post%d" % pieces["distance"]
            if pieces["dirty"]:
                rendered += ".dev0"
    else:
        # exception #1
        rendered = "0.post%d" % pieces["distance"]
        if pieces["dirty"]:
            rendered += ".dev0"
    return rendered


def render_git_describe(pieces):
    """TAG[-DISTANCE-gHEX][-dirty].

    Like 'git describe --tags --dirty --always'.

    Exceptions:
    1: no tags. HEX[-dirty]  (note: no 'g' prefix)
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        if pieces["distance"]:
            rendered += "-%d-g%s" % (pieces["distance"], pieces["short"])
    else:
        # exception #1
        rendered = pieces["short"]
    if pieces["dirty"]:
        rendered += "-dirty"
    return rendered


def render_git_describe_long(pieces):
    """TAG-DISTANCE-gHEX[-dirty].

    Like 'git describe --tags --dirty --always -long'.
    The distance/hash is unconditional.

    Exceptions:
    1: no tags. HEX[-dirty]  (note: no 'g' prefix)
    """
    if pieces["closest-tag"]:
        rendered = pieces["closest-tag"]
        rendered += "-%d-g%s" % (pieces["distance"], pieces["short"])
    else:
        # exception #1
        rendered = pieces["short"]
    if pieces["dirty"]:
        rendered += "-dirty"
    return rendered


def render(pieces, style):
    """Render the given version pieces into the requested style."""
    if pieces["error"]:
        return {
            "version": "unknown",
            "full-revisionid": pieces.get("long"),
            "dirty": None,
            "error": pieces["error"],
            "date": None,
        }

    if not style or style == "default":
        style = "pep440"  # the default

    if style == "pep440":
        rendered = render_pep440(pieces)
    elif style == "pep440-branch":
        rendered = render_pep440_branch(pieces)
    elif style == "pep440-pre":
        rendered = render_pep440_pre(pieces)
    elif style == "pep440-post":
        rendered = render_pep440_post(pieces)
    elif style == "pep440-post-branch":
        rendered = render_pep440_post_branch(pieces)
    elif style == "pep440-old":
        rendered = render_pep440_old(pieces)
    elif style == "git-describe":
        rendered = render_git_describe(pieces)
    elif style == "git-describe-long":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError("unknown style '%s'" % style)

    return {
        "version": rendered,
        "full-revisionid": pieces["long"],
        "dirty": pieces["dirty"],
        "error": None,
        "date": pieces.get("date"),
    }


def get_versions():
    """Get version information or return default if unable to do so."""
    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have
    # __file__, we can work backwards from there to the root. Some
    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which
    # case we can only use expanded keywords.

    cfg = get_config()
    verbose = cfg.verbose

    try:
        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)
    except NotThisMethod:
        pass

    try:
        root = os.path.realpath(__file__)
        # versionfile_source is the relative path from the top of the source
        # tree (where the .git directory might live) to this file. Invert
        # this to find the root from __file__.
        for _ in cfg.versionfile_source.split("/"):
            root = os.path.dirname(root)
    except NameError:
        return {
            "version": "0+unknown",
            "full-revisionid": None,
            "dirty": None,
            "error": "unable to find root of source tree",
            "date": None,
        }

    try:
        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)
        return render(pieces, cfg.style)
    except NotThisMethod:
        pass

    try:
        if cfg.parentdir_prefix:
            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)
    except NotThisMethod:
        pass

    return {
        "version": "0+unknown",
        "full-revisionid": None,
        "dirty": None,
        "error": "unable to compute version",
        "date": None,
    }


--- File: keypoint_moseq/util.py ---
import os
import glob
import tabulate
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from textwrap import fill
import jax, jax.numpy as jnp
from scipy.ndimage import median_filter, convolve1d, gaussian_filter1d
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import pdist, squareform
from jax_moseq.models.keypoint_slds import inverse_rigid_transform
from jax_moseq.utils import get_frequencies, batch
from vidio.read import OpenCVReader

na = jnp.newaxis


def np_io(fn):
    """Converts a function involving jax arrays to one that inputs and outputs
    numpy arrays."""
    return lambda *args, **kwargs: jax.device_get(
        fn(*jax.device_put(args), **jax.device_put(kwargs))
    )


def print_dims_to_explain_variance(pca, f):
    """Print the number of principal components requred to explain a given
    fraction of  variance.

    Parameters
    ----------
    pca: sklearn.decomposition._pca.PCA, A fit PCA model
    f: float, Target variance fraction
    """
    cs = np.cumsum(pca.explained_variance_ratio_)
    if cs[-1] < f:
        print(f"All components together only explain {cs[-1]*100}% of variance.")
    else:
        print(f">={f*100}% of variance exlained by {(cs>f).nonzero()[0].min()+1} components.")


def list_files_with_exts(filepath_pattern, ext_list, recursive=True):
    """This function lists all the files matching a pattern and with a an
    extension in a list of extensions.

    Parameters
    ----------
    filepath_pattern : str or list
        A filepath pattern or a list thereof. Filepath patterns can be be a
        single file, a directory, or a path with wildcards (e.g.,
        '/path/to/dir/prefix*').

    ext_list : list of str
        A list of file extensions to search for.

    recursive : bool, default=True
        Whether to search for files recursively.

    Returns
    -------
    list
        A list of file paths.
    """
    if isinstance(filepath_pattern, list):
        matches = []
        for fp in filepath_pattern:
            matches += list_files_with_exts(fp, ext_list, recursive=recursive)
        return sorted(set(matches))

    else:
        # make sure extensions all start with "." and are lowercase
        ext_list = ["." + ext.strip(".").lower() for ext in ext_list]

        if os.path.isdir(filepath_pattern):
            filepath_pattern = os.path.join(filepath_pattern, "*")

        # find all matches (recursively)
        matches = glob.glob(filepath_pattern)
        if recursive:
            for match in list(matches):
                matches += glob.glob(os.path.join(match, "**"), recursive=True)

        # filter matches by extension
        matches = [match for match in matches if os.path.splitext(match)[1].lower() in ext_list]
        return matches


def find_matching_videos(
    keys,
    video_dir,
    as_dict=False,
    recursive=True,
    recording_name_suffix="",
    video_extension=None,
):
    """
    Find video files for a set of recording names. The filename of each video
    is assumed to be a prefix within the recording name, i.e. the recording
    name has the form `{video_name}{more_text}`. If more than one video matches
    a recording name, the longest match will be used. For example given the
    following video directory::

        video_dir
        ├─ videoname1.avi
        └─ videoname2.avi

    the videos would be matched to recording names as follows::

        >>> keys = ['videoname1blahblah','videoname2yadayada']
        >>> find_matching_videos(keys, video_dir, as_dict=True)

        {'videoname1blahblah': 'video_dir/videoname1.avi',
         'videoname2blahblah': 'video_dir/videoname2.avi'}

    A suffix can also be specified, in which case the recording name is assumed
    to have the form `{video_name}{suffix}{more_text}`.

    Parameters
    -------
    keys: iterable
        Recording names (as strings)

    video_dir: str
        Path to the video directory.

    video_extension: str, default=None
        Extension of the video files. If None, videos are assumed to have the
        one of the following extensions: "mp4", "avi", "mov"

    recursive: bool, default=True
        If True, search recursively for videos in subdirectories of
        `video_dir`.

    as_dict: bool, default=False
        Determines whether to return a dict mapping recording names to video
        paths, or a list of paths in the same order as `keys`.

    recording_name_suffix: str, default=None
        Suffix to append to the video name when searching for a match.

    Returns
    -------
    video_paths: list or dict (depending on `as_dict`)
    """

    if video_extension is None:
        extensions = [".mp4", ".avi", ".mov"]
    else:
        if video_extension[0] != ".":
            video_extension = "." + video_extension
        extensions = [video_extension]

    videos = list_files_with_exts(video_dir, extensions, recursive=recursive)
    videos_to_paths = {os.path.splitext(os.path.basename(f))[0]: f for f in videos}

    video_paths = []
    for key in keys:
        matches = [
            v
            for v in videos_to_paths
            if os.path.basename(key).startswith(v + recording_name_suffix)
        ]
        assert len(matches) > 0, fill(f"No matching videos found for {key}")

        longest_match = sorted(matches, key=lambda v: len(v))[-1]
        video_paths.append(videos_to_paths[longest_match])

    if as_dict:
        return dict(zip(keys, video_paths))
    else:
        return video_paths


def pad_along_axis(arr, pad_widths, axis=0, value=0):
    """Pad an array along a single axis.

    Parameters
    -------
    arr: ndarray, Array to be padded
    pad_widths: tuple (int,int), Amount of padding on either end
    axis: int, Axis along which to add padding
    value: float, Value of padded array elements

    Returns
    _______
    padded_arr: ndarray
    """
    pad_widths_full = [(0, 0)] * len(arr.shape)
    pad_widths_full[axis] = pad_widths
    padded_arr = np.pad(arr, pad_widths_full, constant_values=value)
    return padded_arr


def filter_angle(angles, size=9, axis=0, method="median"):
    """Perform median filtering on time-series of angles by transforming to a
    (cos,sin) representation, filtering in R^2, and then transforming back into
    angle space.

    Parameters
    -------
    angles: ndarray
        Array of angles (in radians)

    size: int, default=9
        Size of the filtering kernel

    axis: int, default=0
        Axis along which to filter

    method: str, default='median'
        Method for filtering. Options are 'median' and 'gaussian'

    Returns
    -------
    filtered_angles: ndarray
    """
    if method == "median":
        kernel = np.where(np.arange(len(angles.shape)) == axis, size, 1)
        filter = lambda x: median_filter(x, kernel)
    elif method == "gaussian":
        filter = lambda x: gaussian_filter1d(x, size, axis=axis)
    return np.arctan2(filter(np.sin(angles)), filter(np.cos(angles)))


def get_centroids_headings(
    coordinates,
    anterior_idxs,
    posterior_idxs,
    bodyparts=None,
    use_bodyparts=None,
    **kwargs,
):
    """Compute centroids and headings from keypoint coordinates.

    Parameters
    -------
    coordinates: dict
        Dictionary mapping recording names to keypoint coordinates as
        ndarrays of shape (n_frames, n_bodyparts, [2 or 3]).

    anterior_idxs: array-like of int
        Indices of anterior bodyparts (after reindexing by `use_bodyparts`
        when the latter is specified).

    posterior_idxs: array-like of int
        Indices of anterior bodyparts (after reindexing by `use_bodyparts`
        when the latter is specified).

    bodyparts: list of str, default=None
        List of bodypart names in `coordinates`. Used to reindex coordinates
        when `use_bodyparts` is specified.

    use_bodyparts: list of str, default=None
        Ordered list of bodyparts used to reindex `coordinates`.

    Returns
    -------
    centroids: dict
        Dictionary mapping recording names to centroid coordinates as ndarrays
        of shape (n_frames, [2 or 3]).

    headings: dict
        Dictionary mapping recording names to heading angles (in radians) as 1d
        arrays of shape (n_frames,).
    """
    if bodyparts is not None and use_bodyparts is not None:
        coordinates = reindex_by_bodyparts(coordinates, bodyparts, use_bodyparts)

    centroids, headings = {}, {}
    for key, coords in coordinates.items():
        coords = interpolate_keypoints(coords, np.isnan(coords).any(-1))
        centroids[key] = np.median(coords, axis=1)
        anterior_loc = coords[:, posterior_idxs].mean(1)
        posterior_loc = coords[:, anterior_idxs].mean(1)
        heading_vec = anterior_loc - posterior_loc
        headings[key] = np.arctan2(*heading_vec.T[::-1]) + np.pi

    return centroids, headings


def filter_centroids_headings(centroids, headings, filter_size=9):
    """Perform median filtering on centroids and headings.

    Parameters
    -------
    centroids: dict
        Centroids stored as a dictionary mapping recording names to ndarrays,
        of shape (n_frames, [2 or 3]).

    headings: dict
        Dictionary mapping recording names to heading angles (in radians) as 1d
        arrays of shape (n_frames,).

    filter_size: int, default=9
        Kernel size for median filtering

    Returns
    -------
    filtered_centroids: dict
    filtered_headings: dict
    """
    centroids = {k: median_filter(v, (filter_size, 1)) for k, v in centroids.items()}
    headings = {k: filter_angle(v, size=filter_size) for k, v in headings.items()}
    return centroids, headings


def get_syllable_instances(
    stateseqs,
    min_duration=3,
    pre=30,
    post=60,
    min_frequency=0,
    min_instances=0,
):
    """Map each syllable to a list of instances when it occured. Only include
    instances that meet the criteria specified by `pre`, `post`, and
    `min_duration`. Only include syllables that meet the criteria specified by
    `min_frequency` and `min_instances`.

    Parameters
    -------
    stateseqs: dict {str : 1d array}
        Dictionary mapping names to syllable sequences

    min_duration: int, default=3
        Mininum duration for inclusion of a syllable instance

    pre: int, default=30
        Syllable instances that start before this location in the state
        sequence will be excluded

    post: int, default=60
        Syllable instances that end after this location in the state sequence
        will be excluded

    min_frequency: int, default=0
        Minimum allowed frequency (across all state sequences) for inclusion of
        a syllable

    min_instances: int, default=0
        Minimum number of instances (across all state sequences) for inclusion
        of a syllable

    Returns
    -------
    syllable_instances: dict
        Dictionary mapping each syllable to a list of instances. Each instance
        is a tuple (name,start,end) representing subsequence
        `stateseqs[name][start:end]`.
    """
    num_syllables = int(max(map(max, stateseqs.values())) + 1)
    syllable_instances = [[] for syllable in range(num_syllables)]

    for key, stateseq in stateseqs.items():
        transitions = np.nonzero(stateseq[1:] != stateseq[:-1])[0] + 1
        starts = np.insert(transitions, 0, 0)
        ends = np.append(transitions, len(stateseq))
        for s, e, syllable in zip(starts, ends, stateseq[starts]):
            if e - s >= min_duration and s >= pre and s < len(stateseq) - post:
                syllable_instances[syllable].append((key, s, e))

    frequencies_filter = get_frequencies(stateseqs) >= min_frequency
    counts_filter = np.array(list(map(len, syllable_instances))) >= min_instances
    use_syllables = np.all([frequencies_filter, counts_filter], axis=0).nonzero()[0]
    return {syllable: syllable_instances[syllable] for syllable in use_syllables}


def get_edges(use_bodyparts, skeleton):
    """Represent the skeleton as a list of index-pairs.

    Parameters
    -------
    use_bodyparts: list
        Bodypart names

    skeleton: list
        Pairs of bodypart names as tuples (bodypart1,bodypart2)

    Returns
    -------
    edges: list
        Pairs of indexes representing the enties of `skeleton`
    """
    edges = []
    if len(skeleton) > 0:
        if isinstance(skeleton[0][0], int):
            edges = skeleton
        else:
            assert use_bodyparts is not None, fill(
                "If skeleton edges are specified using bodypart names, "
                "`use_bodyparts` must be specified"
            )

            for bp1, bp2 in skeleton:
                if bp1 in use_bodyparts and bp2 in use_bodyparts:
                    edges.append([use_bodyparts.index(bp1), use_bodyparts.index(bp2)])
    return edges


def reindex_by_bodyparts(data, bodyparts, use_bodyparts, axis=1):
    """Use an ordered list of bodyparts to reindex keypoint coordinates.

    Parameters
    -------
    data: dict or ndarray
        A single array of keypoint coordinates or a dict mapping from names to
        arrays of keypoint coordinates

    bodyparts: list
        Label for each keypoint represented in `data`

    use_bodyparts: list
        Ordered subset of keypoint labels

    axis: int, default=1
        The axis in `data` that represents keypoints. It is required that
        `data.shape[axis]==len(bodyparts)`.

    Returns
    -------
    reindexed_data: ndarray or dict
        Keypoint coordinates in the same form as `data` with reindexing
        applied.
    """
    ix = np.array([bodyparts.index(bp) for bp in use_bodyparts])
    if isinstance(data, np.ndarray):
        return np.take(data, ix, axis)
    else:
        return {k: np.take(v, ix, axis) for k, v in data.items()}


def get_instance_trajectories(
    syllable_instances,
    coordinates,
    pre=0,
    post=None,
    centroids=None,
    headings=None,
    filter_size=9,
):
    """Extract keypoint trajectories for a collection of syllable instances.

    If centroids and headings are provided, each trajectory is transformed into
    the ego-centric reference frame from the moment of syllable onset. When
    `post` is not None, trajectories will all terminate a fixed number of
    frames after syllable onset.

    Parameters
    -------
    syllable_instances: list
        List of syllable instances, where each instance is a tuple of the form
        (name,start,end)

    coordinates: dict
        Dictionary mapping names to coordinates, formatted as ndarrays with
        shape (num_frames, num_keypoints, d)

    pre: int, default=0
        Number of frames to include before syllable onset

    post: int, defualt=None
        Determines the length of the trajectory. When `post=None`, the
        trajectory terminates at the end of the syllable instance. Otherwise
        the trajectory terminates at a fixed number of frames after syllable
        (where the number is determined by `post`).

    centroids: dict, default=None
        Dictionary with the same keys as `coordinates` mapping each name to an
        ndarray with shape (num_frames, d)

    headings: dict, default=None
        Dictionary with the same keys as `coordinates` mapping each name to a
        1d array of heading angles in radians

    filter_size: int, default=9
        Size of median filter applied to `centroids` and `headings`

    Returns
    -------
    trajectories: list
        List or array of trajectories (a list is used when `post=None`,
        otherwise an array). Each trajectory is an array of shape
        (n_frames, n_bodyparts, [2 or 3]).
    """
    if centroids is not None and headings is not None:
        centroids, headings = filter_centroids_headings(
            centroids, headings, filter_size=filter_size
        )

    if post is None:
        trajectories = [coordinates[key][s - pre : e] for key, s, e in syllable_instances]
        if centroids is not None and headings is not None:
            trajectories = [
                np_io(inverse_rigid_transform)(x, centroids[key][s], headings[key][s])
                for x, (key, s, e) in zip(trajectories, syllable_instances)
            ]
    else:
        trajectories = np.array(
            [coordinates[key][s - pre : s + post] for key, s, e in syllable_instances]
        )
        if centroids is not None and headings is not None:
            c = np.array([centroids[key][s] for key, s, e in syllable_instances])[:, None]
            h = np.array([headings[key][s] for key, s, e in syllable_instances])[:, None]
            trajectories = np_io(inverse_rigid_transform)(trajectories, c, h)

    return trajectories


def sample_instances(
    syllable_instances,
    num_samples,
    mode="random",
    pca_samples=50000,
    pca_dim=4,
    n_neighbors=50,
    coordinates=None,
    pre=5,
    post=15,
    centroids=None,
    headings=None,
    filter_size=9,
):
    """Sample a fixed number of instances for each syllable.

    Parameters
    ----------
    syllable_instances: dict
        Mapping from each syllable to a list of instances, where each instance
        is a tuple of the form (name,start,end)

    num_samples: int
        Number of samples return for each syllable

    mode: str, {'random', 'density'}, default='random'
        Sampling method to use. Options are:

        - 'random': Instances are chosen randomly (without replacement)
        - 'density': For each syllable, a syllable-specific density function is
          computed in trajectory space and compared to the overall density
          across all syllables. An exemplar instance that maximizes this ratio
          is chosen for each syllable, and its nearest neighbors are randomly
          sampled.

    pca_samples: int, default=50000
        Number of trajectories to sample when fitting a PCA model for density
        estimation (used when `mode='density'`)

    pca_dim: int, default=4
        Number of principal components to use for density estimation (used when
        `mode='density'`)

    n_neighbors: int, defualt=50
        Number of neighbors to use for density estimation and for sampling the
        neighbors of the examplar syllable instance (used when
        `mode='density'`)

    coordinates, pre, pos, centroids, heading, filter_size
        Passed to :py:func:`keypoint_moseq.util.get_instance_trajectories`

    Returns
    -------
    sampled_instances: dict
        Dictionary in the same format as `syllable_instances` mapping each
        syllable to a list of sampled instances.
    """
    assert mode in ["random", "density"]
    assert all([len(v) >= num_samples for v in syllable_instances.values()])
    assert n_neighbors >= num_samples

    if mode == "random":
        sampled_instances = {
            syllable: [
                instances[i] for i in np.random.choice(len(instances), num_samples, replace=False)
            ]
            for syllable, instances in syllable_instances.items()
        }
        return sampled_instances

    elif mode == "density":
        assert not (coordinates is None or headings is None or centroids is None), fill(
            "`coordinates`, `headings` and `centroids` are required when " '`mode == "density"`'
        )

        for key in coordinates.keys():
            outliers = np.isnan(coordinates[key]).any(-1)
            coordinates[key] = interpolate_keypoints(coordinates[key], outliers)

        trajectories = {
            syllable: get_instance_trajectories(
                instances,
                coordinates,
                pre=pre,
                post=post,
                centroids=centroids,
                headings=headings,
                filter_size=filter_size,
            )
            for syllable, instances in syllable_instances.items()
        }
        X = np.vstack(list(trajectories.values()))

        if X.shape[0] > pca_samples:
            X = X[np.random.choice(X.shape[0], pca_samples, replace=False)]

        pca = PCA(n_components=pca_dim).fit(X.reshape(X.shape[0], -1))
        Xpca = pca.transform(X.reshape(X.shape[0], -1))
        all_nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(Xpca)

        sampled_instances = {}

        for syllable, X in trajectories.items():
            Xpca = pca.transform(X.reshape(X.shape[0], -1))
            nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(Xpca)
            distances, indices = nbrs.kneighbors(Xpca)
            local_density = 1 / distances.mean(1)

            distances, _ = all_nbrs.kneighbors(Xpca)
            global_density = 1 / distances.mean(1)
            exemplar = np.argmax(local_density / global_density)
            samples = np.random.choice(indices[exemplar], num_samples, replace=False)
            sampled_instances[syllable] = [syllable_instances[syllable][i] for i in samples]

        return sampled_instances

    else:
        raise ValueError("Invalid mode: {}".format(mode))


def interpolate_along_axis(x, xp, fp, axis=0):
    """Linearly interpolate along a given axis.

    Parameters
    ----------
    x: 1D array
        The x-coordinates of the interpolated values
    xp: 1D array
        The x-coordinates of the data points
    fp: ndarray
        The y-coordinates of the data points. fp.shape[axis] must
        be equal to the length of xp.

    Returns
    -------
    x_interp: ndarray
        The interpolated values, with the same shape as fp except along the
        interpolation axis.
    """
    assert len(xp.shape) == len(x.shape) == 1
    assert fp.shape[axis] == len(xp)
    assert len(xp) > 0, "xp must be non-empty; cannot interpolate without datapoints"

    fp = np.moveaxis(fp, axis, 0)
    shape = fp.shape[1:]
    fp = fp.reshape(fp.shape[0], -1)

    x_interp = np.zeros((len(x), fp.shape[1]))
    for i in range(fp.shape[1]):
        x_interp[:, i] = np.interp(x, xp, fp[:, i])
    x_interp = x_interp.reshape(len(x), *shape)
    x_interp = np.moveaxis(x_interp, 0, axis)
    return x_interp


def interpolate_keypoints(coordinates, outliers):
    """Use linear interpolation to impute the coordinates of outliers.

    Parameters
    ----------
    coordinates : ndarray of shape (num_frames, num_keypoints, dim)
        Keypoint observations.
    outliers : ndarray of shape (num_frames, num_keypoints)
        Binary indicator whose true entries are outlier points.

    Returns
    -------
    interpolated_coordinates : ndarray with same shape as `coordinates`
        Keypoint observations with outliers imputed.
    """
    interpolated_coordinates = np.zeros_like(coordinates)
    for i in range(coordinates.shape[1]):
        xp = np.nonzero(~outliers[:, i])[0]
        if len(xp) > 0:
            interpolated_coordinates[:, i, :] = interpolate_along_axis(
                np.arange(coordinates.shape[0]), xp, coordinates[xp, i, :]
            )
    return interpolated_coordinates


def filtered_derivative(Y_flat, ksize, axis=0):
    """Compute the filtered derivative of a signal along a given axis.

    When `ksize=3`, for example, the filtered derivative is

    .. math::

        \\dot{y_t} = \\frac{1}{3}( x_{t+3}+x_{t+2}+x_{t+1}-x_{t-1}-x_{t-2}-x_{t-3})


    Parameters
    ----------
    Y_flat: ndarray
        The signal to differentiate

    ksize: int
        The size of the filter. Must be odd.

    axis: int, default=0
        The axis along which to differentiate

    Returns
    -------
    dY: ndarray
        The filtered derivative of the signal
    """
    kernel = np.ones(ksize + 1) / (ksize + 1)
    pre = convolve1d(Y_flat, kernel, origin=-(ksize + 1) // 2, axis=axis)
    post = convolve1d(Y_flat, kernel, origin=ksize // 2, axis=axis)
    return post - pre


def permute_cyclic(arr, mask=None, axis=0):
    """Cyclically permute an array along a given axis.

    Parameters
    ----------
    arr: ndarray
        The array to permute

    mask: ndarray, optional
        A boolean mask indicating which elements to permute. If None, all
        elements are permuted.

    axis: int, default=0
        The axis along which to permute

    Returns
    -------
    arr_permuted: ndarray
        The permuted array
    """
    if mask is None:
        mask = np.ones_like(arr)

    arr = np.moveaxis(arr, axis, 0)
    mask = np.moveaxis(mask, axis, 0)

    shape = arr.shape
    arr = arr.reshape(arr.shape[0], -1)
    mask = mask.reshape(mask.shape[0], -1)

    arr_permuted = np.zeros_like(arr)
    for i in range(arr.shape[1]):
        arr_permuted[mask[:, i] > 0, i] = np.roll(
            arr[mask[:, i] > 0, i], np.random.randint(0, mask[:, i].sum())
        )

    arr_permuted = arr_permuted.reshape(shape)
    arr_permuted = np.moveaxis(arr_permuted, 0, axis)
    return arr_permuted


def _print_colored_table(row_labels, col_labels, values):
    try:
        from IPython.display import display

        display_available = True
    except ImportError:
        display_available = False

    title = "Proportion of NaNs"
    df = pd.DataFrame(values, index=row_labels, columns=col_labels)

    if display_available:

        def colorize(val):
            color = plt.get_cmap("Reds")(val * 0.8)
            return f"background-color: rgba({int(color[0]*255)}, {int(color[1]*255)}, {int(color[2]*255)}, {color[3]})"

        colored_df = df.style.applymap(colorize).set_caption("Proportion of NaNs")
        display(colored_df)
        return colored_df
    else:
        print(title)
        print(tabulate(df, headers="keys", tablefmt="simple_grid", showindex=True))


def check_nan_proportions(coordinates, bodyparts, warning_threshold=0.5, breakdown=False, **kwargs):
    """Check if any bodyparts have a high proportion of NaNs.

    Parameters
    ----------
    coordinates: dict
        Dictionary mapping filenames to keypoint coordinates as ndarrays of
        shape (n_frames, n_bodyparts, 2)

    bodyparts: list of str
        Name of each bodypart. The order of the names should match the order of
        the bodyparts in `coordinates`.

    warning_threshold: float, default=0.5
        If the proportion of NaNs for a bodypart is greater than
        `warning_threshold`, then a warning is printed.

    breakdown: bool, default=False
        Whether to print a table detailing the proportion of NaNs for each
        bodyparts in each array of `coordinates`.
    """
    if breakdown:
        keys = sorted(coordinates.keys())
        nan_props = [np.isnan(coordinates[k]).any(-1).mean(0) for k in keys]
        _print_colored_table(keys, bodyparts, nan_props)
    else:
        all_coords = np.concatenate(list(coordinates.values()))
        nan_props = np.isnan(all_coords).any(-1).mean(0)
        if np.any(nan_props > warning_threshold):
            bps = [bp for bp, p in zip(bodyparts, nan_props) if p > warning_threshold]
            warnings.warn(
                "\nCoordinates for the following bodyparts are missing (set to NaN) in at least "
                "{}% of frames:\n - {}\n\n".format(warning_threshold * 100, "\n - ".join(bps))
            )
            warnings.warn(
                "This may cause problems during modeling. See "
                "https://keypoint-moseq.readthedocs.io/en/latest/FAQs.html#high-proportion-of-nans"
                " for additional information."
            )


def format_data(
    coordinates,
    confidences=None,
    keys=None,
    seg_length=None,
    bodyparts=None,
    use_bodyparts=None,
    conf_pseudocount=1e-3,
    added_noise_level=0.1,
    **kwargs,
):
    """Format keypoint coordinates and confidences for inference.

    Data are transformed as follows:
        1. Coordinates and confidences are each merged into a single array
           using :py:func:`keypoint_moseq.util.batch`. Each row of the merged
           arrays is a segment from one recording.
        2. The keypoints axis is reindexed according to the order of elements
           in `use_bodyparts` with respect to their initial orer in
           `bodyparts`.
        3. Uniform noise proportional to `added_noise_level` is added to the
           keypoint coordinates to prevent degenerate solutions during fitting.
        4. Keypoint confidences are augmented by `conf_pseudocount`.
        5. Wherever NaNs occur in the coordinates, they are replaced by values
           imputed using linear interpolation, and the corresponding
           confidences are set to `conf_pseudocount`.

    Parameters
    ----------
    coordinates: dict
        Keypoint coordinates for a collection of recordings. Values must be
        numpy arrays of shape (T,K,D) where K is the number of keypoints and
        D={2 or 3}.

    confidences: dict, default=None
        Nonnegative confidence values for the keypoints in `coordinates` as
        numpy arrays of shape (T,K).

    keys: list of str, default=None
        (See :py:func:`keypoint_moseq.util.batch`)

    bodyparts: list, default=None
        Label for each keypoint represented in `coordinates`. Required to
        reindex coordinates and confidences according to `use_bodyparts`.

    use_bodyparts: list, default=None
        Ordered subset of keypoint labels to be used for modeling. If
        `use_bodyparts=None`, then all keypoints are used.

    conf_pseudocount: float, default=1e-3
        Pseudocount used to augment keypoint confidences.

    seg_length: int, default=None
        Length of each segment. If `seg_length=None`, a length is chosen so
        that no time-series are broken into multiple segments. If all
        time-series are shorter than `seg_length`, then  `seg_length` is set to
        the length of the shortest time-series.

    Returns
    -------
    data: dict with the following items

        Y: jax array with shape (n_segs, seg_length, K, D)
            Keypoint coordinates from all recordings broken into fixed-length
            segments.

        conf: jax array with shape (n_segs, seg_length, K)
            Confidences from all recordings broken into fixed-length segments.
            If no input is provided for `confidences`, then
            `data["conf"]=None`.

        mask: jax array with shape (n_segs, seg_length)
            Binary array where 0 indicates areas of padding
            (see :py:func:`keypoint_moseq.util.batch`).

    metadata: tuple (keys, bounds)
        Metadata for the rows of `Y`, `conf` and `mask`, as a tuple with a
        array of recording names and an array of (start,end) times. See
        :py:func:`jax_moseq.utils.batch` for details.
    """
    if keys is None:
        keys = sorted(coordinates.keys())
    else:
        bad_keys = set(keys) - set(coordinates.keys())
        assert len(bad_keys) == 0, fill(f"Keys {bad_keys} not found in coordinates")

    assert len(keys) > 0, "No recordings found"

    num_keypoints = [coordinates[key].shape[-2] for key in keys]
    assert len(set(num_keypoints)) == 1, fill(
        f"All recordings must have the same number of keypoints, but "
        f"found {set(num_keypoints)} keypoints across recordings."
    )

    if bodyparts is not None:
        assert len(bodyparts) == num_keypoints[0], fill(
            f"The number of keypoints in `coordinates` ({num_keypoints[0]}) "
            f"does not match the number of labels in `bodyparts` "
            f"({len(bodyparts)})"
        )

    if any(["/" in key for key in keys]):
        warnings.warn(
            fill(
                'WARNING: Recording names should not contain "/", this will cause '
                "problems with saving/loading hdf5 files."
            )
        )

    if confidences is None:
        confidences = {key: np.ones_like(coordinates[key][..., 0]) for key in keys}

    if bodyparts is not None and use_bodyparts is not None:
        coordinates = reindex_by_bodyparts(coordinates, bodyparts, use_bodyparts)
        confidences = reindex_by_bodyparts(confidences, bodyparts, use_bodyparts)

    for key in keys:
        outliers = np.isnan(coordinates[key]).any(-1)
        coordinates[key] = interpolate_keypoints(coordinates[key], outliers)
        confidences[key] = np.where(outliers, 0, np.nan_to_num(confidences[key]))

    if seg_length is not None:
        max_recording_length = max([coordinates[key].shape[0] for key in keys])
        seg_length = min(seg_length, max_recording_length)

    Y, mask, metadata = batch(coordinates, seg_length=seg_length, keys=keys)
    Y = Y.astype(float)

    min_segment_length = np.diff(metadata[1], axis=1).min()
    assert min_segment_length >= 4, (
        f"The shortest segment has length  {min_segment_length} which is below the "
        "minimum of 4. Try increasing `seg_length` in the config (e.g. add "
        f"{min_segment_length} to its current value) and also make sure that all your "
        "input recordings are at least 4 frames long."
    )

    conf = batch(confidences, seg_length=seg_length, keys=keys)[0]
    if np.min(conf) < 0:
        conf = np.maximum(conf, 0)
        warnings.warn(fill("Negative confidence values are not allowed and will be set to 0."))
    conf = conf + conf_pseudocount

    if added_noise_level > 0:
        Y += np.random.uniform(-added_noise_level, added_noise_level, Y.shape)

    data = jax.device_put({"mask": mask, "Y": Y, "conf": conf})
    return data, metadata


def get_typical_trajectories(
    coordinates,
    results,
    pre=5,
    post=15,
    min_frequency=0.005,
    min_duration=3,
    bodyparts=None,
    use_bodyparts=None,
    density_sample=True,
    sampling_options={"n_neighbors": 50},
):
    """Generate representative keypoint trajectories for each syllable.

    Parameters
    ----------
    coordinates: dict
        Dictionary mapping recording names to keypoint coordinates as ndarrays
        of shape (n_frames, n_bodyparts, 2).

    results: dict
        Dictionary containing modeling results for a dataset (see
        :py:func:`keypoint_moseq.fitting.extract_results`).

    pre: int, default=5, post: int, default=15
        Defines the temporal window around syllable onset for computing the
        average trajectory. Note that the window is independent of the actual
        duration of the syllable.

    min_frequency: float, default=0.005
        Minimum frequency of a syllable to plotted.

    min_duration: float, default=3
        Minimum duration of a syllable instance to be included in the
        trajectory average.

    bodyparts: list of str, default=None
        List of bodypart names in `coordinates`.

    use_bodyparts: list of str, default=None
        Ordered list of bodyparts to include in each trajectory. If None, all
        bodyparts will be included.

    density_sample : bool, default=True
        Whether to use density sampling when generating trajectories. If True,
        the trajectory is based on the most exemplary syllable instances,
        rather than being average across all instances.

    sampling_options: dict, default={'n_neighbors':50}
        Dictionary of options for sampling syllable instances (see
        :py:func:`keypoint_moseq.util.sample_instances`). Only used when
        `density_sample` is True.

    Returns
    -------
    representative_trajectories: dict
        Dictionary mapping syllable indexes to representative trajectories
        as arrays of shape (pre+pose, n_bodyparts, [2 or 3]).
    """
    if bodyparts is not None and use_bodyparts is not None:
        coordinates = reindex_by_bodyparts(coordinates, bodyparts, use_bodyparts)

    syllables = {k: v["syllable"] for k, v in results.items()}
    centroids = {k: v["centroid"] for k, v in results.items()}
    headings = {k: v["heading"] for k, v in results.items()}

    min_instances = sampling_options["n_neighbors"] if density_sample else 1
    syllable_instances = get_syllable_instances(
        syllables,
        pre=pre,
        post=post,
        min_duration=min_duration,
        min_frequency=min_frequency,
        min_instances=min_instances,
    )

    if len(syllable_instances) == 0:
        raise ValueError(
            fill(
                "No syllables with sufficient instances to generate a trajectory. "
                "This usually occurs when there is not enough inut data or when "
                "all frames have the same syllable label (use "
                "`plot_syllable_frequencies` to check if this is the case)"
            )
        )
        return

    if density_sample:
        sampling_options["mode"] = "density"
        sampled_instances = sample_instances(
            syllable_instances,
            sampling_options["n_neighbors"],
            coordinates=coordinates,
            centroids=centroids,
            headings=headings,
            **sampling_options,
        )
    else:
        sampled_instances = syllable_instances

    trajectories = {
        syllable: get_instance_trajectories(
            instances,
            coordinates,
            pre=pre,
            post=post,
            centroids=centroids,
            headings=headings,
        )
        for syllable, instances in sampled_instances.items()
    }

    return {s: np.nanmedian(ts, axis=0) for s, ts in trajectories.items()}


def syllable_similarity(
    coordinates,
    results,
    metric="cosine",
    pre=5,
    post=15,
    min_frequency=0.005,
    min_duration=3,
    bodyparts=None,
    use_bodyparts=None,
    density_sample=False,
    sampling_options={"n_neighbors": 50},
    **kwargs,
):
    """Generate a distance matrix over syllable trajectories.

    See :py:func:`keypoint_moseq.util.get_typical_trajectories` for a
    description of the parameters not listed below.

    Parameters
    ----------
    metric: str, default='cosine'
        Distance metric to use. See :py:func:`scipy.spatial.pdist` for options.

    Returns
    -------
    distances : ndarray of shape (n_syllables, n_syllables)
        Pairwise distances between the typical trajectories associated with
        each syllable. Only syllables with sufficient frequency of occurence
        are included.

    syllable_ixs : array of int
        Syllable indexes corresponding to the rows and columns of `distances`.
    """
    typical_trajectories = get_typical_trajectories(
        coordinates,
        results,
        pre,
        post,
        min_frequency,
        min_duration,
        bodyparts,
        use_bodyparts,
        density_sample,
        sampling_options,
    )

    syllable_ixs = sorted(typical_trajectories.keys())
    Xs = np.stack([typical_trajectories[s] for s in syllable_ixs])
    distances = squareform(pdist(Xs.reshape(Xs.shape[0], -1), metric))
    return distances, syllable_ixs


def downsample_timepoints(data, downsample_rate):
    """
    Downsample timepoints, e.g. of coordinates or confidences.

    Parameters
    ----------
    data: ndarray or dict
        Array of shape (n_frames, ...) or a dictionary with such arrays as values.

    downsample_rate: int
        The downsampling rate (e.g., `downsample_rate=2` keeps every other frame).

    Returns
    -------
    downsampled_data: ndarray or dict
        Downsampled array or dictionary of arrays.

    indexes: ndarray or dict
        Downsampled timepoints (in the original numbering)
    """
    if isinstance(data, dict):
        downsampled_data = {}
        indexes = {}
        for k, v in data.items():
            downsampled_data[k], indexes[k] = downsample_timepoints(v, downsample_rate)
    else:
        downsampled_data = data[::downsample_rate]
        indexes = np.arange(len(downsampled_data)) * downsample_rate
    return downsampled_data, indexes


def check_video_paths(video_paths, keys):
    """
    Check if video paths are valid and match the keys.

    Parameters
    ----------
    video_paths: dict
        Dictionary mapping keys to video paths.

    keys: list
        List of keys that require a video path.

    Raises
    ------
    ValueError
        If any of the following are true:
        - a video path is not provided for a key in `keys`
        - a video isn't readable.
        - a video path does not exist.
    """
    missing_keys = set(keys) - set(video_paths.keys())

    nonexistent_videos = []
    unreadable_videos = []
    for path in video_paths.values():
        if not os.path.exists(path):
            nonexistent_videos.append(path)
        else:
            try:
                OpenCVReader(path)[0]
            except:
                unreadable_videos.append(path)

    error_messages = []

    if len(missing_keys) > 0:
        error_messages.append("The following keys require a video path: {}".format(missing_keys))
    if len(nonexistent_videos) > 0:
        error_messages.append("The following videos do not exist: {}".format(nonexistent_videos))
    if len(unreadable_videos) > 0:
        error_messages.append(
            "The following videos are not readable and must be reencoded: {}".format(
                unreadable_videos
            )
        )

    if len(error_messages) > 0:
        raise ValueError("\n\n".join(error_messages))


--- File: keypoint_moseq/io.py ---
import jax.numpy as jnp
import jax
import re
import commentjson
import json
import numpy as np
import h5py
import joblib
import tqdm
import yaml
import os
import pandas as pd
from textwrap import fill
import sleap_io
from pynwb import NWBHDF5IO
from ndx_pose import PoseEstimation
from itertools import islice

from keypoint_moseq.util import list_files_with_exts, check_nan_proportions
from jax_moseq.utils import get_frequencies, unbatch
from scipy.io import loadmat


def _build_yaml(sections, comments):
    text_blocks = []
    for title, data in sections:
        centered_title = f" {title} ".center(50, "=")
        text_blocks.append(f"\n\n{'#'}{centered_title}{'#'}")
        for key, value in data.items():
            text = yaml.dump({key: value}).strip("\n")
            if key in comments:
                text = f"\n{'#'} {comments[key]}\n{text}"
            text_blocks.append(text)
    return "\n".join(text_blocks)


def _get_path(project_dir, model_name, path, filename, pathname_for_error_msg="path"):
    if path is None:
        assert project_dir is not None and model_name is not None, fill(
            f"`model_name` and `project_dir` are required if `{pathname_for_error_msg}` is None."
        )
        path = os.path.join(project_dir, model_name, filename)
    return path


def generate_config(project_dir, **kwargs):
    """Generate a `config.yml` file with project settings. Default settings
    will be used unless overriden by a keyword argument.

    Parameters
    ----------
    project_dir: str
        A file `config.yml` will be generated in this directory.

    kwargs
        Custom project settings.
    """

    def _update_dict(new, original):
        return {k: new[k] if k in new else v for k, v in original.items()}

    hypperams = _update_dict(
        kwargs,
        {
            "error_estimator": {"slope": -0.5, "intercept": 0.25},
            "obs_hypparams": {
                "sigmasq_0": 0.1,
                "sigmasq_C": 0.1,
                "nu_sigma": 1e5,
                "nu_s": 5,
            },
            "ar_hypparams": {
                "latent_dim": 10,
                "nlags": 3,
                "S_0_scale": 0.01,
                "K_0_scale": 10.0,
            },
            "trans_hypparams": {
                "num_states": 100,
                "gamma": 1e3,
                "alpha": 5.7,
                "kappa": 1e6,
            },
            "cen_hypparams": {"sigmasq_loc": 0.5},
        },
    )

    hypperams = {k: _update_dict(kwargs, v) for k, v in hypperams.items()}

    anatomy = _update_dict(
        kwargs,
        {
            "bodyparts": ["BODYPART1", "BODYPART2", "BODYPART3"],
            "use_bodyparts": ["BODYPART1", "BODYPART2", "BODYPART3"],
            "skeleton": [
                ["BODYPART1", "BODYPART2"],
                ["BODYPART2", "BODYPART3"],
            ],
            "anterior_bodyparts": ["BODYPART1"],
            "posterior_bodyparts": ["BODYPART3"],
        },
    )

    other = _update_dict(
        kwargs,
        {
            "recording_name_suffix": "",
            "verbose": False,
            "conf_pseudocount": 1e-3,
            "video_dir": "",
            "keypoint_colormap": "autumn",
            "whiten": True,
            "fix_heading": False,
            "seg_length": 10000,
        },
    )

    fitting = _update_dict(
        kwargs,
        {
            "added_noise_level": 0.1,
            "PCA_fitting_num_frames": 1000000,
            "conf_threshold": 0.5,
            #         'kappa_scan_target_duration': 12,
            #         'kappa_scan_min': 1e2,
            #         'kappa_scan_max': 1e12,
            #         'num_arhmm_scan_iters': 50,
            #         'num_arhmm_final_iters': 200,
            #         'num_kpslds_scan_iters': 50,
            #         'num_kpslds_final_iters': 500
        },
    )

    comments = {
        "verbose": "whether to print progress messages during fitting",
        "keypoint_colormap": "colormap used for visualization; see `matplotlib.cm.get_cmap` for options",
        "added_noise_level": "upper bound of uniform noise added to the data during initial AR-HMM fitting; this is used to regularize the model",
        "PCA_fitting_num_frames": "number of frames used to fit the PCA model during initialization",
        "video_dir": "directory with videos from which keypoints were derived (used for crowd movies)",
        "recording_name_suffix": "suffix used to match videos to recording names; this can usually be left empty (see `util.find_matching_videos` for details)",
        "bodyparts": "used to access columns in the keypoint data",
        "skeleton": "used for visualization only",
        "use_bodyparts": "determines the subset of bodyparts to use for modeling and the order in which they are represented",
        "anterior_bodyparts": "used to initialize heading",
        "posterior_bodyparts": "used to initialize heading",
        "seg_length": "data are broken up into segments to parallelize fitting",
        "trans_hypparams": "transition hyperparameters",
        "ar_hypparams": "autoregressive hyperparameters",
        "obs_hypparams": "keypoint observation hyperparameters",
        "cen_hypparams": "centroid movement hyperparameters",
        "error_estimator": "parameters to convert neural net likelihoods to error size priors",
        "save_every_n_iters": "frequency for saving model snapshots during fitting; if 0 only final state is saved",
        "kappa_scan_target_duration": "target median syllable duration (in frames) for choosing kappa",
        "whiten": "whether to whiten principal components; used to initialize the latent pose trajectory `x`",
        "conf_threshold": "used to define outliers for interpolation when the model is initialized",
        "conf_pseudocount": "pseudocount used regularize neural network confidences",
        "fix_heading": "whether to keep the heading angle fixed; this should only be True if the pose is constrained to a narrow range of angles, e.g. a headfixed mouse.",
    }

    sections = [
        ("ANATOMY", anatomy),
        ("FITTING", fitting),
        ("HYPER PARAMS", hypperams),
        ("OTHER", other),
    ]

    with open(os.path.join(project_dir, "config.yml"), "w") as f:
        f.write(_build_yaml(sections, comments))


def check_config_validity(config):
    """Check if the config is valid.

    To be valid, the config must satisfy the following criteria:
        - All the elements of `config["use_bodyparts"]` are also in
          `config["bodyparts"]`
        - All the elements of `config["anterior_bodyparts"]` are also in
          `config["use_bodyparts"]`
        - All the elements of `config["anterior_bodyparts"]` are also in
          `config["use_bodyparts"]`
        - For each pair in `config["skeleton"]`, both elements also in
          `config["bodyparts"]`

    Parameters
    ----------
    config: dict

    Returns
    -------
    validity: bool
    """
    error_messages = []

    # check anatomy
    for bodypart in config["use_bodyparts"]:
        if not bodypart in config["bodyparts"]:
            error_messages.append(
                f"ACTION REQUIRED: `use_bodyparts` contains {bodypart} "
                "which is not one of the options in `bodyparts`."
            )

    for bodypart in sum(config["skeleton"], []):
        if not bodypart in config["bodyparts"]:
            error_messages.append(
                f"ACTION REQUIRED: `skeleton` contains {bodypart} "
                "which is not one of the options in `bodyparts`."
            )

    for bodypart in config["anterior_bodyparts"]:
        if not bodypart in config["use_bodyparts"]:
            error_messages.append(
                f"ACTION REQUIRED: `anterior_bodyparts` contains {bodypart} "
                "which is not one of the options in `use_bodyparts`."
            )

    for bodypart in config["posterior_bodyparts"]:
        if not bodypart in config["use_bodyparts"]:
            error_messages.append(
                f"ACTION REQUIRED: `posterior_bodyparts` contains {bodypart} "
                "which is not one of the options in `use_bodyparts`."
            )

    if len(error_messages) == 0:
        return True
    for msg in error_messages:
        print(fill(msg, width=70, subsequent_indent="  "), end="\n\n")
    return False


def load_config(project_dir, check_if_valid=True, build_indexes=True):
    """Load a project config file.

    Parameters
    ----------
    project_dir: str
        Directory containing the config file

    check_if_valid: bool, default=True
        Check if the config is valid using
        :py:func:`keypoint_moseq.io.check_config_validity`

    build_indexes: bool, default=True
        Add keys `"anterior_idxs"` and `"posterior_idxs"` to the config. Each
        maps to a jax array indexing the elements of
        `config["anterior_bodyparts"]` and `config["posterior_bodyparts"]` by
        their order in `config["use_bodyparts"]`

    Returns
    -------
    config: dict
    """
    config_path = os.path.join(project_dir, "config.yml")

    with open(config_path, "r") as stream:
        config = yaml.safe_load(stream)

    if check_if_valid:
        check_config_validity(config)

    if build_indexes:
        config["anterior_idxs"] = jnp.array(
            [config["use_bodyparts"].index(bp) for bp in config["anterior_bodyparts"]]
        )
        config["posterior_idxs"] = jnp.array(
            [config["use_bodyparts"].index(bp) for bp in config["posterior_bodyparts"]]
        )

    if not "skeleton" in config or config["skeleton"] is None:
        config["skeleton"] = []

    return config


def update_config(project_dir, **kwargs):
    """Update the config file stored at `project_dir/config.yml`.

    Use keyword arguments to update key/value pairs in the config. To update
    model hyperparameters, just use the name of the hyperparameter as the
    keyword argument.

    Examples
    --------
    To update `video_dir` to `/path/to/videos`::

      >>> update_config(project_dir, video_dir='/path/to/videos')
      >>> print(load_config(project_dir)['video_dir'])
      /path/to/videos

    To update `trans_hypparams['kappa']` to `100`::

      >>> update_config(project_dir, kappa=100)
      >>> print(load_config(project_dir)['trans_hypparams']['kappa'])
      100
    """
    config = load_config(project_dir, check_if_valid=False, build_indexes=False)
    config.update(kwargs)
    generate_config(project_dir, **config)


def setup_project(
    project_dir,
    deeplabcut_config=None,
    sleap_file=None,
    nwb_file=None,
    freipose_config=None,
    dannce_config=None,
    overwrite=False,
    **options,
):
    """
    Setup a project directory with the following structure::

        project_dir
        └── config.yml

    Parameters
    ----------
    project_dir: str
        Path to the project directory (relative or absolute).

    deeplabcut_config: str, default=None
        Path to a deeplabcut config file. Will be used to initialize
        `bodyparts`, `skeleton`, `use_bodyparts` and `video_dir` in the
        keypoint MoSeq config (overrided by kwargs).

    sleap_file: str, default=None
        Path to a .hdf5 or .slp file containing predictions for one video. Will
        be used to initialize `bodyparts`, `skeleton`, and `use_bodyparts` in
        the keypoint MoSeq config (overrided by kwargs).

    nwb_file: str, default=None
        Path to a .nwb file containing predictions for one video. Will be used
        to initialize `bodyparts`, `skeleton`, and `use_bodyparts` in the
        keypoint MoSeq config. (overrided by kwargs).

    freipose_config: str, default=None
        Path to a freipose skeleton config file. Will be used to initialize
        `bodyparts`, `skeleton`, and `use_bodyparts` in the keypoint MoSeq config
        (overrided by kwargs).

    dannce_config: str, default=None
        Path to a dannce config file. Will be used to initialize `bodyparts`,
        `skeleton`, and `use_bodyparts` in the keypoint MoSeq config (overrided
        by kwargs).

    overwrite: bool, default=False
        Overwrite any config.yml that already exists at the path
        `{project_dir}/config.yml`.

    options
        Used to initialize config file. Overrides default settings.
    """

    if os.path.exists(project_dir) and not overwrite:
        print(
            fill(
                f"The directory `{project_dir}` already exists. Use "
                "`overwrite=True` or pick a different name"
            )
        )
        return

    if deeplabcut_config is not None:
        dlc_options = {}
        with open(deeplabcut_config, "r") as stream:
            dlc_config = yaml.safe_load(stream)
            if dlc_config is None:
                raise RuntimeError(
                    f"{deeplabcut_config} does not exists or is not a" " valid yaml file"
                )
            if "multianimalproject" in dlc_config and dlc_config["multianimalproject"]:
                dlc_options["bodyparts"] = dlc_config["multianimalbodyparts"]
                dlc_options["use_bodyparts"] = dlc_config["multianimalbodyparts"]
            else:
                dlc_options["bodyparts"] = dlc_config["bodyparts"]
                dlc_options["use_bodyparts"] = dlc_config["bodyparts"]
            dlc_options["skeleton"] = dlc_config["skeleton"]
            dlc_options["video_dir"] = os.path.join(dlc_config["project_path"], "videos")
        options = {**dlc_options, **options}

    elif sleap_file is not None:
        sleap_options = {}
        if os.path.splitext(sleap_file)[1] == ".slp":
            slp_file = sleap_io.load_slp(sleap_file)
            assert len(slp_file.skeletons) == 1, fill(
                f"{sleap_file} contains more than one skeleton. "
                "This is not currently supported. Please "
                "open a github issue or email calebsw@gmail.com"
            )
            skeleton = slp_file.skeletons[0]
            node_names = skeleton.node_names
            edge_names = [[e.source.name, e.destination.name] for e in skeleton.edges]
        else:
            with h5py.File(sleap_file, "r") as f:
                node_names = [n.decode("utf-8") for n in f["node_names"]]
                edge_names = [[n.decode("utf-8") for n in edge] for edge in f["edge_names"]]
        sleap_options["bodyparts"] = node_names
        sleap_options["use_bodyparts"] = node_names
        sleap_options["skeleton"] = edge_names
        options = {**sleap_options, **options}

    elif nwb_file is not None:
        nwb_options = {}
        with NWBHDF5IO(nwb_file, mode="r", load_namespaces=True) as io:
            pose_obj = _load_nwb_pose_obj(io, nwb_file)
            bodyparts = list(pose_obj.nodes[:])
            nwb_options["bodyparts"] = bodyparts
            nwb_options["use_bodyparts"] = bodyparts
            if "edges" in pose_obj.fields:
                edges = pose_obj.edges[:]
                skeleton = [[bodyparts[i], bodyparts[j]] for i, j in edges]
                nwb_options["skeleton"] = skeleton
        options = {**nwb_options, **options}

    elif freipose_config is not None:
        freipose_options = {}
        with open(freipose_config, "r") as stream:
            freipose_config = commentjson.load(stream)
            bodyparts = [kp for kp, color in freipose_config["keypoints"]]
            skeleton = []
            for [bp1, bp2], color in freipose_config["limbs"]:
                if isinstance(bp1, list):
                    bp1 = bp1[0]
                if isinstance(bp2, list):
                    bp2 = bp2[0]
                skeleton.append(tuple(sorted([bodyparts[bp1], bodyparts[bp2]])))
            freipose_options["bodyparts"] = bodyparts
            freipose_options["use_bodyparts"] = bodyparts
            freipose_options["skeleton"] = list(map(list, sorted(set(skeleton))))
        options = {**freipose_options, **options}

    elif dannce_config is not None:
        dannce_config = loadmat(dannce_config)
        bodyparts = [n[0][0].item() for n in dannce_config["joint_names"]]
        skeleton = [[bodyparts[i], bodyparts[j]] for i, j in dannce_config["joints_idx"] - 1]
        dannce_options = {
            "bodyparts": bodyparts,
            "use_bodyparts": bodyparts,
            "skeleton": skeleton,
        }
        options = {**dannce_options, **options}

    if not os.path.exists(project_dir):
        os.makedirs(project_dir)
    generate_config(project_dir, **options)


def save_pca(pca, project_dir, pca_path=None):
    """Save a PCA model to disk.

    The model is saved to `pca_path` or else to `{project_dir}/pca.p`.

    Parameters
    ----------
    pca: :py:class:`sklearn.decomposition.PCA`
    project_dir: str
    pca_path: str, default=None
    """
    if pca_path is None:
        pca_path = os.path.join(project_dir, "pca.p")
    joblib.dump(pca, pca_path)


def load_pca(project_dir, pca_path=None):
    """Load a PCA model from disk.

    The model is loaded from `pca_path` or else from `{project_dir}/pca.p`.

    Parameters
    ----------
    project_dir: str
    pca_path: str, default=None

    Returns
    -------
    pca: :py:class:`sklearn.decomposition.PCA`
    """
    if pca_path is None:
        pca_path = os.path.join(project_dir, "pca.p")
        assert os.path.exists(pca_path), fill(f"No PCA model found at {pca_path}")
    return joblib.load(pca_path)


def load_checkpoint(project_dir=None, model_name=None, path=None, iteration=None):
    """Load data and model snapshot from a saved checkpoint.

    The checkpoint path can be specified directly via `path` or else it is
    assumed to be `{project_dir}/{model_name}/checkpoint.h5`.

    Parameters
    ----------
    project_dir: str, default=None
        Project directory; used in conjunction with `model_name` to determine the
        checkpoint path if `path` is not specified.

    model_name: str, default=None
        Model name; used in conjunction with `project_dir` to determine the
        checkpoint path if `path` is not specified.

    path: str, default=None
        Checkpoint path; if not specified, the checkpoint path is set to
        `{project_dir}/{model_name}/checkpoint.h5`.

    iteration: int, default=None
        Determines which model snapshot to load. If None, the last snapshot is
        loaded.

    Returns
    -------
    model: dict
        Model dictionary containing states, parameters, hyperparameters,
        noise prior, and random seed.

    data: dict
        Data dictionary containing observations, confidences, mask and
        associated metadata (see :py:func:`keypoint_moseq.util.format_data`).

    metadata: tuple (keys, bounds)
        Recording names and start/end frames for the data (see
        :py:func:`keypoint_moseq.util.format_data`).

    iteration: int
        Iteration of model fitting corresponding to the loaded snapshot.
    """
    path = _get_path(project_dir, model_name, path, "checkpoint.h5")

    with h5py.File(path, "r") as f:
        saved_iterations = np.sort([int(i) for i in f["model_snapshots"]])

    if iteration is None:
        iteration = saved_iterations[-1]
    else:
        assert iteration in saved_iterations, fill(
            f"No snapshot found for iteration {iteration}. "
            f"Available iterations are {saved_iterations}"
        )

    model = load_hdf5(path, f"model_snapshots/{iteration}")
    metadata = load_hdf5(path, "metadata")
    data = load_hdf5(path, "data")
    return model, data, metadata, iteration


def reindex_syllables_in_checkpoint(
    project_dir=None, model_name=None, path=None, index=None, runlength=True
):
    """Reindex syllable labels by their frequency in the most recent model
    snapshot in a checkpoint file.

    This is an in-place operation: the checkpoint is loaded from disk, modified
    and saved to disk again. The label permutation is applied to all model
    snapshots in the checkpoint.

    The checkpoint path can be specified directly via `path` or else it is
    assumed to be `{project_dir}/{model_name}/checkpoint.h5`.

    Parameters
    ----------
    project_dir: str, default=None
    model_name: str, default=None
    path: str, default=None

    index: array of shape (num_states,), default=None
        Permutation for syllable labels, where `index[i]` is relabled as `i`.
        If None, syllables are relabled by frequency, with the most frequent
        syllable relabled as 0, and so on.

    runlength: bool, default=True
        If True, frequencies are quantified using the number of non-consecutive
        occurrences of each syllable. If False, frequency is quantified by
        total number of frames.

    Returns
    -------
    index: array of shape (num_states,)
        The index used for permuting syllable labels. If `index[i] = j`, then
        the syllable formerly labeled `j` is now labeled `i`.
    """
    path = _get_path(project_dir, model_name, path, "checkpoint.h5")

    with h5py.File(path, "r") as f:
        saved_iterations = [int(i) for i in f["model_snapshots"]]

    if index is None:
        with h5py.File(path, "r") as f:
            last_iter = np.max(saved_iterations)
            num_states = f[f"model_snapshots/{last_iter}/params/pi"].shape[0]
            z = f[f"model_snapshots/{last_iter}/states/z"][()]
            mask = f["data/mask"][()]
        index = np.argsort(get_frequencies(z, mask, num_states, runlength))[::-1]

    def _reindex(model):
        model["params"]["betas"] = model["params"]["betas"][index]
        model["params"]["pi"] = model["params"]["pi"][index, :][:, index]
        model["params"]["Ab"] = model["params"]["Ab"][index]
        model["params"]["Q"] = model["params"]["Q"][index]
        model["states"]["z"] = np.argsort(index)[model["states"]["z"]]
        return model

    for iteration in tqdm.tqdm(
        saved_iterations, desc="Reindexing", unit="model snapshot", ncols=72
    ):
        model = load_hdf5(path, f"model_snapshots/{iteration}")
        save_hdf5(path, _reindex(model), f"model_snapshots/{iteration}")
    return index


def extract_results(
    model,
    metadata,
    project_dir=None,
    model_name=None,
    save_results=True,
    path=None,
):
    """Extract model outputs and [optionally] save them to disk.

    Model outputs are saved to disk as a .h5 file, either at `path`
    if it is specified, or at `{project_dir}/{model_name}/results.h5` if it is not.
    If a .h5 file with the given path already exists, the outputs will be added
    to it. The results have the following structure::

        results.h5
        ├──recording_name1
        │  ├──syllable      # model state sequence (z), shape=(num_timepoints,)
        │  ├──latent_state  # model latent state (x), shape=(num_timepoints,latent_dim)
        │  ├──centroid      # model centroid (v), shape=(num_timepoints,keypoint_dim)
        │  └──heading       # model heading (h), shape=(num_timepoints,)
        ⋮

    Parameters
    ----------
    model : dict
        Model dictionary containing states, parameters, hyperparameters,
        noise prior, and random seed.

    metadata: tuple (keys, bounds)
        Recordings and start/end frames for the data (see
        :py:func:`keypoint_moseq.util.format_data`).

    save_results : bool, default=True
        If True, the model outputs will be saved to disk.

    project_dir : str, default=None
        Path to the project directory. Required if `save_results=True` and
        `results_path=None`.

    model_name : str, default=None
        Name of the model. Required if `save_results=True` and
        `results_path=None`.

    path : str, default=None
        Optional path for saving model outputs.

    Returns
    -------
    results_dict : dict
        Dictionary of model outputs with the same structure as the results
        `.h5` file.
    """
    if save_results:
        path = _get_path(project_dir, model_name, path, "results.h5")

    states = jax.device_get(model["states"])

    # extract syllables; repeat first syllable an extra `nlags` times
    nlags = states["x"].shape[1] - states["z"].shape[1]
    z = np.pad(states["z"], ((0, 0), (nlags, 0)), mode="edge")
    syllables = unbatch(z, *metadata)

    # extract latent state, centroid, and heading
    latent_state = unbatch(states["x"], *metadata)
    centroid = unbatch(states["v"], *metadata)
    heading = unbatch(states["h"], *metadata)

    results_dict = {
        recording_name: {
            "syllable": syllables[recording_name],
            "latent_state": latent_state[recording_name],
            "centroid": centroid[recording_name],
            "heading": heading[recording_name],
        }
        for recording_name in syllables.keys()
    }

    if save_results:
        save_hdf5(path, results_dict)
        print(fill(f"Saved results to {path}"))

    return results_dict


def load_results(project_dir=None, model_name=None, path=None):
    """Load the results from a modeled dataset.

    The results path can be specified directly via `path`. Otherwise it is
    assumed to be `{project_dir}/{model_name}/results.h5`.

    Parameters
    ----------
    project_dir: str, default=None
    model_name: str, default=None
    path: str, default=None

    Returns
    -------
    results: dict
        See :py:func:`keypoint_moseq.fitting.apply_model`
    """
    path = _get_path(project_dir, model_name, path, "results.h5")
    return load_hdf5(path)


def save_results_as_csv(results, project_dir=None, model_name=None, save_dir=None, path_sep="-"):
    """Save modeling results to csv format.

    This function creates a directory and then saves a separate csv file for
    each recording. The directory is created at `save_dir` if provided,
    otherwise at `{project_dir}/{model_name}/results`.

    Parameters
    ----------
    results: dict
        See :py:func:`keypoint_moseq.io.extract_results`.

    project_dir: str, default=None
        Project directory; required if `save_dir` is not provided.

    model_name: str, default=None
        Name of the model; required if `save_dir` is not provided.

    save_dir: str, default=None
        Optional path to the directory where the csv files will be saved.

    path_sep: str, default='-'
        If a path separator ("/" or "\") is present in the recording name, it
        will be replaced with `path_sep` when saving the csv file.
    """
    save_dir = _get_path(project_dir, model_name, save_dir, "results", "save_dir")

    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    for key in tqdm.tqdm(results.keys(), desc="Saving to csv", ncols=72):
        column_names, data = [], []

        if "syllable" in results[key].keys():
            column_names.append(["syllable"])
            data.append(results[key]["syllable"].reshape(-1, 1))

        if "centroid" in results[key].keys():
            d = results[key]["centroid"].shape[1]
            column_names.append(["centroid x", "centroid y", "centroid z"][:d])
            data.append(results[key]["centroid"])

        if "heading" in results[key].keys():
            column_names.append(["heading"])
            data.append(results[key]["heading"].reshape(-1, 1))

        if "latent_state" in results[key].keys():
            latent_dim = results[key]["latent_state"].shape[1]
            column_names.append([f"latent_state {i}" for i in range(latent_dim)])
            data.append(results[key]["latent_state"])

        dfs = [pd.DataFrame(arr, columns=cols) for arr, cols in zip(data, column_names)]
        df = pd.concat(dfs, axis=1)

        for col in df.select_dtypes(include=[np.floating]).columns:
            df[col] = df[col].astype(float).round(4)

        save_name = key.replace(os.path.sep, path_sep)
        save_path = os.path.join(save_dir, save_name)
        df.to_csv(f"{save_path}.csv", index=False)


def _name_from_path(filepath, path_in_name, path_sep, remove_extension):
    """Create a name from a filepath.

    Either return the name of the file (with the extension removed) or return
    the full filepath, where the path separators are replaced with `path_sep`.
    """
    if remove_extension:
        filepath = os.path.splitext(filepath)[0]
    if path_in_name:
        return filepath.replace(os.path.sep, path_sep)
    else:
        return os.path.basename(filepath)


def save_keypoints(save_dir, coordinates, confidences=None, bodyparts=None, path_sep="-"):
    """Convenience function for saving keypoint detections to csv files.

    One csv file is saved for each recording in `coordinates`. Each row in the
    csv corresponds to one frame and the columns are named

        "BODYPART1_x", "BODYPART1_y", "BODYPART1_conf", "BODYPART2_x", ...

    Columns with confidence scores are ommitted if `confidences` is not provided.
    Besides confidences, there can be 2 or 3 columns for each bodypart, depending
    on whether the keypoints are 2D or 3D.

    Parameters
    ----------
    save_dir: str
        Directory to save the results. A separate csv file will be saved for
        each recording in `coordinates`.

    coordinates: dict
        Dictionary mapping recording names to numpy arrays of shape
        (n_frames, n_keypoints, 2[or 3]) that contain the x and y (and z)
        coordinates of the keypoints. If any keys contain a path separator
        (such as "/"), it will be replaced with `path_sep` when naming the
        csv file.

    confidences: dict, default=None
        Dictionary mapping recording names to numpy arrays of shape
        (n_frames, n_keypoints) with the confidence scores of the keypoints.
        Must have the same keys as `coordinates`.

    bodyparts: list, default=None
        List of bodypart names, in the same order as the keypoints in the
        `coordinates` and `confidences` arrays. If None, the bodypart names
        will be set to ["bodypart1", "bodypart2", ...].

    path_sep: str, default='-'
        If a path separator ("/" or "\") is present in the recording name, it
        will be replaced with `path_sep` when saving the csv file.
    """
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    if confidences is not None:
        assert set(coordinates.keys()) == set(confidences.keys()), fill(
            "The keys in `coordinates` and `confidences` must be the same."
        )

    # get number of keypoints and dimensions
    _, num_keypoints, num_dims = next(iter(coordinates.values())).shape

    # generate bodypart names if not provided
    if bodyparts is None:
        bodyparts = [f"bodypart{i}" for i in range(num_keypoints)]

    # create column names
    suffixes = ["x", "y", "z"][:num_keypoints]
    if confidences is not None:
        suffixes += ["conf"]
    columns = [f"{bp}_{suffix}" for bp in bodyparts for suffix in suffixes]

    # save data to csv
    for recording_name, coords in coordinates.items():
        if confidences is not None:
            data = np.concatenate(
                [coords, confidences[recording_name][..., np.newaxis]], axis=-1
            ).reshape(-1, (num_dims + 1) * num_keypoints)
        else:
            data = coords.reshape(-1, num_dims * num_keypoints)
        save_name = recording_name.replace(os.path.sep, path_sep)
        save_path = os.path.join(save_dir, save_name)
        pd.DataFrame(data, columns=columns).to_csv(f"{save_path}.csv", index=False)


def load_keypoints(
    filepath_pattern,
    format,
    extension=None,
    recursive=True,
    path_sep="-",
    path_in_name=False,
    remove_extension=True,
    exclude_individuals=["single"],
):
    """
    Load keypoint tracking results from one or more files. Several file
    formats are supported:

    - deeplabcut
        .csv and .h5/.hdf5 files generated by deeplabcut. For single-animal
        tracking, each file yields a single key/value pair in the returned
        `coordinates` and `confidences` dictionaries. For multi-animal tracking,
        a key/vaue pair will be generated for each tracked individual. For
        example the file `two_mice.h5` with individuals "mouseA" and "mouseB"
        will yield the pair of keys `'two_mice_mouseA', 'two_mice_mouseB'`.

    - sleap
        .slp and .h5/.hdf5 files generated by sleap. For single-animal tracking,
        each file yields a single key/value pair in the returned `coordinates`
        and `confidences` dictionaries. For multi-animal tracking, a key/vaue
        pair will be generated for each track. For example a single file called
        `two_mice.h5` will yield the pair of keys `'two_mice_track0',
        'two_mice_track1'`.

    - anipose
        .csv files generated by anipose. Each file should contain five columns
        per keypoint (x,y,z,error,score), plus a last column with the frame
        number. The `score` column is used as the keypoint confidence.

    - sleap-anipose
        .h5/.hdf5 files generated by sleap-anipose. Each file should contain a
        dataset called `'tracks'` with shape (n_frames, 1, n_keypoints, 3). If
        there is also a `'point_scores'` dataset, it will be used as the
        keypoint confidence. Otherwise, the confidence will be set to 1.

    - nwb
        .nwb files (Neurodata Without Borders). Each file should contain
        exactly one `PoseEstimation` object (for multi-animal tracking, each
        animal should be stored in its own .nwb file). The `PoseEstimation`
        object should contain one `PoseEstimationSeries` object for each
        bodypart. Confidence values are optional and will be set to 1 if not
        present.

    - facemap
        .h5 files saved by Facemap. See Facemap documentation for details:
        https://facemap.readthedocs.io/en/latest/outputs.html#keypoints-processing
        The files should have the format::

            [filename].h5
            └──Facemap
                ├──keypoint1
                │  ├──x
                │  ├──y
                │  └──likelihood
                ⋮

    - freipose
        .json files saved by FreiPose. Each file should contain a list of dicts
        that each include a "kp_xyz" key with the 3D coordinates for one frame.
        Keypoint scores (saved under "kp_score") are not loaded because they are
        not bounded between 0 and 1, which is required for modeling. Since
        FreiPose does not save the bodypart names, the `bodyparts` return
        value is set to None.

    - dannce
        .mat files saved by Dannce.

    Parameters
    ----------
    filepath_pattern: str or list of str
        Filepath pattern for a set of deeplabcut csv or hdf5 files, or a list
        of such patterns. Filepath patterns can be:

        - single file (e.g. `/path/to/file.csv`)
        - single directory (e.g. `/path/to/dir/`)
        - set of files (e.g. `/path/to/fileprefix*`)
        - set of directories (e.g. `/path/to/dirprefix*`)

    format: str
        Format of the files to load. Must be one of `deeplabcut`, `sleap`,
        `anipose`, or `sleap-anipose`.

    extension: str, default=None
        File extension to use when searching for files. If None, then the
        extension will be inferred from the `format` argument:

        - sleap: 'h5' or 'slp'
        - deeplabcut: 'csv' or 'h5'
        - anipose: 'csv'
        - sleap-anipose: 'h5'
        - nwb: 'nwb'
        - facemap: 'h5'
        - freipose: 'json'
        - dannce: 'mat'

    recursive: bool, default=True
        Whether to search recursively for deeplabcut csv or hdf5 files.

    path_in_name: bool, default=False
        Whether to name the tracking results from each file by the path to the
        file (True) or just the filename (False). If True, the `path_sep`
        argument is used to separate the path components.

    path_sep: str, default='-'
        Separator to use when `path_in_name` is True. For example, if
        `path_sep` is `'-'`, then the tracking results from the file
        `/path/to/file.csv` will be named `path-to-file`. Using `'/'` as the
        separator is discouraged, as it will cause problems saving/loading the
        modeling results to/from hdf5 files.

    remove_extension: bool, default=True
        Whether to remove the file extension when naming the tracking results
        from each file.

    exclude_individuals: list of str, default=["single"]
        List of individuals to exclude from the results. This is only used for
        multi-animal tracking with deeplabcut.

    Returns
    -------
    coordinates: dict
        Dictionary mapping filenames to keypoint coordinates as ndarrays of
        shape (n_frames, n_bodyparts, 2[or 3])

    confidences: dict
        Dictionary mapping filenames to `likelihood` scores as ndarrays of
        shape (n_frames, n_bodyparts)

    bodyparts: list of str
        List of bodypart names. The order of the names matches the order of the
        bodyparts in `coordinates` and `confidences`.
    """
    formats = {
        "deeplabcut": (_deeplabcut_loader, [".csv", ".h5", ".hdf5"]),
        "sleap": (_sleap_loader, [".h5", ".hdf5", ".slp"]),
        "anipose": (_anipose_loader, [".csv"]),
        "sleap-anipose": (_sleap_anipose_loader, [".h5", ".hdf5"]),
        "nwb": (_nwb_loader, [".nwb"]),
        "facemap": (_facemap_loader, [".h5", ".hdf5"]),
        "freipose": (_freipose_loader, [".json"]),
        "dannce": (_dannce_loader, [".mat"]),
    }

    # get format-specific loader and extensions
    assert format in formats, fill(
        f"Unrecognized format '{format}'. Must be one of {list(formats.keys())}"
    )
    loader, extensions = formats[format]

    # optionally override default extension list
    if extension is not None:
        extensions = [extension]

    # optionally add format-specific arguments
    if format == "deeplabcut":
        additional_args = {"exclude_individuals": exclude_individuals}
    else:
        additional_args = {}

    # get list of filepaths
    filepaths = list_files_with_exts(filepath_pattern, extensions, recursive=recursive)
    assert len(filepaths) > 0, fill(
        f"No files with extensions {extensions} found for {filepath_pattern}"
    )

    # load keypoints from each file
    coordinates, confidences, bodyparts = {}, {}, None
    for filepath in tqdm.tqdm(filepaths, desc=f"Loading keypoints", ncols=72):
        name = _name_from_path(filepath, path_in_name, path_sep, remove_extension)

        try:
            new_coordinates, new_confidences, bodyparts = loader(filepath, name, **additional_args)
        except Exception as e:
            print(fill(f"Error loading {filepath}"))
            raise e

        if set(new_coordinates.keys()) & set(coordinates.keys()):
            raise ValueError(
                f"Duplicate names found in {filepath_pattern}:\n\n"
                f"{set(new_coordinates.keys()) & set(coordinates.keys())}"
                f"\n\nThis may be caused by repeated filenames with "
                "different extensions. If so, please set the extension "
                "explicitly via the `extension` argument. Another possible"
                " cause is commonly-named files in different directories. "
                "if that is the case, then set `path_in_name=True`."
            )

        coordinates.update(new_coordinates)
        confidences.update(new_confidences)

    # check for valid results
    assert len(coordinates) > 0, fill(f"No valid results found for {filepath_pattern}")
    check_nan_proportions(coordinates, bodyparts)
    return coordinates, confidences, bodyparts


def _deeplabcut_loader(filepath, name, exclude_individuals=["single"]):
    """Load tracking results from deeplabcut csv or hdf5 files."""
    ext = os.path.splitext(filepath)[1]
    if ext == ".h5":
        df = pd.read_hdf(filepath)
    if ext == ".csv":
        with open(filepath) as f:
            head = list(islice(f, 0, 5))
            if "individuals" in head[1]:
                header = [0, 1, 2, 3]
            else:
                header = [0, 1, 2]
        df = pd.read_csv(filepath, header=header, index_col=0)

    coordinates, confidences = {}, {}
    if "individuals" in df.columns.names:
        ind_bodyparts = {}
        for ind in df.columns.get_level_values("individuals").unique():
            if ind in exclude_individuals:
                print(f'Excluding individual: "{ind}". Set `exclude_individuals=[]` to include.')
            else:
                ind_df = df.xs(ind, axis=1, level="individuals")
                bps = ind_df.columns.get_level_values("bodyparts").unique().tolist()
                ind_bodyparts[ind] = bps

                arr = ind_df.to_numpy().reshape(len(ind_df), -1, 3)
                coordinates[f"{name}_{ind}"] = arr[:, :, :-1]
                confidences[f"{name}_{ind}"] = arr[:, :, -1]

        bodyparts = set(ind_bodyparts[list(ind_bodyparts.keys())[0]])
        assert all([set(bps) == bodyparts for bps in ind_bodyparts.values()]), (
            f"Bodyparts are not consistent across individuals. The following bodyparts "
            f"were found for each individual: {ind_bodyparts}. Use `exclude_individuals`"
            "to exclude specific individuals."
        )
    else:
        bodyparts = df.columns.get_level_values("bodyparts").unique().tolist()
        arr = df.to_numpy().reshape(len(df), -1, 3)
        coordinates[name] = arr[:, :, :-1]
        confidences[name] = arr[:, :, -1]

    return coordinates, confidences, bodyparts


def _sleap_loader(filepath, name):
    """Load keypoints from sleap hdf5 or slp files."""
    if os.path.splitext(filepath)[1] == ".slp":
        slp_file = sleap_io.load_slp(filepath)

        assert len(slp_file.skeletons) == 1, fill(
            f"{filepath} contains more than one skeleton. "
            "This is not currently supported. Please "
            "open a github issue or email calebsw@gmail.com"
        )

        bodyparts = slp_file.skeletons[0].node_names
        arr = slp_file.numpy(return_confidence=True)
        coords = arr[:, :, :, :-1].transpose((1, 0, 2, 3))
        confs = arr[:, :, :, -1].transpose((1, 0, 2))
    else:
        with h5py.File(filepath, "r") as f:
            coords = f["tracks"][()].transpose((0, 3, 2, 1))
            confs = f["point_scores"][()].transpose((0, 2, 1))
            bodyparts = [name.decode("utf-8") for name in f["node_names"]]

    if coords.shape[0] == 1:
        coordinates = {name: coords[0]}
        confidences = {name: confs[0]}
    else:
        coordinates = {f"{name}_track{i}": coords[i] for i in range(coords.shape[0])}
        confidences = {f"{name}_track{i}": confs[i] for i in range(coords.shape[0])}
    return coordinates, confidences, bodyparts


def _anipose_loader(filepath, name):
    """Load keypoints from anipose csv files."""
    with open(filepath, "r") as f:
        header = f.readline()

    pattern = r"(?P<string>\w+)_x,(?P=string)_y,(?P=string)_z"
    bodyparts = list(re.findall(pattern, header))

    df = pd.read_csv(filepath)
    coordinates = {
        name: np.stack(
            [df[[f"{bp}_x", f"{bp}_y", f"{bp}_z"]].to_numpy() for bp in bodyparts],
            axis=1,
        )
    }
    confidences = {name: df[[f"{bp}_score" for bp in bodyparts]].to_numpy()}
    return coordinates, confidences, bodyparts


def _sleap_anipose_loader(filepath, name):
    """Load keypoints from sleap-anipose hdf5 files."""
    with h5py.File(filepath, "r") as f:
        coords = f["tracks"][()]
        if "point_scores" in f.keys():
            confs = f["point_scores"][()]
        else:
            confs = np.ones_like(coords[..., 0])
        bodyparts = ["bodypart{}".format(i) for i in range(coords.shape[2])]
        if coords.shape[1] == 1:
            coordinates = {name: coords[:, 0]}
            confidences = {name: confs[:, 0]}
        else:
            coordinates = {f"{name}_track{i}": coords[:, i] for i in range(coords.shape[1])}
            confidences = {f"{name}_track{i}": confs[:, i] for i in range(coords.shape[1])}
    return coordinates, confidences, bodyparts


def _load_nwb_pose_obj(io, filepath):
    """Grab PoseEstimation object from an opened .nwb file."""
    all_objs = io.read().all_children()
    pose_objs = [o for o in all_objs if isinstance(o, PoseEstimation)]
    assert len(pose_objs) > 0, fill(f"No PoseEstimation objects found in {filepath}")
    assert len(pose_objs) == 1, fill(
        f"Found multiple PoseEstimation objects in {filepath}. "
        "This is not currently supported. Please open a github "
        "issue to request this feature."
    )
    pose_obj = pose_objs[0]
    return pose_obj


def _nwb_loader(filepath, name):
    """Load keypoints from nwb files."""
    with NWBHDF5IO(filepath, mode="r", load_namespaces=True) as io:
        pose_obj = _load_nwb_pose_obj(io, filepath)
        bodyparts = list(pose_obj.nodes[:])
        coords = np.stack(
            [pose_obj.pose_estimation_series[bp].data[()] for bp in bodyparts],
            axis=1,
        )
        if "confidence" in pose_obj.pose_estimation_series[bodyparts[0]].fields:
            confs = np.stack(
                [pose_obj.pose_estimation_series[bp].confidence[()] for bp in bodyparts],
                axis=1,
            )
        else:
            confs = np.ones_like(coords[..., 0])
        coordinates = {name: coords}
        confidences = {name: confs}
    return coordinates, confidences, bodyparts


def _facemap_loader(filepath, name):
    """Load keypoints from facemap h5 files."""
    with h5py.File(filepath, "r") as h5:
        dset = h5["Facemap"]
        bodyparts = sorted(dset.keys())
        coords, confs = [], []
        for bp in bodyparts:
            coords.append(np.stack([dset[bp]["x"], dset[bp]["y"]], axis=1))
            confs.append(dset[bp]["likelihood"])
        coordinates = {name: np.stack(coords, axis=1)}
        confidences = {name: np.stack(confs, axis=1)}
    return coordinates, confidences, bodyparts


def _freipose_loader(filepath, name):
    """Load keypoints from freipose json files."""
    with open(filepath, "r") as f:
        data = json.load(f)
    coords = np.concatenate([d["kp_xyz"] for d in data], axis=0)
    coordinates = {name: coords}
    confidences = {name: np.ones_like(coords[..., 0])}
    return coordinates, confidences, None


def _dannce_loader(filepath, name):
    """Load keypoints from dannce mat files."""
    mat = loadmat(filepath)
    coords = mat["pred"].transpose((0, 2, 1))
    confs = np.ones_like(coords[..., 0])
    coordinates = {name: coords}
    confidences = {name: confs}
    return coordinates, confidences, None


def save_hdf5(filepath, save_dict, datapath=None):
    """Save a dict of pytrees to an hdf5 file. The leaves of the pytrees must
    be numpy arrays, scalars, or strings.

    Parameters
    ----------
    filepath: str
        Path of the hdf5 file to create.

    save_dict: dict
        Dictionary where the values are pytrees, i.e. recursive collections of
        tuples, lists, dicts, and numpy arrays.

    datapath: str, default=None
        Path within the hdf5 file to save the data. If None, the data is saved
        at the root of the hdf5 file.
    """
    with h5py.File(filepath, "a") as f:
        if datapath is not None:
            _savetree_hdf5(jax.device_get(save_dict), f, datapath)
        else:
            for k, tree in save_dict.items():
                _savetree_hdf5(jax.device_get(tree), f, k)


def load_hdf5(filepath, datapath=None):
    """Load a dict of pytrees from an hdf5 file.

    Parameters
    ----------
    filepath: str
        Path of the hdf5 file to load.

    datapath: str, default=None
        Path within the hdf5 file to load the data from. If None, the data is
        loaded from the root of the hdf5 file.

    Returns
    -------
    save_dict: dict
        Dictionary where the values are pytrees, i.e. recursive collections of
        tuples, lists, dicts, and numpy arrays.
    """
    with h5py.File(filepath, "r") as f:
        if datapath is None:
            return {k: _loadtree_hdf5(f[k]) for k in f}
        else:
            return _loadtree_hdf5(f[datapath])


def _savetree_hdf5(tree, group, name):
    """Recursively save a pytree to an h5 file group."""
    if name in group:
        del group[name]
    if isinstance(tree, np.ndarray):
        if tree.dtype.kind == "U":
            dt = h5py.special_dtype(vlen=str)
            group.create_dataset(name, data=tree.astype(object), dtype=dt)
        else:
            group.create_dataset(name, data=tree)
    elif isinstance(tree, (float, int, str)):
        group.create_dataset(name, data=tree)
    else:
        subgroup = group.create_group(name)
        subgroup.attrs["type"] = type(tree).__name__

        if isinstance(tree, (tuple, list)):
            for k, subtree in enumerate(tree):
                _savetree_hdf5(subtree, subgroup, f"arr{k}")
        elif isinstance(tree, dict):
            for k, subtree in tree.items():
                _savetree_hdf5(subtree, subgroup, k)
        else:
            raise ValueError(f"Unrecognized type {type(tree)}")


def _loadtree_hdf5(leaf):
    """Recursively load a pytree from an h5 file group."""
    if isinstance(leaf, h5py.Dataset):
        data = np.array(leaf[()])
        if h5py.check_dtype(vlen=data.dtype) == str:
            data = np.array([item.decode("utf-8") for item in data])
        elif data.dtype.kind == "S":
            data = data.item().decode("utf-8")
        elif data.shape == ():
            data = data.item()
        return data
    else:
        leaf_type = leaf.attrs["type"]
        values = map(_loadtree_hdf5, leaf.values())
        if leaf_type == "dict":
            return dict(zip(leaf.keys(), values))
        elif leaf_type == "list":
            return list(values)
        elif leaf_type == "tuple":
            return tuple(values)
        else:
            raise ValueError(f"Unrecognized type {leaf_type}")


--- File: keypoint_moseq/__init__.py ---
# use double-precision by default
from jax import config

config.update("jax_enable_x64", True)

# simple warning formatting
import warnings

warnings.formatwarning = lambda msg, *a: str(msg)

from .io import *
from .viz import *
from .util import *
from .fitting import *
from .analysis import *
from .calibration import noise_calibration

from jax_moseq.models.keypoint_slds import fit_pca
from jax_moseq.utils import get_frequencies, get_durations

from . import _version

__version__ = _version.get_versions()["version"]


--- File: keypoint_moseq/fitting.py ---
import os
import numpy as np
import tqdm
import h5py
import jax
import jax.numpy as jnp
import warnings
from textwrap import fill
from datetime import datetime

from keypoint_moseq.viz import plot_progress
from keypoint_moseq.io import save_hdf5, extract_results, load_checkpoint
from jax_moseq.models import allo_keypoint_slds, keypoint_slds
from jax_moseq.models.arhmm import stateseq_marginals, marginal_log_likelihood
from jax_moseq.utils.autoregression import get_nlags
from jax_moseq.utils import check_for_nans, device_put_as_scalar, unbatch


class StopResampling(Exception):
    pass


def _wrapped_resample(resample_func, data, model, pbar=None, **resample_options):
    try:
        model = resample_func(data, **model, **resample_options)
    except KeyboardInterrupt:
        print("Early termination of fitting: user interruption")
        raise StopResampling()

    any_nans, nan_info, messages = check_for_nans(model)

    if any_nans:
        if pbar is not None:
            pbar.close()
        warning_text = ["\nEarly termination of fitting: NaNs encountered"]
        for msg in messages:
            warning_text.append("  - {}".format(msg))
        warning_text.append(
            "\nFor additional information, see https://keypoint-moseq.readthedocs.io/en/latest/troubleshooting.html#nans-during-fitting"
        )
        warnings.warn("\n".join(warning_text))
        raise StopResampling()

    return model


def _set_parallel_flag(parallel_message_passing):
    if parallel_message_passing == "force":
        parallel_message_passing = True
    elif parallel_message_passing is None:
        parallel_message_passing = jax.default_backend() != "cpu"
    elif parallel_message_passing and jax.default_backend() == "cpu":
        warnings.warn(
            fill(
                "Setting parallel_message_passing to True when JAX is CPU-bound can "
                "result in long jit times without speed increase for calculations. "
                '(To suppress this message, set parallel_message_passing="force")'
            )
        )
    return parallel_message_passing


def init_model(*args, location_aware=False, allo_hypparams=None, trans_hypparams=None, **kwargs):
    """Initialize a model. Wrapper for `jax_moseq.models.keypoint_slds.init_model`
    and `jax_moseq.models.allo_keypoint_slds.init_model`.

    Parameters
    ----------
    location_aware : bool, default=False
        If True, the model will be initialized using the location-aware version
        of the keypoint-SLDS model (`jax_moseq.models.allo_keypoint_slds`).

    allo_hypparams : dict, default=None
        Hyperparameters for the `allo_keypoint_slds` model. If None, default
        hyperparameters will be used.

    Returns
    -------
    model : dict
        Model dictionary containing states, parameters, hyperparameters, noise
        prior, and random seed.
    """
    if location_aware:
        num_states = trans_hypparams["num_states"]
        allo_hypparams = {
            "alpha0_v": 10,
            "beta0_v": 0.1,
            "lambda0_v": 1,
            "alpha0_h": 10,
            "beta0_h": 0.1,
            "lambda0_h": 1,
            "num_states": num_states,
        }

        return allo_keypoint_slds.init_model(
            *args,
            allo_hypparams=allo_hypparams,
            trans_hypparams=trans_hypparams,
            **kwargs,
        )
    else:
        return keypoint_slds.init_model(*args, trans_hypparams=trans_hypparams, **kwargs)


def fit_model(
    model,
    data,
    metadata,
    project_dir=None,
    model_name=None,
    num_iters=50,
    start_iter=0,
    verbose=False,
    ar_only=False,
    parallel_message_passing=None,
    jitter=0.001,
    generate_progress_plots=True,
    save_every_n_iters=25,
    location_aware=False,
    **kwargs,
):
    """Fit a model to data.

    This method optionally:
        - saves checkpoints of the model and data at regular intervals
        - plots of the model's progress during fitting (see
          :py:func:`jax_moseq.viz.plot_progress`)

    Note that if a checkpoint file already exists, all model snapshots after
    `start_iter` will be deleted.

    Parameters
    ----------
    model : dict
        Model dictionary containing states, parameters, hyperparameters, noise
        prior, and random seed.

    data: dict
        Data for model fitting (see :py:func:`keypoint_moseq.io.format_data`).

    metadata: tuple (keys, bounds)
        Recordings and start/end frames for the data (see
        :py:func:`keypoint_moseq.io.format_data`).

    project_dir : str, default=None
        Project directory; required if `save_every_n_iters>0`.

    model_name : str, default=None
        Name of the model. If None, the model is named using the current date
        and time.

    num_iters : int, default=50
        Number of Gibbs sampling iterations to run.

    start_iter : int, default=0
        Index of the starting iteration, which is non-zero when continuing a
        previous fit.

    verbose : bool, default=True
        If True, print the model's progress during fitting.

    ar_only : bool, default=False
        If True, fit an AR-HMM model using the latent trajectory defined by
        `model['states']['x']` (see
        :py:func:`jax_moseq.models.arhmm.resample_model`).
        Otherwise fit a full keypoint-SLDS model (see
        :py:func:`jax_moseq.models.keypoint_slds.resample_model`)

    save_every_n_iters : int, default=25
        Save the current model every `save_every_n_iters`. To only save the
        final model, set `save_every_n_iter=-1`. To save nothing, set
        `save_every_n_iters=None`.

    generate_progress_plots : bool, default=True
        If True, generate plots of the model's progress during fitting. Plots
        are saved to `{project_dir}/{model_name}/plots/`.

    parallel_message_passing : bool | string, default=None,
        Use parallel implementation of Kalman sampling, which can be faster but
        has a significantly longer jit time. If None, will be set automatically
        based on the backend (True for GPU, False for CPU). A warning will be
        raised if `parallel_message_passing=True` and JAX is CPU-bound. Set to
        'force' to skip this check.

    jitter : float, default=0.001
        Amount to boost the diagonal of the dynamics covariance matrix when
        resampling pose trajectories. Increasing this value can help prevent
        NaNs during fitting.

    location_aware : bool, default=False
        If True, the model will be fit using the location-aware version of the
        keypoint-SLDS model (`jax_moseq.models.allo_keypoint_slds`).

    Returns
    -------
    model : dict
        Model dictionary containing states, parameters, hyperparameters, noise
        prior, and random seed.

    model_name : str
        Name of the model.
    """
    if generate_progress_plots and save_every_n_iters == 0:
        warnings.warn(
            fill(
                "The `generate_progress_plots` option requires that "
                "`save_every_n_iters` be greater than 0. Progress plots will "
                "not be generated."
            )
        )
        generate_progress_plots = False

    if model_name is None:
        model_name = str(datetime.now().strftime("%Y_%m_%d-%H_%M_%S"))

    if save_every_n_iters is not None:
        savedir = os.path.join(project_dir, model_name)
        if not os.path.exists(savedir):
            os.makedirs(savedir)
        print(fill(f"Outputs will be saved to {savedir}"))

        checkpoint_path = os.path.join(savedir, "checkpoint.h5")
        if not os.path.exists(checkpoint_path):
            save_hdf5(
                checkpoint_path,
                {
                    "model_snapshots": {f"{start_iter}": model},
                    "metadata": metadata,
                    "data": data,
                },
            )
        else:  # delete model snapshots later than start_iter
            with h5py.File(checkpoint_path, "a") as f:
                for k in list(f["model_snapshots"].keys()):
                    if int(k) > start_iter:
                        del f["model_snapshots"][k]

    parallel_message_passing = _set_parallel_flag(parallel_message_passing)
    model = device_put_as_scalar(model)

    if location_aware:
        resample_func = allo_keypoint_slds.resample_model
    else:
        resample_func = keypoint_slds.resample_model

    with tqdm.trange(start_iter, num_iters + 1, ncols=72) as pbar:
        for iteration in pbar:
            try:
                model = _wrapped_resample(
                    resample_func,
                    data,
                    model,
                    pbar=pbar,
                    ar_only=ar_only,
                    verbose=verbose,
                    jitter=jitter,
                    parallel_message_passing=parallel_message_passing,
                )
            except StopResampling:
                break

            if save_every_n_iters is not None and iteration > start_iter:
                if iteration == num_iters or (
                    save_every_n_iters > 0 and iteration % save_every_n_iters == 0
                ):
                    save_hdf5(checkpoint_path, model, f"model_snapshots/{iteration}")
                    if generate_progress_plots:
                        plot_progress(
                            model,
                            data,
                            checkpoint_path,
                            iteration,
                            project_dir,
                            model_name,
                            savefig=True,
                        )

    return model, model_name


def apply_model(
    model,
    data,
    metadata,
    project_dir=None,
    model_name=None,
    num_iters=500,
    ar_only=False,
    save_results=True,
    verbose=False,
    results_path=None,
    parallel_message_passing=None,
    return_model=False,
    location_aware=False,
    **kwargs,
):
    """Apply a model to new data.

    Parameters
    ----------
    model : dict
        Model dictionary containing states, parameters, hyperparameters, noise
        prior, and random seed.

    data: dict
        Data for model fitting (see :py:func:`keypoint_moseq.io.format_data`).

    metadata: tuple (keys, bounds)
        Recordings and start/end frames for the data (see
        :py:func:`keypoint_moseq.io.format_data`).

    project_dir : str, default=None
        Path to the project directory. Required if `save_results=True` and
        `results_path=None`.

    model_name : str, default=None
        Name of the model. Required if `save_results=True` and
        `results_path=None`.

    num_iters : int, default=500
        Number of iterations to run the model.

    ar_only : bool, default=False
        See :py:func:`keypoint_moseq.fitting.fit_model`.

    save_results : bool, default=True
        If True, the model outputs will be saved to disk (see
        :py:func:`keypoint_moseq.io.extract_results` for the output format).

    verbose : bool, default=False
        Whether to print progress updates.

    results_path : str, default=None
        Optional path for saving model outputs.

    parallel_message_passing : bool | string, default=None,
        Use parallel implementation of Kalman sampling, which can be faster
        but has a significantly longer jit time. If None, will be set
        automatically based on the backend (True for GPU, False for CPU). A
        warning will be raised if `parallel_message_passing=True` and JAX is
        CPU-bound. Set to 'force' to skip this check.

    return_model : bool, default=False
        Whether to return the model after fitting.

    location_aware : bool, default=False
        If True, the model will be fit using the location-aware version of the
        keypoint-SLDS model (`jax_moseq.models.allo_keypoint_slds`).

    Returns
    -------
    results : dict
        Dictionary of model outputs (for results format, see
        :py:func:`keypoint_moseq.io.extract_results`).

    model : dict
        Model dictionary containing states, parameters, hyperparameters, noise
        prior, and random seed. Only returned if `return_model=True`.
    """
    parallel_message_passing = _set_parallel_flag(parallel_message_passing)
    data = jax.device_put(data)

    if save_results:
        if results_path is None:
            assert project_dir is not None and model_name is not None, fill(
                "The `save_results` option requires either a `results_path` "
                "or the `project_dir` and `model_name` arguments"
            )
            results_path = os.path.join(project_dir, model_name, "results.h5")

    model = init_model(
        data=data,
        seed=model["seed"],
        params=model["params"],
        hypparams=model["hypparams"],
        location_aware=location_aware,
        **kwargs,
    )

    if location_aware:
        resample_func = allo_keypoint_slds.resample_model
    else:
        resample_func = keypoint_slds.resample_model

    with tqdm.trange(num_iters, desc="Applying model", ncols=72) as pbar:
        for iteration in pbar:
            try:
                model = _wrapped_resample(
                    resample_func,
                    data,
                    model,
                    pbar=pbar,
                    ar_only=ar_only,
                    states_only=True,
                    verbose=verbose,
                    parallel_message_passing=parallel_message_passing,
                )
            except StopResampling:
                break

    results = extract_results(model, metadata, project_dir, model_name, save_results, results_path)

    if return_model:
        return results, model
    else:
        return results


def estimate_syllable_marginals(
    model,
    data,
    metadata,
    burn_in_iters=200,
    num_samples=100,
    steps_per_sample=10,
    return_samples=False,
    verbose=False,
    parallel_message_passing=None,
    location_aware=False,
    **kwargs,
):
    """Estimate marginal distributions over syllables.

    Parameters
    ----------
    model : dict
        Model dictionary containing states, parameters, hyperparameters, noise
        prior, and random seed.

    data: dict
        Data for model fitting (see :py:func:`keypoint_moseq.io.format_data`).

    metadata: tuple (keys, bounds)
        Recordings and start/end frames for the data (see
        :py:func:`keypoint_moseq.io.format_data`).

    burn_in_iters : int, default=200
        Number of resampling iterations to run before collecting samples.

    num_samples : int, default=100
        Number of samples to collect for marginalization.

    steps_per_sample : int, default=10
        Number of resampling iterations to run between collecting samples.

    return_samples : bool, default=False
        Whether to store and return sampled syllable sequences. May require
        significant RAM.

    verbose : bool, default=False
        Whether to print progress updates.

    parallel_message_passing : bool | string, default=None,
        Use parallel implementation of Kalman sampling, which can be faster
        but has a significantly longer jit time. If None, will be set
        automatically based on the backend (True for GPU, False for CPU). A
        warning will be raised if `parallel_message_passing=True` and JAX is
        CPU-bound. Set to 'force' to skip this check.

    location_aware : bool, default=False
        If True, the model will be fit using the location-aware version of the
        keypoint-SLDS model (`jax_moseq.models.allo_keypoint_slds`).

    Returns
    -------
    marginal_estimates : dict
        Estimated marginal distributions over syllables in the form of a
        dictionary mapping recoriding names to arrays of shape
        ``(num_timepoints, num_syllables)``.

    samples : dict
        Sampled syllable sequences in the form of a dictionary mapping
        recording names to arrays of shape ``(num_samples, num_timepoints)``.
        Only returned if `return_samples=True`.
    """
    parallel_message_passing = _set_parallel_flag(parallel_message_passing)
    data = jax.device_put(data)

    model = init_model(
        data=data,
        seed=model["seed"],
        params=model["params"],
        hypparams=model["hypparams"],
        **kwargs,
    )

    num_syllables = model["hypparams"]["trans_hypparams"]["num_states"]
    marginal_estimates = np.zeros((*model["states"]["z"].shape, num_syllables))
    samples = []

    if location_aware:
        resample_func = allo_keypoint_slds.resample_model
    else:
        resample_func = keypoint_slds.resample_model

    total_iters = burn_in_iters + num_samples * steps_per_sample
    with tqdm.trange(total_iters, desc="Applying model", ncols=72) as pbar:
        for iteration in pbar:
            try:
                model = _wrapped_resample(
                    resample_func,
                    data,
                    model,
                    pbar=pbar,
                    states_only=True,
                    verbose=verbose,
                    parallel_message_passing=parallel_message_passing,
                )
            except StopResampling:
                break

            if iteration >= burn_in_iters and (iteration - burn_in_iters) % steps_per_sample == 0:
                marginal_estimates += np.array(
                    stateseq_marginals(model["states"]["x"], data["mask"], **model["params"])
                )
                if return_samples:
                    samples.append(np.array(model["states"]["z"]))

    nlags = get_nlags(model["params"]["Ab"])
    keys, bounds = metadata
    bounds = bounds + np.array([nlags, 0])
    marginal_estimates = unbatch(marginal_estimates / num_samples, keys, bounds)
    marginal_estimates = {
        k: np.pad(v[nlags:], ((nlags, 0), (0, 0)), mode="edge")
        for k, v in marginal_estimates.items()
    }
    if return_samples:
        samples = unbatch(np.moveaxis(samples, 0, 2), keys, bounds)
        samples = {
            k: np.pad(v[nlags:], ((nlags, 0), (0, 0)), mode="edge") for k, v in samples.items()
        }
        return marginal_estimates, samples
    else:
        return marginal_estimates


def update_hypparams(model_dict, **kwargs):
    """Edit the hyperparameters of a model.

    Hyperparameters are stored as a nested dictionary in the `hypparams` key of
    the model dictionary. This function allows the user to update the
    hyperparameters of a model by passing in keyword arguments with the same
    name as the hyperparameter. The hyperparameter will be updated if it is a
    scalar value.

    Parameters
    ----------
    model_dict : dict
        Model dictionary.

    kwargs : dict
        Keyword arguments mapping hyperparameter names to new values.

    Returns
    -------
    model_dict : dict
        Model dictionary with updated hyperparameters.
    """
    assert "hypparams" in model_dict, fill(
        "The inputted model/checkpoint does not contain any hyperparams"
    )

    not_updated = list(kwargs.keys())

    for hypparms_group in model_dict["hypparams"]:
        for k, v in kwargs.items():
            if k in model_dict["hypparams"][hypparms_group]:
                old_value = model_dict["hypparams"][hypparms_group][k]
                if not np.isscalar(old_value):
                    print(fill(f"{k} cannot be updated since it is not a scalar hyperparam"))
                else:
                    if not isinstance(v, type(old_value)):
                        warnings.warn(f"'{k}' with {type(v)} will be cast to {type(old_value)}")

                    model_dict["hypparams"][hypparms_group][k] = type(old_value)(v)
                    not_updated.remove(k)

    if len(not_updated) > 0:
        warnings.warn(fill(f"The following hypparams were not found {not_updated}"))

    return model_dict


def expected_marginal_likelihoods(project_dir=None, model_names=None, checkpoint_paths=None):
    """Calculate the expected marginal likelihood score for each model.

    The score is calculated as follows, where theta^i denotes the
    autoregressive parameters and transition matrix for the i'th model,
    x^i denotes the latent trajectories for the i'th model, and the
    number of models is N:

    score(theta^i) = 1/(N-1) sum_{j ≠ i} P(x^j | theta^i)

    Parameters
    ----------
    project_dir : str
        Path to the project directory. Required if ``checkpoint_paths`` is None.

    model_names : list of str
        Names of the models to compare. Required if ``checkpoint_paths`` is None.

    checkpoint_paths : list of str
        Paths to the checkpoints to compare. Required if ``model_names`` and
        ``project_dir`` are None.

    Returns
    -------
    scores : numpy array
        Expected marginal likelihood score for each model.

    standard_errors : numpy array
        Standard error of the expected marginal likelihood score for each model.
    """
    if checkpoint_paths is None:
        assert project_dir is not None and model_names is not None, fill(
            "Must provide either `checkpoint_paths` or `project_dir` and `model_names`"
        )
        checkpoint_paths = [
            os.path.join(project_dir, model_name, "checkpoint.h5") for model_name in model_names
        ]

    xs, params = [], []
    for checkpoint_path in checkpoint_paths:
        model, data, _, _ = load_checkpoint(path=checkpoint_path)
        xs.append(model["states"]["x"])
        params.append(model["params"])

    num_models = len(xs)
    mlls = np.zeros((num_models, num_models))
    for i in tqdm.trange(num_models, ncols=72):
        for j in range(num_models):
            if i != j:
                mlls[i, j] = marginal_log_likelihood(
                    jnp.array(data["mask"]),
                    jnp.array(xs[j]),
                    jnp.array(params[i]["Ab"]),
                    jnp.array(params[i]["Q"]),
                    jnp.array(params[i]["pi"]),
                ).item()

    scores = mlls.sum(1) / (num_models - 1)
    variances = (mlls**2).sum(1) / (num_models - 1) - scores**2
    standard_errors = np.sqrt(variances / (num_models - 1))
    return scores, standard_errors


--- File: keypoint_moseq/viz.py ---
import os
import cv2
import tqdm
import imageio
import warnings
import logging
import h5py
import numpy as np
import plotly
import matplotlib.pyplot as plt
from scipy.ndimage import gaussian_filter1d
from vidio.read import OpenCVReader
from scipy.spatial.distance import squareform, pdist
from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list

from textwrap import fill
from PIL import Image
from keypoint_moseq.util import *
from keypoint_moseq.io import load_results, _get_path
from jax_moseq.models.keypoint_slds import center_embedding
from jax_moseq.utils import get_durations, get_frequencies

from plotly.subplots import make_subplots
import plotly.io as pio

pio.renderers.default = "iframe"

# set matplotlib defaults
plt.rcParams["figure.dpi"] = 100

# suppress warnings from imageio
logging.getLogger().setLevel(logging.ERROR)


def crop_image(image, centroid, crop_size):
    """Crop an image around a centroid.

    Parameters
    ----------
    image: ndarray of shape (height, width, 3)
        Image to crop.

    centroid: tuple of int
        (x,y) coordinates of the centroid.

    crop_size: int or tuple(int,int)
        Size of the crop around the centroid. Either a single int for a square
        crop, or a tuple of ints (w,h) for a rectangular crop.


    Returns
    -------
    image: ndarray of shape (crop_size, crop_size, 3)
        Cropped image.
    """
    if isinstance(crop_size, tuple):
        w, h = crop_size
    else:
        w, h = crop_size, crop_size
    x, y = int(centroid[0]), int(centroid[1])

    x_min = max(0, x - w // 2)
    y_min = max(0, y - h // 2)
    x_max = min(image.shape[1], x + w // 2)
    y_max = min(image.shape[0], y + h // 2)

    cropped = image[y_min:y_max, x_min:x_max]
    padded = np.zeros((h, w, *image.shape[2:]), dtype=image.dtype)
    pad_x = max(w // 2 - x, 0)
    pad_y = max(h // 2 - y, 0)
    padded[pad_y : pad_y + cropped.shape[0], pad_x : pad_x + cropped.shape[1]] = cropped
    return padded


def plot_scree(pca, savefig=True, project_dir=None, fig_size=(3, 2)):
    """Plot explained variance as a function of the number of PCs.

    Parameters
    ----------
    pca : :py:func:`sklearn.decomposition.PCA`
        Fitted PCA model

    savefig : bool, True
        Whether to save the figure to a file. If true, the figure is saved to
        `{project_dir}/pca_scree.pdf`.

    project_dir : str, default=None
        Path to the project directory. Required if `savefig` is True.

    fig_size : tuple, (2.5,2)
        Size of the figure in inches.

    Returns
    -------
    fig : :py:class:`matplotlib.figure.Figure`
        Figure handle
    """
    fig = plt.figure()
    num_pcs = len(pca.components_)
    plt.plot(np.arange(num_pcs) + 1, np.cumsum(pca.explained_variance_ratio_))
    plt.xlabel("PCs")
    plt.ylabel("Explained variance")
    plt.gcf().set_size_inches(fig_size)
    plt.grid()
    plt.tight_layout()

    if savefig:
        assert project_dir is not None, fill("The `savefig` option requires a `project_dir`")
        plt.savefig(os.path.join(project_dir, "pca_scree.pdf"))
    plt.show()
    return fig


def plot_pcs(
    pca,
    *,
    use_bodyparts,
    skeleton,
    keypoint_colormap="autumn",
    keypoint_colors=None,
    savefig=True,
    project_dir=None,
    scale=1,
    plot_n_pcs=10,
    axis_size=(2, 1.5),
    ncols=5,
    node_size=30.0,
    line_width=2.0,
    interactive=True,
    **kwargs,
):
    """
    Visualize the components of a fitted PCA model.

    For each PC, a subplot shows the mean pose (semi-transparent) along with a
    perturbation of the mean pose in the direction of the PC.

    Parameters
    ----------
    pca : :py:func:`sklearn.decomposition.PCA`
        Fitted PCA model

    use_bodyparts : list of str
        List of bodyparts to that are used in the model; used to index bodypart
        names in the skeleton.

    skeleton : list
        List of edges that define the skeleton, where each edge is a pair of
        bodypart names.

    keypoint_colormap : str
        Name of a matplotlib colormap to use for coloring the keypoints.

    keypoint_colors : array-like, shape=(num_keypoints,3), default=None
        Color for each keypoint. If None, `keypoint_colormap` is used. If the
        dtype is int, the values are assumed to be in the range 0-255,
        otherwise they are assumed to be in the range 0-1.

    savefig : bool, True
        Whether to save the figure to a file. If true, the figure is saved to
        `{project_dir}/pcs-{xy/xz/yz}.pdf` (`xz` and `yz` are only included
        for 3D data).

    project_dir : str, default=None
        Path to the project directory. Required if `savefig` is True.

    scale : float, default=0.5
        Scale factor for the perturbation of the mean pose.

    plot_n_pcs : int, default=10
        Number of PCs to plot.

    axis_size : tuple of float, default=(2,1.5)
        Size of each subplot in inches.

    ncols : int, default=5
        Number of columns in the figure.

    node_size : float, default=30.0
        Size of the keypoints in the figure.

    line_width: float, default=2.0
        Width of edges in skeleton

    interactive : bool, default=True
        For 3D data, whether to generate an interactive 3D plot.
    """
    k = len(use_bodyparts)
    d = len(pca.mean_) // (k - 1)

    if keypoint_colors is None:
        cmap = plt.cm.get_cmap(keypoint_colormap)
        keypoint_colors = cmap(np.linspace(0, 1, k))

    Gamma = np.array(center_embedding(k))
    edges = get_edges(use_bodyparts, skeleton)
    plot_n_pcs = min(plot_n_pcs, pca.components_.shape[0])

    magnitude = np.sqrt((pca.mean_**2).mean()) * scale
    ymean = Gamma @ pca.mean_.reshape(k - 1, d)
    ypcs = (pca.mean_ + magnitude * pca.components_).reshape(-1, k - 1, d)
    ypcs = Gamma[np.newaxis] @ ypcs[:plot_n_pcs]

    if d == 2:
        dims_list, names = [[0, 1]], ["xy"]
    if d == 3:
        dims_list, names = [[0, 1], [0, 2]], ["xy", "xz"]

    for dims, name in zip(dims_list, names):
        nrows = int(np.ceil(plot_n_pcs / ncols))
        fig, axs = plt.subplots(nrows, ncols, sharex=True, sharey=True)
        for i, ax in enumerate(axs.flat):
            if i >= plot_n_pcs:
                ax.axis("off")
                continue

            for e in edges:
                ax.plot(
                    *ymean[:, dims][e].T,
                    color=keypoint_colors[e[0]],
                    zorder=0,
                    alpha=0.25,
                    linewidth=line_width,
                )
                ax.plot(
                    *ypcs[i][:, dims][e].T,
                    color="k",
                    zorder=2,
                    linewidth=line_width + 0.2,
                )
                ax.plot(
                    *ypcs[i][:, dims][e].T,
                    color=keypoint_colors[e[0]],
                    zorder=3,
                    linewidth=line_width,
                )

            ax.scatter(
                *ymean[:, dims].T,
                c=keypoint_colors,
                s=node_size,
                zorder=1,
                alpha=0.25,
                linewidth=0,
            )
            ax.scatter(
                *ypcs[i][:, dims].T,
                c=keypoint_colors,
                s=node_size,
                zorder=4,
                edgecolor="k",
                linewidth=0.2,
            )

            ax.set_title(f"PC {i+1}", fontsize=10)
            ax.set_aspect("equal")
            ax.axis("off")

        fig.set_size_inches((axis_size[0] * ncols, axis_size[1] * nrows))
        plt.tight_layout()

        if savefig:
            assert project_dir is not None, fill("The `savefig` option requires a `project_dir`")
            plt.savefig(os.path.join(project_dir, f"pcs-{name}.pdf"))
        plt.show()

    if interactive and d == 3:
        plot_pcs_3D(
            ymean,
            ypcs,
            edges,
            keypoint_colormap,
            project_dir if savefig else None,
            node_size / 3,
            line_width * 2,
        )


def plot_syllable_frequencies(
    project_dir=None,
    model_name=None,
    results=None,
    path=None,
    minlength=10,
    min_frequency=0.005,
):
    """Plot a histogram showing the frequency of each syllable.

    Caller must provide a results dictionary, a path to a results .h5, or a
    project directory and model name, in which case the results are loaded
    from `{project_dir}/{model_name}/results.h5`.

    Parameters
    ----------
    results : dict, default=None
        Dictionary containing modeling results for a dataset (see
        :py:func:`keypoint_moseq.fitting.extract_results`)

    model_name: str, default=None
        Name of the model. Required to load results if `results` is None and
        `path` is None.

    project_dir: str, default=None
        Project directory. Required to load results if `results` is None and
        `path` is None.

    path: str, default=None
        Path to a results file. If None, results will be loaded from
        `{project_dir}/{model_name}/results.h5`.

    minlength: int, default=10
        Minimum x-axis length of the histogram.

    min_frequency: float, default=0.005
        Minimum frequency of syllables to include in the histogram.

    Returns
    -------
    fig : matplotlib.figure.Figure
        Figure containing the histogram.

    ax : matplotlib.axes.Axes
        Axes containing the histogram.
    """
    if results is None:
        results = load_results(project_dir, model_name, path)

    syllables = {k: res["syllable"] for k, res in results.items()}
    frequencies = get_frequencies(syllables)
    frequencies = frequencies[frequencies > min_frequency]
    xmax = max(minlength, np.max(np.nonzero(frequencies > min_frequency)[0]) + 1)

    fig, ax = plt.subplots()
    ax.bar(range(len(frequencies)), frequencies, width=1)
    ax.set_ylabel("probability")
    ax.set_xlabel("syllable rank")
    ax.set_xlim(-1, xmax + 1)
    ax.set_title("Frequency distribution")
    ax.set_yticks([])
    return fig, ax


def plot_duration_distribution(
    project_dir=None,
    model_name=None,
    results=None,
    path=None,
    lim=None,
    num_bins=30,
    fps=None,
    show_median=True,
):
    """Plot a histogram showing the frequency of each syllable.

    Caller must provide a results dictionary, a path to a results .h5, or a
    project directory and model name, in which case the results are loaded from
    `{project_dir}/{model_name}/results.h5`.

    Parameters
    ----------
    results : dict, default=None
        Dictionary containing modeling results for a dataset (see
        :py:func:`keypoint_moseq.fitting.extract_results`)

    model_name: str, default=None
        Name of the model. Required to load results if `results` is None and
        `path` is None.

    project_dir: str, default=None
        Project directory. Required to load results if `results` is None and
        `path` is None.

    path: str, default=None
        Path to a results file. If None, results will be loaded from
        `{project_dir}/{model_name}/results.h5`.

    lim: tuple, default=None
        x-axis limits as a pair of ints (in units of frames). If None, the
        limits are set to (0, 95th-percentile).

    num_bins: int, default=30
        Number of bins in the histogram.

    fps: int, default=None
        Frames per second. Used to convert x-axis from frames to seconds.

    show_median: bool, default=True
        Whether to show the median duration as a vertical line.

    Returns
    -------
    fig : matplotlib.figure.Figure
        Figure containing the histogram.

    ax : matplotlib.axes.Axes
        Axes containing the histogram.
    """
    if results is None:
        results = load_results(project_dir, model_name, path)

    syllables = {k: res["syllable"] for k, res in results.items()}
    durations = get_durations(syllables)

    if lim is None:
        lim = int(np.percentile(durations, 95))
    binsize = max(int(np.floor(lim / num_bins)), 1)

    if fps is not None:
        durations = durations / fps
        binsize = binsize / fps
        lim = lim / fps
        xlabel = "syllable duration (s)"
    else:
        xlabel = "syllable duration (frames)"

    fig, ax = plt.subplots()
    ax.hist(durations, range=(0, lim), bins=(int(lim / binsize)), density=True)
    ax.set_xlim([0, lim])
    ax.set_xlabel(xlabel)
    ax.set_ylabel("probability")
    ax.set_title("Duration distribution")
    ax.set_yticks([])
    if show_median:
        ax.axvline(np.median(durations), color="k", linestyle="--")
    return fig, ax


def plot_kappa_scan(kappas, project_dir, prefix, figsize=(8, 2.5)):
    """Plot the results of a kappa scan.

    This function assumes that model results for each kappa value are stored
    in `{project_dir}/{prefix}-{kappa}/checkpoint.h5`. Two plots are generated:
    (1) a line plot showing the median syllable duration over the course of
    fitting for each kappa value; (2) and a plot showing the final median
    syllable duration as a function of kappa.

    Parameters
    ----------
    kappas : array-like of float
        Kapppa values used in the scan.

    project_dir : str
        Path to the project directory.

    prefix : str
        Prefix for the kappa scan model names.

    Returns
    -------
    fig : matplotlib.figure.Figure
        Figure containing the plot.

    final_median_durations : array of float
        Median syllable durations for each kappa value, derived using the
        final iteration of each model.
    """
    median_dur_histories = []
    final_median_durs = []

    for kappa in tqdm.tqdm(kappas, desc="Loading checkpoints"):
        model_dir = f"{project_dir}/{prefix}-{kappa}"
        with h5py.File(f"{model_dir}/checkpoint.h5", "r") as h5:
            mask = h5["data/mask"][()]
            iterations = np.sort([int(i) for i in h5["model_snapshots"]])

            history = {}
            for itr in iterations:
                z = h5[f"model_snapshots/{itr}/states/z"][()]
                durs = get_durations(z, mask)
                history[itr] = np.median(durs)

            final_median_durs.append(history[iterations[-1]])
            median_dur_histories.append(history)

    fig, axs = plt.subplots(1, 2)
    for i, (kappa, history) in enumerate(zip(kappas, median_dur_histories)):
        color = plt.cm.viridis(i / (len(kappas) - 1))
        label = "{:.1e}".format(kappa)
        axs[0].plot(*zip(*history.items()), color=color, label=label)
    axs[0].legend(loc="center left", bbox_to_anchor=(1, 0.5))
    axs[0].set_xlabel("iteration")
    axs[0].set_ylabel("median duration")

    axs[1].scatter(kappas, final_median_durs)
    axs[1].set_xlabel("kappa")
    axs[1].set_ylabel("final median duration")
    axs[1].set_xscale("log")

    fig.set_size_inches(figsize)
    plt.tight_layout()
    return fig, np.array(final_median_durs)


def plot_progress(
    model,
    data,
    checkpoint_path,
    iteration,
    project_dir=None,
    model_name=None,
    path=None,
    savefig=True,
    fig_size=None,
    window_size=600,
    min_frequency=0.001,
    min_histogram_length=10,
):
    """Plot the progress of the model during fitting.

    The figure shows the following plots:
        - Duration distribution:
            The distribution of state durations for the most recent iteration
            of the model.
        - Frequency distribution:
            The distribution of state frequencies for the most recent iteration
            of the model.
        - Median duration:
            The median state duration across iterations.
        - State sequence history
            The state sequence across iterations in a random window (a new
            window is selected each time the progress is plotted).

    Parameters
    ----------
    model : dict
        Model dictionary containing `states`

    data : dict
        Data dictionary containing `mask`

    checkpoint_path : str
        Path to an HDF5 file containing model checkpoints.

    iteration : int
        Current iteration of model fitting

    project_dir : str, default=None
        Path to the project directory. Required if `savefig` is True.

    model_name : str, default=None
        Name of the model. Required if `savefig` is True.

    savefig : bool, default=True
        Whether to save the figure to a file. If true, the figure is either
        saved to `path` or, to `{project_dir}/{model_name}-progress.pdf` if
        `path` is None.

    fig_size : tuple of float, default=None
        Size of the figure in inches.

    window_size : int, default=600
        Window size for state sequence history plot.

    min_frequency : float, default=.001
        Minimum frequency for including a state in the frequency distribution
        plot.

    min_histogram_length : int, default=10
        Minimum x-axis length of the frequency distribution plot.

    Returns
    -------
    fig : matplotlib.figure.Figure
        Figure containing the plots.

    axs : list of matplotlib.axes.Axes
        Axes containing the plots.
    """
    z = np.array(model["states"]["z"])
    mask = np.array(data["mask"])
    durations = get_durations(z, mask)
    frequencies = get_frequencies(z, mask)

    with h5py.File(checkpoint_path, "r") as f:
        saved_iterations = np.sort([int(i) for i in f["model_snapshots"]])

    if len(saved_iterations) > 1:
        fig, axs = plt.subplots(1, 4, gridspec_kw={"width_ratios": [1, 1, 1, 3]})
        if fig_size is None:
            fig_size = (12, 2.5)
    else:
        fig, axs = plt.subplots(1, 2)
        if fig_size is None:
            fig_size = (4, 2.5)

    frequencies = np.sort(frequencies[frequencies > min_frequency])[::-1]
    xmax = max(len(frequencies), min_histogram_length)
    axs[0].bar(range(len(frequencies)), frequencies, width=1)
    axs[0].set_ylabel("probability")
    axs[0].set_xlabel("syllable rank")
    axs[0].set_xlim([-1, xmax + 1])
    axs[0].set_title("Frequency distribution")
    axs[0].set_yticks([])

    lim = int(np.percentile(durations, 95))
    binsize = max(int(np.floor(lim / 30)), 1)
    axs[1].hist(durations, range=(1, lim), bins=(int(lim / binsize)), density=True)
    axs[1].set_xlim([1, lim])
    axs[1].set_xlabel("syllable duration (frames)")
    axs[1].set_ylabel("probability")
    axs[1].set_title("Duration distribution")
    axs[1].set_yticks([])

    if len(saved_iterations) > 1:
        window_size = int(min(window_size, mask.max(0).sum() - 1))
        nz = np.stack(np.array(mask[:, window_size:]).nonzero(), axis=1)
        batch_ix, start = nz[np.random.randint(nz.shape[0])]

        sample_state_history = []
        median_durations = []

        for i in saved_iterations:
            with h5py.File(checkpoint_path, "r") as f:
                z = np.array(f[f"model_snapshots/{i}/states/z"])
                sample_state_history.append(z[batch_ix, start : start + window_size])
                median_durations.append(np.median(get_durations(z, mask)))

        axs[2].scatter(saved_iterations, median_durations)
        axs[2].set_ylim([-1, np.max(median_durations) * 1.1])
        axs[2].set_xlabel("iteration")
        axs[2].set_ylabel("duration")
        axs[2].set_title("Median duration")

        axs[3].imshow(
            sample_state_history,
            cmap=plt.cm.jet,
            aspect="auto",
            interpolation="nearest",
        )
        axs[3].set_xlabel("Time (frames)")
        axs[3].set_ylabel("Iterations")
        axs[3].set_title("State sequence history")

        yticks = [int(y) for y in axs[3].get_yticks() if y < len(saved_iterations) and y > 0]
        yticklabels = saved_iterations[yticks]
        axs[3].set_yticks(yticks)
        axs[3].set_yticklabels(yticklabels)

    title = f"Iteration {iteration}"
    if model_name is not None:
        title = f"{model_name}: {title}"
    fig.suptitle(title)
    fig.set_size_inches(fig_size)
    plt.tight_layout()

    if savefig:
        path = _get_path(project_dir, model_name, path, "fitting_progress.pdf")
        plt.savefig(path)
    plt.show()
    return fig, axs


def write_video_clip(frames, path, fps=30, quality=7):
    """Write a video clip to a file.

    Parameters
    ----------
    frames : np.ndarray
        Video frames as a 4D array of shape `(num_frames, height, width, 3)`
        or a 3D array of shape `(num_frames, height, width)`.

    path : str
        Path to save the video clip.

    fps : int, default=30
        Framerate of video encoding.

    quality : int, default=7
        Quality of video encoding.
    """
    with imageio.get_writer(path, pixelformat="yuv420p", fps=fps, quality=quality) as writer:
        for frame in frames:
            writer.append_data(frame)


def _grid_movie_tile(
    key,
    start,
    end,
    videos,
    centroids,
    headings,
    dot_color,
    window_size,
    scaled_window_size,
    pre,
    post,
    dot_radius,
    overlay_keypoints,
    edges,
    coordinates,
    plot_options,
    video_frame_indexes,
):
    scale_factor = scaled_window_size / window_size
    cs = centroids[key][start - pre : start + post]
    h, c = headings[key][start], cs[pre]
    r = np.float32([[np.cos(h), np.sin(h)], [-np.sin(h), np.cos(h)]])

    tile = []

    if videos is not None:
        frame_ixs = video_frame_indexes[key][start - pre : start + post]
        frames = [videos[key][ix] for ix in frame_ixs]
        c = r @ c - window_size // 2
        M = [[np.cos(h), np.sin(h), -c[0]], [-np.sin(h), np.cos(h), -c[1]]]

        for ii, (frame, c) in enumerate(zip(frames, cs)):
            if overlay_keypoints:
                coords = coordinates[key][start - pre + ii]
                frame = overlay_keypoints_on_image(frame, coords, edges=edges, **plot_options)

            frame = cv2.warpAffine(frame, np.float32(M), (window_size, window_size))
            frame = cv2.resize(frame, (scaled_window_size, scaled_window_size))
            if 0 <= ii - pre <= end - start and dot_radius > 0:
                pos = tuple([int(x) for x in M @ np.append(c, 1) * scale_factor])
                cv2.circle(frame, pos, dot_radius, dot_color, -1, cv2.LINE_AA)
            tile.append(frame)

    else:  # first transform keypoints, then overlay on black background
        assert overlay_keypoints, fill(
            "If no videos are provided, then `overlay_keypoints` must "
            "be True. Otherwise there is nothing to show"
        )
        scale_factor = scaled_window_size / window_size
        coords = coordinates[key][start - pre : start + post]
        coords = (coords - c) @ r.T * scale_factor + scaled_window_size // 2
        cs = (cs - c) @ r.T * scale_factor + scaled_window_size // 2
        background = np.zeros((scaled_window_size, scaled_window_size, 3))
        for ii, (uvs, c) in enumerate(zip(coords, cs)):
            frame = overlay_keypoints_on_image(background.copy(), uvs, edges=edges, **plot_options)
            if 0 <= ii - pre <= end - start and dot_radius > 0:
                pos = (int(c[0]), int(c[1]))
                cv2.circle(frame, pos, dot_radius, dot_color, -1, cv2.LINE_AA)
            tile.append(frame)

    return np.stack(tile)


def grid_movie(
    instances,
    rows,
    cols,
    videos,
    centroids,
    headings,
    window_size,
    video_frame_indexes,
    dot_color=(255, 255, 255),
    dot_radius=4,
    pre=30,
    post=60,
    scaled_window_size=None,
    edges=[],
    overlay_keypoints=False,
    coordinates=None,
    plot_options={},
):
    """Generate a grid movie and return it as an array of frames.

    Grid movies show many instances of  a syllable. Each instance contains a snippet of
    video (and/or keypoint-overlay) centered on the animal and synchronized to the onset
    of the syllable. A dot appears at syllable onset and disappears at syllable offset.

    Parameters
    ----------
    instances: list of tuples `(key, start, end)`
        List of syllable instances to include in the grid movie, where each instance is
        specified as a tuple with the video name, start frame and end frame. The list
        must have length `rows*cols`. The video names must also be keys in `videos`.

    rows: int, cols : int
        Number of rows and columns in the grid movie grid

    videos: dict or None
        Dictionary mapping video names to video readers. Frames from each reader should
        be accessible via `__getitem__(int or slice)`. If None, the the grid movie will
        not include video frames.

    centroids: dict
        Dictionary mapping video names to arrays of shape `(n_frames, 2)` with the x,y
        coordinates of animal centroid on each frame

    headings: dict
        Dictionary mapping video names to arrays of shape `(n_frames,)` with the heading
        of the animal on each frame (in radians)

    window_size: int
        Size of the window around the animal. This should be a multiple of 16 or imageio
        will complain.

    video_frame_indexes: dict
        Dictionary mapping recording names to arrays of video frame indexes.
        This is useful when the original keypoint coordinates used for modeling
        corresponded to a subset of frames from each video (i.e. if videos were
        trimmed or coordinates were downsampled).

    dot_color: tuple of ints, default=(255,255,255)
        RGB color of the dot indicating syllable onset and offset

    dot_radius: int, default=4
        Radius of the dot indicating syllable onset and offset

    pre: int, default=30
        Number of frames before syllable onset to include in the movie

    post: int, default=60
        Number of frames after syllable onset to include in the movie

    scaled_window_size: int, default=None
        Window size after scaling the video. If None, the no scaling is performed (i.e.
        `scaled_window_size = window_size`)

    overlay_keypoints: bool, default=False
        If True, overlay the pose skeleton on the video frames.

    edges: list of tuples, default=[]
        List of edges defining pose skeleton. Used when `overlay_keypoints=True`.

    coordinates: dict, default=None
        Dictionary mapping video names to arrays of shape `(n_frames, 2)`. Used when
        `overlay_keypoints=True`.

    plot_options: dict, default={}
        Dictionary of options to pass to `overlay_keypoints_on_image`. Used when
        `overlay_keypoints=True`.

    Returns
    -------
    frames: array of shape `(post+pre, width, height, 3)`
        Array of frames in the grid movie where::

            width = rows * scaled_window_size
            height = cols * scaled_window_size
    """
    if videos is None:
        assert overlay_keypoints, fill(
            "If no videos are provided, then `overlay_keypoints` must "
            "be True. Otherwise there is nothing to show"
        )

    if scaled_window_size is None:
        scaled_window_size = window_size

    tiles = []
    for key, start, end in instances:
        tiles.append(
            _grid_movie_tile(
                key,
                start,
                end,
                videos,
                centroids,
                headings,
                dot_color,
                window_size,
                scaled_window_size,
                pre,
                post,
                dot_radius,
                overlay_keypoints,
                edges,
                coordinates,
                plot_options,
                video_frame_indexes,
            )
        )

    tiles = np.stack(tiles).reshape(
        rows, cols, post + pre, scaled_window_size, scaled_window_size, 3
    )
    frames = np.concatenate(np.concatenate(tiles, axis=2), axis=2)
    return frames


def get_grid_movie_window_size(
    sampled_instances,
    centroids,
    headings,
    coordinates,
    pre,
    post,
    pctl=90,
    fudge_factor=1.1,
    blocksize=16,
):
    """Automatically determine the window size for a grid movie.

    The window size is set such that across all sampled instances,
    the animal is fully visible in at least `pctl` percent of frames.

    Parameters
    ----------
    sampled_instances: dict
        Dictionary mapping syllables to lists of instances, where each
        instance is specified as a tuple with the video name, start frame
        and end frame.

    centroids: dict
        Dictionary mapping video names to arrays of shape `(n_frames, 2)`
        with the x,y coordinates of animal centroid on each frame

    headings: dict
        Dictionary mapping video names to arrays of shape `(n_frames,)`
        with the heading of the animal on each frame (in radians)

    coordinates: dict
        Dictionary mapping recording names to keypoint coordinates as
        ndarrays of shape (n_frames, n_bodyparts, 2).

    pre, post: int
        Number of frames before/after syllable onset that are included
        in the grid movies.

    pctl: int, default=95
        Percentile of frames in which the animal should be fully visible.

    fudge_factor: float, default=1.1
        Factor by which to multiply the window size.

    blocksize: int, default=16
        Window size is rounded up to the nearest multiple of `blocksize`.
    """
    all_trajectories = get_instance_trajectories(
        sum(sampled_instances.values(), []),
        coordinates,
        pre=pre,
        post=post,
        centroids=centroids,
        headings=headings,
    )

    all_trajectories = np.concatenate(all_trajectories, axis=0)
    all_trajectories = all_trajectories[~np.isnan(all_trajectories).all((1, 2))]
    max_distances = np.nanmax(np.abs(all_trajectories), axis=1)
    window_size = np.percentile(max_distances, pctl) * fudge_factor * 2
    window_size = int(np.ceil(window_size / blocksize) * blocksize)
    return window_size


def generate_grid_movies(
    results,
    project_dir=None,
    model_name=None,
    output_dir=None,
    video_dir=None,
    video_paths=None,
    video_frame_indexes=None,
    rows=4,
    cols=6,
    filter_size=9,
    pre=30,
    post=60,
    min_frequency=0.005,
    min_duration=3,
    dot_radius=4,
    dot_color=(255, 255, 255),
    quality=7,
    window_size=None,
    coordinates=None,
    centroids=None,
    headings=None,
    bodyparts=None,
    use_bodyparts=None,
    sampling_options={},
    video_extension=None,
    max_video_size=1920,
    skeleton=[],
    overlay_keypoints=False,
    keypoints_only=False,
    keypoints_scale=1,
    fps=None,
    plot_options={},
    use_dims=[0, 1],
    keypoint_colormap="autumn",
    **kwargs,
):
    """Generate grid movies for a modeled dataset.

    Grid movies show many instances of a syllable and are useful in
    figuring out what behavior the syllable captures
    (see :py:func:`keypoint_moseq.viz.grid_movie`). This method
    generates a grid movie for each syllable that is used sufficiently
    often (i.e. has at least `rows*cols` instances with duration
    of at least `min_duration` and an overall frequency of at least
    `min_frequency`). The grid movies are saved to `output_dir` if
    specified, or else to `{project_dir}/{model_name}/grid_movies`.
    A subset of parameters are documented below. See
    :py:func:`keypoint_moseq.viz.grid_movie` for the remaining parameters.

    Parameters
    ----------
    results: dict
        Dictionary containing modeling results for a dataset (see
        :py:func:`keypoint_moseq.fitting.extract_results`)

    project_dir: str, default=None
        Project directory. Required to save grid movies if `output_dir`
        is None.

    model_name: str, default=None
        Name of the model. Required to save grid movies if
        `output_dir` is None.

    output_dir: str, default=None
        Directory where grid movies should be saved. If None, grid
        movies will be saved to `{project_dir}/{model_name}/grid_movies`.

    video_dir: str, default=None
        Directory containing videos of the modeled data (see
        :py:func:`keypoint_moseq.io.find_matching_videos`). Either  `video_dir`
        or `video_paths` must be provided unless `keypoints_only=True`.

    video_paths: dict, default=None
        Dictionary mapping recording names to video paths. The recording
        names must correspond to keys in the results dictionary. Either
        `video_dir` or `video_paths` must be provided unless
        `keypoints_only=True`.

    video_frame_indexes: dict, default=None
        Dictionary mapping recording names to arrays of video frame indexes.
        This is useful when the original keypoint coordinates used for modeling
        corresponded to a subset of frames from each video (i.e. if videos were
        trimmed or coordinates were downsampled).

    filter_size: int, default=9
        Size of the median filter applied to centroids and headings

    min_frequency: float, default=0.005
        Minimum frequency of a syllable to be included in the grid movies.

    min_duration: int, default=3
        Minimum duration of a syllable instance to be included in the
        grid movie for that syllable.

    sampling_options: dict, default={}
        Dictionary of options for sampling syllable instances (see
        :py:func:`keypoint_moseq.util.sample_instances`).

    coordinates: dict, default=None
        Dictionary mapping recording names to keypoint coordinates as
        ndarrays of shape (n_frames, n_bodyparts, [2 or 3]). Required when
        `window_size=None`, or `overlay_keypoints=True`, or if using
        density-based sampling (i.e. when `sampling_options['mode']=='density'`;
        see :py:func:`keypoint_moseq.util.sample_instances`).

    centroids: dict, default=None
        Dictionary mapping recording names to arrays of shape `(n_frames, 2)`.
        Overrides the centroid information in `results`.

    headings: dict, default=None
        Dictionary mapping recording names to arrays of shape `(n_frames,)`.
        Overrides the heading information in `results`.

    bodyparts: list of str, default=None
        List of bodypart names in `coordinates`. Required when `coordinates` is
        provided and bodyparts were reindexed for modeling.

    use_bodyparts: list of str, default=None
        Ordered list of bodyparts used for modeling. Required when
        `coordinates` is provided and bodyparts were reindexed
        for modeling.

    quality: int, default=7
        Quality of the grid movies. Higher values result in higher
        quality movies but larger file sizes.

    rows, cols, pre, post, dot_radius, dot_color, window_size
        See :py:func:`keypoint_moseq.viz.grid_movie`

    video_extension: str, default=None
        Preferred video extension (passed to
        :py:func:`keypoint_moseq.util.find_matching_videos`)

    window_size: int, default=None
        Size of the window around the animal. If None, the window
        size is determined automatically based on the size of the
        animal. If provided explicitly, `window_size` should be a
        multiple of 16 or imageio will complain.

    max_video_size: int, default=4000
        Maximum size of the grid movie in pixels. If the grid movie
        is larger than this, it will be downsampled.

    skeleton: list of tuples, default=[]
        List of tuples specifying the skeleton. Used when
        `overlay_keypoints=True`.

    overlay_keypoints: bool, default=False
        Whether to overlay the keypoints on the grid movie.

    keypoints_only: bool, default=False
        Whether to only show the keypoints (i.e. no video frames).
        Overrides `overlay_keypoints`. When this option is used,
        the framerate should be explicitly specified using `fps`.

    keypoints_scale: float, default=1
        Factor to scale keypoint coordinates before plotting. Only used when
        `keypoints_only=True`. This is useful when the keypoints are 3D and
        encoded in units that are larger than a pixel.

    fps: int, default=30
        Framerate of the grid movie. If None, the framerate is determined
        from the videos.

    plot_options: dict, default={}
        Dictionary of options to pass to
        :py:func:`keypoint_moseq.viz.overlay_keypoints_on_image`.

    use_dims: pair of ints, default=[0,1]
        Dimensions to use for plotting keypoints. Only used when
        `overlay_keypoints=True` and the keypoints are 3D.

    keypoint_colormap: str, default='autumn'
        Colormap used to color keypoints. Used when
        `overlay_keypoints=True`.


    Returns
    -------
    sampled_instances: dict
        Dictionary mapping syllables to lists of instances shown in each in
        grid movie (in row-major order), where each instance is specified as a
        tuple with the video name, start frame and end frame.
    """
    # check inputs
    if keypoints_only:
        overlay_keypoints = True
    else:
        assert (video_dir is not None) or (video_paths is not None), fill(
            "Either `video_dir` or `video_paths` is required unless `keypoints_only=True`"
        )

    if window_size is None or overlay_keypoints:
        assert coordinates is not None, fill(
            "`coordinates` must be provided if `window_size` is None "
            "or `overlay_keypoints` is True"
        )

    # prepare output directory
    output_dir = _get_path(project_dir, model_name, output_dir, "grid_movies", "output_dir")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    print(f"Writing grid movies to {output_dir}")

    # reindex coordinates if necessary
    if not (bodyparts is None or use_bodyparts is None or coordinates is None):
        coordinates = reindex_by_bodyparts(coordinates, bodyparts, use_bodyparts)

    # get edges for plotting skeleton
    edges = []
    if len(skeleton) > 0 and overlay_keypoints:
        edges = get_edges(use_bodyparts, skeleton)

    # load results
    if results is None:
        results = load_results(project_dir, model_name)

    # extract syllables from results
    syllables = {k: v["syllable"] for k, v in results.items()}

    # extract and smooth centroids and headings
    if centroids is None:
        centroids = {k: v["centroid"] for k, v in results.items()}
    if headings is None:
        headings = {k: v["heading"] for k, v in results.items()}

    centroids, headings = filter_centroids_headings(centroids, headings, filter_size=filter_size)

    # scale keypoints if necessary
    if keypoints_only:
        for k, v in coordinates.items():
            coordinates[k] = v * keypoints_scale
        for k, v in centroids.items():
            centroids[k] = v * keypoints_scale

    # load video readers if necessary
    if not keypoints_only:
        if video_paths is None:
            video_paths = find_matching_videos(
                results.keys(),
                video_dir,
                as_dict=True,
                video_extension=video_extension,
            )
        check_video_paths(video_paths, results.keys())
        videos = {k: OpenCVReader(path) for k, path in video_paths.items()}

        if fps is None:
            fps = list(videos.values())[0].fps

        if video_frame_indexes is None:
            video_frame_indexes = {k: np.arange(len(v)) for k, v in syllables.items()}
        else:
            assert set(video_frame_indexes.keys()) == set(
                syllables.keys()
            ), "The keys of `video_frame_indexes` must match the keys of `results`"
            for k, v in syllables.items():
                assert len(v) == len(video_frame_indexes[k]), (
                    "There is a mismatch between the length of `video_frame_indexes` "
                    f"and the length of modeling results for key {k}."
                    f"\n\tLength of `video_frame_indexes` = {len(video_frame_indexes[k])}"
                    f"\n\tLength of modeling results = {len(v)}"
                )
    else:
        videos = None

    # sample instances for each syllable
    syllable_instances = get_syllable_instances(
        syllables,
        pre=pre,
        post=post,
        min_duration=min_duration,
        min_frequency=min_frequency,
        min_instances=rows * cols,
    )

    if len(syllable_instances) == 0:
        warnings.warn(
            fill(
                "No syllables with sufficient instances to make a grid movie. "
                "This usually occurs when all frames have the same syllable label "
                "(use `plot_syllable_frequencies` to check if this is the case)"
            )
        )
        return

    sampled_instances = sample_instances(
        syllable_instances,
        rows * cols,
        coordinates=coordinates,
        centroids=centroids,
        headings=headings,
        **sampling_options,
    )

    # if the data is 3D, pick 2 dimensions to use for plotting
    keypoint_dimension = next(iter(centroids.values())).shape[-1]
    if keypoint_dimension == 3:
        ds = np.array(use_dims)
        centroids = {k: v[:, ds] for k, v in centroids.items()}
        if coordinates is not None:
            coordinates = {k: v[:, :, ds] for k, v in coordinates.items()}

    # determine window size for grid movies
    if window_size is None:
        window_size = get_grid_movie_window_size(
            sampled_instances, centroids, headings, coordinates, pre, post
        )
        print(f"Using window size of {window_size} pixels")
        if keypoints_only:
            if window_size < 64:
                warnings.warn(
                    fill(
                        "The scale of the keypoints is very small. This may result in "
                        "poor quality grid movies. Try increasing `keypoints_scale`."
                    )
                )

    # possibly reduce window size to keep grid movies under max_video_size
    scaled_window_size = max_video_size / max(rows, cols)
    scaled_window_size = int(np.floor(scaled_window_size / 16) * 16)
    scaled_window_size = min(scaled_window_size, window_size)
    scale_factor = scaled_window_size / window_size

    if scale_factor < 1:
        warnings.warn(
            "\n"
            + fill(
                f"Videos will be downscaled by a factor of {scale_factor:.2f} "
                f"so that the grid movies are under {max_video_size} pixels. "
                "Use `max_video_size` to increase or decrease this size limit."
            )
            + "\n\n"
        )

    # add colormap to plot options
    plot_options.update({"keypoint_colormap": keypoint_colormap})

    # generate grid movies
    for syllable, instances in tqdm.tqdm(
        sampled_instances.items(), desc="Generating grid movies", ncols=72
    ):
        frames = grid_movie(
            instances,
            rows,
            cols,
            videos,
            centroids,
            headings,
            window_size,
            video_frame_indexes,
            edges=edges,
            scaled_window_size=scaled_window_size,
            dot_color=dot_color,
            pre=pre,
            post=post,
            dot_radius=dot_radius,
            overlay_keypoints=overlay_keypoints,
            coordinates=coordinates,
            plot_options=plot_options,
        )

        path = os.path.join(output_dir, f"syllable{syllable}.mp4")
        write_video_clip(frames, path, fps=fps, quality=quality)

    return sampled_instances


def get_limits(
    coordinates,
    pctl=1,
    blocksize=None,
    left=0.2,
    right=0.2,
    top=0.2,
    bottom=0.2,
):
    """Get axis limits based on the coordinates of all keypoints.

    For each axis, limits are determined using the percentiles
    `pctl` and `100-pctl` and then padded by `padding`.

    Parameters
    ----------
    coordinates: ndarray or dict
        Coordinates as an ndarray of shape (..., 2), or a dict
        with values that are ndarrays of shape (..., 2).

    pctl: float, default=1
        Percentile to use for determining the axis limits.

    blocksize: int, default=None
        Axis limits are cast to integers and padded so that the width
        and height are multiples of `blocksize`. This is useful
        when they are used for generating cropped images for a video.

    left, right, top, bottom: float, default=0.1
        Fraction of the axis range to pad on each side.

    Returns
    -------
    lims: ndarray of shape (2,dim)
        Axis limits, in the format `[[xmin,ymin,...],[xmax,ymax,...]]`.
    """
    if isinstance(coordinates, dict):
        X = np.concatenate(list(coordinates.values())).reshape(-1, 2)
    else:
        X = coordinates.reshape(-1, 2)

    xmin, ymin = np.nanpercentile(X, pctl, axis=0)
    xmax, ymax = np.nanpercentile(X, 100 - pctl, axis=0)

    width = xmax - xmin
    height = ymax - ymin
    xmin -= width * left
    xmax += width * right
    ymin -= height * bottom
    ymax += height * top

    lims = np.array([[xmin, ymin], [xmax, ymax]])

    if blocksize is not None:
        lims = np.round(lims)
        padding = np.mod(lims[0] - lims[1], blocksize) / 2
        lims[0] -= padding
        lims[1] += padding
        lims = np.ceil(lims)

    return lims.astype(int)


def rasterize_figure(fig):
    canvas = fig.canvas
    canvas.draw()
    width, height = canvas.get_width_height()
    raster_flat = np.frombuffer(canvas.tostring_rgb(), dtype="uint8")
    raster = raster_flat.reshape((height, width, 3))
    return raster


def plot_trajectories(
    titles,
    Xs,
    lims,
    edges=[],
    n_cols=4,
    invert=False,
    keypoint_colormap="autumn",
    keypoint_colors=None,
    node_size=50.0,
    line_width=3.0,
    alpha=0.2,
    num_timesteps=10,
    plot_width=4,
    overlap=(0.2, 0),
    return_rasters=False,
):
    """Plot one or more pose trajectories on a common axis and return the axis.

    (See :py:func:`keypoint_moseq.viz.generate_trajectory_plots`)

    Parameters
    ----------
    titles: list of str
        List of titles for each trajectory plot.

    Xs: list of ndarray
        List of pose trajectories as ndarrays of shape
        (n_frames, n_keypoints, 2).

    lims: ndarray
        Axis limits used for all the trajectory plots. The limits
        should be provided as an array of shape (2,2) with the format
        `[[xmin,ymin],[xmax,ymax]]`.

    edges: list of tuples, default=[]
        List of edges, where each edge is a tuple of two integers

    n_cols: int, default=4
        Number of columns in the figure (used when plotting multiple
        trajectories).

    invert: bool, default=False
        Determines the background color of the figure. If `True`,
        the background will be black.

    keypoint_colormap : str or list
        Name of a matplotlib colormap or a list of colors as (r,b,g)
        tuples in the same order as as the keypoints.

    keypoint_colors : array-like, shape=(num_keypoints,3), default=None
        Color for each keypoint. If None, the keypoint colormap is used.
        If the dtype is int, the values are assumed to be in the range 0-255,
        otherwise they are assumed to be in the range 0-1.

    node_size: int, default=50
        Size of each keypoint.

    line_width: int, default=3
        Width of the lines connecting keypoints.

    alpha: float, default=0.2
        Opacity of fade-out layers.

    num_timesteps: int, default=10
        Number of timesteps to plot for each trajectory. The pose
        at each timestep is determined by linearly interpolating
        between the keypoints.

    plot_width: int, default=4
        Width of each trajectory plot in inches. The height  is
        determined by the aspect ratio of `lims`. The final figure
        width is `fig_width * min(n_cols, len(X))`.

    overlap: tuple of float, default=(0.2,0)
        Amount of overlap between each trajectory plot as a tuple
        with the format `(x_overlap, y_overlap)`. The values should
        be between 0 and 1.

    return_rasters: bool, default=False
        Rasterize the matplotlib canvas after plotting each step of
        the trajecory. This is used to generate an animated video/gif
        of the trajectory.

    Returns
    -------
    fig : :py:class:`matplotlib.figure.Figure`
        Figure handle

    ax: matplotlib.axes.Axes
        Axis containing the trajectory plots.
    """
    fill_color = "k" if invert else "w"
    if keypoint_colors is None:
        cmap = plt.colormaps[keypoint_colormap]
        colors = plt.get_cmap(cmap)(np.linspace(0, 1, Xs[0].shape[1]))
    elif isinstance(keypoint_colors[0][0], int):
        colors = list(np.array(keypoint_colors) / 255)
    else:
        colors = list(keypoint_colors)

    n_cols = min(n_cols, len(Xs))
    n_rows = np.ceil(len(Xs) / n_cols)
    offsets = np.stack(
        np.meshgrid(
            np.arange(n_cols) * np.diff(lims[:, 0]) * (1 - overlap[0]),
            np.arange(n_rows) * np.diff(lims[:, 1]) * (overlap[1] - 1),
        ),
        axis=-1,
    ).reshape(-1, 2)[: len(Xs)]

    Xs = interpolate_along_axis(
        np.linspace(0, Xs[0].shape[0], num_timesteps),
        np.arange(Xs[0].shape[0]),
        np.array(Xs),
        axis=1,
    )

    Xs = Xs + offsets[:, None, None]
    xmin, ymin = lims[0] + offsets.min(0)
    xmax, ymax = lims[1] + offsets.max(0)

    fig, ax = plt.subplots(frameon=False)
    ax.fill_between(
        [xmin, xmax],
        y1=[ymax, ymax],
        y2=[ymin, ymin],
        facecolor=fill_color,
        zorder=0,
        clip_on=False,
    )

    title_xy = (lims * np.array([[0.5, 0.1], [0.5, 0.9]])).sum(0)
    title_color = "w" if invert else "k"

    for xy, text in zip(offsets + title_xy, titles):
        ax.text(
            *xy,
            text,
            c=title_color,
            ha="center",
            va="top",
            zorder=Xs.shape[1] * 4 + 4,
        )

    # final extents in axis
    final_width = xmax - xmin
    final_height = title_xy[1] - ymin

    fig_width = plot_width * (n_cols - (n_cols - 1) * overlap[0])
    fig_height = final_height / final_width * fig_width
    fig.set_size_inches((fig_width, fig_height))

    ax.set_xlim(xmin, xmax)
    ax.set_ylim(ymin, ymax)
    ax.set_aspect("equal")
    ax.axis("off")
    plt.tight_layout()

    rasters = []  # for making a gif

    for i in range(Xs.shape[1]):
        for X, offset in zip(Xs, offsets):
            for ii, jj in edges:
                ax.plot(
                    *X[i, (ii, jj)].T,
                    c="k",
                    zorder=i * 4,
                    linewidth=line_width,
                    clip_on=False,
                )

            for ii, jj in edges:
                ax.plot(
                    *X[i, (ii, jj)].T,
                    c=colors[ii],
                    zorder=i * 4 + 1,
                    linewidth=line_width * 0.9,
                    clip_on=False,
                )

            ax.scatter(
                *X[i].T,
                c=colors,
                zorder=i * 4 + 2,
                edgecolor="k",
                linewidth=0.4,
                s=node_size,
                clip_on=False,
            )

        if i < Xs.shape[1] - 1:
            ax.fill_between(
                [xmin, xmax],
                y1=[ymax, ymax],
                y2=[ymin, ymin],
                facecolor=fill_color,
                alpha=alpha,
                zorder=i * 4 + 3,
                clip_on=False,
            )

        if return_rasters:
            rasters.append(rasterize_figure(fig))

    return fig, ax, rasters


def save_gif(image_list, gif_filename, duration=0.5):
    # Convert NumPy arrays to PIL Image objects
    pil_images = [Image.fromarray(np.uint8(img)) for img in image_list]

    # Save the PIL Images as an animated GIF
    pil_images[0].save(
        gif_filename,
        save_all=True,
        append_images=pil_images[1:],
        duration=int(duration * 1000),
        loop=0,
    )


def generate_trajectory_plots(
    coordinates,
    results,
    project_dir=None,
    model_name=None,
    output_dir=None,
    pre=5,
    post=15,
    min_frequency=0.005,
    min_duration=3,
    skeleton=[],
    bodyparts=None,
    use_bodyparts=None,
    keypoint_colormap="autumn",
    plot_options={},
    get_limits_pctl=0,
    padding={"left": 0.1, "right": 0.1, "top": 0.2, "bottom": 0.2},
    lims=None,
    save_individually=True,
    save_gifs=True,
    save_mp4s=False,
    fps=30,
    projection_planes=["xy", "xz"],
    interactive=True,
    density_sample=True,
    sampling_options={"n_neighbors": 50},
    **kwargs,
):
    """
    Generate trajectory plots for a modeled dataset.

    Each trajectory plot shows a sequence of poses along the average
    trajectory through latent space associated with a given syllable.
    A separate figure (and gif, optionally) is saved for each syllable,
    along with a single figure showing all syllables in a grid. The
    plots are saved to `{output_dir}` if it is provided, otherwise
    they are saved to `{project_dir}/{model_name}/trajectory_plots`.

    Plot-related parameters are described below. For the remaining
    parameters see (:py:func:`keypoint_moseq.util.get_typical_trajectories`)

    Parameters
    ----------
    coordinates: dict
        Dictionary mapping recording names to keypoint coordinates as
        ndarrays of shape (n_frames, n_bodyparts, [2 or 3]).

    results: dict
        Dictionary containing modeling results for a dataset (see
        :py:func:`keypoint_moseq.fitting.extract_results`).

    project_dir: str, default=None
        Project directory. Required to save trajectory plots if
        `output_dir` is None.

    model_name: str, default=None
        Name of the model. Required to save trajectory plots if
        `output_dir` is None.

    output_dir: str, default=None
        Directory where trajectory plots should be saved. If None,
        plots will be saved to `{project_dir}/{model_name}/trajectory_plots`.

    skeleton : list, default=[]
        List of edges that define the skeleton, where each edge is a
        pair of bodypart names or a pair of indexes.

    keypoint_colormap : str
        Name of a matplotlib colormap to use for coloring the keypoints.

    plot_options: dict, default={}
        Dictionary of options for trajectory plots (see
        :py:func:`keypoint_moseq.util.plot_trajectories`).

    get_limits_pctl: float, default=0
        Percentile to use for determining the axis limits. Higher values lead
        to tighter axis limits.

    padding: dict, default={'left':0.1, 'right':0.1, 'top':0.2, 'bottom':0.2}
        Padding around trajectory plots. Controls the the distance
        between trajectories (when multiple are shown in one figure)
        as well as the title offset.

    lims: ndarray of shape (2,2), default=None
        Axis limits used for all the trajectory plots with format
        `[[xmin,ymin],[xmax,ymax]]`. If None, the limits are determined
        automatically based on the coordinates of the keypoints using
        :py:func:`keypoint_moseq.viz.get_limits`.

    save_individually: bool, default=True
        If True, a separate figure is saved for each syllable (in
        addition to the grid figure).

    save_gifs: bool, default=True
        Whether to save an animated gif of the trajectory plots.

    save_mp4s: bool, default=False
        Whether to save videos of the trajectory plots as .mp4 files

    fps: int, default=30
        Framerate of the videos from which keypoints were derived.
        Used to set the framerate of gifs when `save_gif=True`.

    projection_planes: list (subset of ['xy', 'yz', 'xz']), default=['xy','xz']
        For 3D data, defines the 2D plane(s) on which to project keypoint
        coordinates. A separate plot will be saved for each plane with
        the name of the plane (e.g. 'xy') as a suffix. This argument is
        ignored for 2D data.

    interactive: bool, default=True
        For 3D data, whether to create an visualization that can be
        rotated and zoomed. This argument is ignored for 2D data.
    """
    plot_options.update({"keypoint_colormap": keypoint_colormap})
    edges = [] if len(skeleton) == 0 else get_edges(use_bodyparts, skeleton)

    output_dir = _get_path(project_dir, model_name, output_dir, "trajectory_plots", "output_dir")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    print(f"Saving trajectory plots to {output_dir}")

    typical_trajectories = get_typical_trajectories(
        coordinates,
        results,
        pre,
        post,
        min_frequency,
        min_duration,
        bodyparts,
        use_bodyparts,
        density_sample,
        sampling_options,
    )

    syllable_ixs = sorted(typical_trajectories.keys())
    titles = [f"Syllable{s}" for s in syllable_ixs]
    Xs = np.stack([typical_trajectories[s] for s in syllable_ixs])

    if Xs.shape[-1] == 3:
        projection_planes = ["".join(sorted(plane.lower())) for plane in projection_planes]
        assert set(projection_planes) <= set(["xy", "yz", "xz"]), fill(
            "`projection_planes` must be a subset of `['xy','yz','xz']`"
        )
        if lims is not None:
            assert lims.shape == (2, 3), fill(
                "`lims` must be None or an ndarray of shape (2,3) when plotting 3D data"
            )
        all_Xs, all_lims, suffixes = [], [], []
        for plane in projection_planes:
            use_dims = {"xy": [0, 1], "yz": [1, 2], "xz": [0, 2]}[plane]
            all_Xs.append(Xs[..., use_dims])
            suffixes.append("." + plane)
            if lims is None:
                all_lims.append(get_limits(all_Xs[-1], pctl=get_limits_pctl, **padding))
            else:
                all_lims.append(lims[..., use_dims])

    else:
        all_Xs = [Xs * np.array([1, -1])]  # flip y-axis
        if lims is None:
            lims = get_limits(all_Xs[-1], pctl=get_limits_pctl, **padding)
        all_lims = [lims]
        suffixes = [""]

    for Xs_2D, lims, suffix in zip(all_Xs, all_lims, suffixes):
        # individual plots
        if save_individually:
            desc = "Generating trajectory plots"
            for title, X in tqdm.tqdm(zip(titles, Xs_2D), desc=desc, total=len(titles), ncols=72):
                fig, ax, rasters = plot_trajectories(
                    [title],
                    X[None],
                    lims,
                    edges=edges,
                    return_rasters=(save_gifs or save_mp4s),
                    **plot_options,
                )

                plt.savefig(os.path.join(output_dir, f"{title}{suffix}.pdf"))
                plt.close(fig=fig)

                if save_gifs:
                    frame_duration = (pre + post) / len(rasters) / fps
                    path = os.path.join(output_dir, f"{title}{suffix}.gif")
                    save_gif(rasters, path, duration=frame_duration)
                if save_mp4s:
                    use_fps = len(rasters) / (pre + post) * fps
                    path = os.path.join(output_dir, f"{title}{suffix}.mp4")
                    write_video_clip(rasters, path, fps=use_fps)

        # grid plot
        fig, ax, rasters = plot_trajectories(
            titles,
            Xs_2D,
            lims,
            edges=edges,
            return_rasters=(save_gifs or save_mp4s),
            **plot_options,
        )

        plt.savefig(os.path.join(output_dir, f"all_trajectories{suffix}.pdf"))
        plt.show()

        if save_gifs:
            frame_duration = (pre + post) / len(rasters) / fps
            path = os.path.join(output_dir, f"all_trajectories{suffix}.gif")
            save_gif(rasters, path, duration=frame_duration)
        if save_mp4s:
            use_fps = len(rasters) / (pre + post) * fps
            path = os.path.join(output_dir, f"all_trajectories{suffix}.mp4")
            write_video_clip(rasters, path, fps=use_fps)

    if interactive and Xs.shape[-1] == 3:
        plot_trajectories_3D(Xs, titles, edges, output_dir, **plot_options)


def overlay_keypoints_on_image(
    image,
    coordinates,
    edges=[],
    keypoint_colormap="autumn",
    keypoint_colors=None,
    node_size=5,
    line_width=2,
    copy=False,
    opacity=1.0,
):
    """Overlay keypoints on an image.

    Parameters
    ----------
    image: ndarray of shape (height, width, 3)
        Image to overlay keypoints on.

    coordinates: ndarray of shape (num_keypoints, 2)
        Array of keypoint coordinates.

    edges: list of tuples, default=[]
        List of edges that define the skeleton, where each edge is a
        pair of indexes.

    keypoint_colormap: str, default='autumn'
        Name of a matplotlib colormap to use for coloring the keypoints.

    keypoint_colors : array-like, shape=(num_keypoints,3), default=None
        Color for each keypoint. If None, the keypoint colormap is used.
        If the dtype is int, the values are assumed to be in the range 0-255,
        otherwise they are assumed to be in the range 0-1.

    node_size: int, default=5
        Size of the keypoints.

    line_width: int, default=2
        Width of the skeleton lines.

    copy: bool, default=False
        Whether to copy the image before overlaying keypoints.

    opacity: float, default=1.0
        Opacity of the overlay graphics (0.0-1.0).

    Returns
    -------
    image: ndarray of shape (height, width, 3)
        Image with keypoints overlayed.
    """
    if copy or opacity < 1.0:
        canvas = image.copy()
    else:
        canvas = image

    if keypoint_colors is None:
        cmap = plt.colormaps[keypoint_colormap]
        colors = np.array(cmap(np.linspace(0, 1, coordinates.shape[0])))[:, :3]
    else:
        colors = np.array(keypoint_colors)

    if isinstance(colors[0, 0], float):
        colors = [tuple([int(c) for c in cs * 255]) for cs in colors]

    # overlay skeleton
    for i, j in edges:
        if np.isnan(coordinates[i, 0]) or np.isnan(coordinates[j, 0]):
            continue
        pos1 = (int(coordinates[i, 0]), int(coordinates[i, 1]))
        pos2 = (int(coordinates[j, 0]), int(coordinates[j, 1]))
        canvas = cv2.line(canvas, pos1, pos2, colors[i], line_width, cv2.LINE_AA)

    # overlay keypoints
    for i, (x, y) in enumerate(coordinates):
        if np.isnan(x) or np.isnan(y):
            continue
        pos = (int(x), int(y))
        canvas = cv2.circle(canvas, pos, node_size, colors[i], -1, lineType=cv2.LINE_AA)

    if opacity < 1.0:
        image = cv2.addWeighted(image, 1 - opacity, canvas, opacity, 0)
    return image


def overlay_keypoints_on_video(
    video_path,
    coordinates,
    skeleton=[],
    bodyparts=None,
    use_bodyparts=None,
    output_path=None,
    show_frame_numbers=True,
    text_color=(255, 255, 255),
    crop_size=None,
    frames=None,
    quality=7,
    centroid_smoothing_filter=10,
    plot_options={},
    video_frame_indexes=None,
):
    """Overlay keypoints on a video.

    Parameters
    ----------
    video_path: str
        Path to a video file.

    coordinates: ndarray of shape (num_frames, num_keypoints, 2)
        Array of keypoint coordinates.

    skeleton: list of tuples, default=[]
        List of edges that define the skeleton, where each edge is a pair of bodypart
        names or a pair of indexes.

    bodyparts: list of str, default=None
        List of bodypart names in `coordinates`. Required if `skeleton` is defined using
        bodypart names.

    use_bodyparts: list of str, default=None
        Subset of bodyparts to plot. If None, all bodyparts are plotted.

    output_path: str, default=None
        Path to save the video. If None, the video is saved to `video_path` with the
        suffix `_keypoints`.

    show_frame_numbers: bool, default=True
        Whether to overlay the frame number in the video.

    text_color: tuple of int, default=(255,255,255)
        Color for the frame number overlay.

    crop_size: int, default=None
        Size of the crop around the keypoints to overlay on the video. If None, the
        entire video is used.

    frames: iterable of int, default=None
        Frames to overlay keypoints on (in the numbering of `coordinates`). If None,
        all of `coordinates` is used. This option can be used in conjunction with
        `video_frame_indexes` when the entries of `coordinates` do not correspond
        one-to-one with frames of the video.

    quality: int, default=7
        Quality of the output video.

    centroid_smoothing_filter: int, default=10
        Amount of smoothing to determine cropping centroid.

    plot_options: dict, default={}
        Additional keyword arguments to pass to
        :py:func:`keypoint_moseq.viz.overlay_keypoints`.

    video_frame_indexes: array, default=None
        Video frames corresponding to the entries of `coordinates`. If None, it is
        assumed that the i'th entry of `coordinate` corresponds to the i'th video frame.
    """
    if output_path is None:
        output_path = os.path.splitext(video_path)[0] + "_keypoints.mp4"
        print(f"Saving video to {output_path}")

    if bodyparts is not None:
        if use_bodyparts is not None:
            coordinates = reindex_by_bodyparts(coordinates, bodyparts, use_bodyparts)
        else:
            use_bodyparts = bodyparts
        edges = get_edges(use_bodyparts, skeleton)
    else:
        edges = skeleton

    if crop_size is not None:
        outliers = np.any(np.isnan(coordinates), axis=2)
        interpolated_coordinates = interpolate_keypoints(coordinates, outliers)
        crop_centroid = np.nanmedian(interpolated_coordinates, axis=1)
        crop_centroid = gaussian_filter1d(crop_centroid, centroid_smoothing_filter, axis=0)

    reader = OpenCVReader(video_path)
    fps = reader.fps
    if frames is None:
        frames = np.arange(len(reader))

    if video_frame_indexes is None:
        video_frame_indexes = np.arange(len(coordinates))

    with imageio.get_writer(output_path, pixelformat="yuv420p", fps=fps, quality=quality) as writer:
        for frame in tqdm.tqdm(frames, ncols=72):
            image = overlay_keypoints_on_image(
                reader[frame], coordinates[frame], edges=edges, **plot_options
            )

            if crop_size is not None:
                image = crop_image(image, crop_centroid[frame], crop_size)

            if show_frame_numbers:
                image = cv2.putText(
                    image,
                    f"Frame {frame}",
                    (10, 20),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    text_color,
                    1,
                    cv2.LINE_AA,
                )

            writer.append_data(image)


def add_3D_pose_to_plotly_fig(
    fig,
    coords,
    edges,
    keypoint_colors,
    node_size=50.0,
    line_width=3.0,
    visible=True,
    opacity=1,
):
    """
    Add a 3D pose to a plotly figure.

    Parameters
    ----------
    fig: plotly figure
        Figure to which the pose should be added.

    coords: ndarray (N,3)
        3D coordinates of the pose.

    edges: list of index pairs
        Skeleton edges

    keypoint_colors : array-like with shape (num_keypoints,3)
        Color for each keypoint. If None, the keypoint colormap is used.
        If the dtype is int, the values are assumed to be in the range 0-255,
        otherwise they are assumed to be in the range 0-1.

    node_size: float, default=50.0
        Size of keypoints.

    line_width: float, default=3.0
        Width of skeleton edges.

    visibility: bool, default=True
        Initial visibility state of the nodes and edges

    opacity: float, default=1
        Opacity of the nodes and edges (0-1)
    """
    if isinstance(keypoint_colors[0, 0], int):
        keypoint_colors = np.array(keypoint_colors) / 255.0

    marker = {
        "size": node_size / 10,
        "color": keypoint_colors,
        "line": dict(color="black", width=0.5),
        "opacity": opacity,
    }

    line = {"width": line_width, "color": f"rgba(0,0,0,{opacity})"}

    fig.add_trace(
        plotly.graph_objs.Scatter3d(
            x=coords[:, 0],
            y=coords[:, 1],
            z=coords[:, 2],
            mode="markers",
            visible=visible,
            marker=marker,
        )
    )

    for e in edges:
        fig.add_trace(
            plotly.graph_objs.Scatter3d(
                x=coords[e, 0],
                y=coords[e, 1],
                z=coords[e, 2],
                mode="lines",
                visible=visible,
                line=line,
            )
        )

    if keypoint_colors is None:
        # Use a default color (for example, red) if no colors are provided
        keypoint_colors = ["red"] * len(coords)
    elif isinstance(keypoint_colors[0], int):
        # Convert RGB values from [0, 255] to [0, 1]
        keypoint_colors = np.array(keypoint_colors) / 255.0
    else:
        keypoint_colors = keypoint_colors

    marker = {
        "size": node_size,
        "color": keypoint_colors,
        "line": dict(color="black", width=0.5),
        "opacity": opacity,
    }


def plot_pcs_3D(
    ymean,
    ypcs,
    edges,
    keypoint_colors,
    savefig,
    project_dir=None,
    node_size=50,
    line_width=3,
    height=400,
    mean_pose_opacity=0.2,
):
    """
    Visualize the components of a fitted PCA model based on 3D components.

    For each PC, a subplot shows the mean pose (semi-transparent) along
    with a perturbation of the mean pose in the direction of the PC.

    Parameters
    ----------
    ymean : ndarray (num_bodyparts, 3)
        Mean pose.

    ypcs : ndarray (num_pcs, num_bodyparts, 3)
        Perturbations of the mean pose in the direction of each PC.

    edges : list of index pairs
        Skeleton edges.

    keypoint_colors : array-like, shape=(num_keypoints,3), default=None
        Color for each keypoint. If None, the keypoint colormap is used.
        If the dtype is int, the values are assumed to be in the range 0-255,
        otherwise they are assumed to be in the range 0-1.

    savefig : bool
        Whether to save the figure to a file. If true, the figure is
        saved to `{project_dir}/pcs.html`

    project_dir : str, default=None
        Path to the project directory. Required if `savefig` is True.

    node_size : float, default=50.0
        Size of the keypoints in the figure.

    line_width: float, default=3.0
        Width of edges in skeleton

    height : int, default=400
        Height of the figure in pixels.

    mean_pose_opacity: float, default=0.4
        Opacity of the mean pose
    """
    from plotly.subplots import make_subplots

    fig = make_subplots(rows=1, cols=1, specs=[[{"type": "scatter3d"}]])

    def visibility_mask(i):
        visible = np.zeros((len(edges) + 1) * (len(ypcs) + 1))
        visible[-(len(edges) + 1) :] = 1
        visible[(len(edges) + 1) * i : (len(edges) + 1) * (i + 1)] = 1
        return visible > 0

    steps = []
    for i, coords in enumerate(ypcs):
        add_3D_pose_to_plotly_fig(
            fig,
            coords,
            edges,
            keypoint_colors,
            visible=(i == 0),
            node_size=node_size,
            line_width=line_width,
        )

        steps.append(
            dict(
                method="update",
                label=f"PC {i+1}",
                args=[{"visible": visibility_mask(i)}],
            )
        )

    add_3D_pose_to_plotly_fig(
        fig,
        ymean,
        edges,
        keypoint_colors,
        opacity=mean_pose_opacity,
        node_size=node_size,
        line_width=line_width,
    )

    fig.update_layout(
        height=height,
        showlegend=False,
        sliders=[dict(steps=steps)],
        scene=dict(
            xaxis=dict(showgrid=False, showbackground=False),
            yaxis=dict(showgrid=False, showbackground=False),
            zaxis=dict(showgrid=False, showline=True, linecolor="black"),
            bgcolor="white",
            aspectmode="data",
        ),
        margin=dict(l=20, r=20, b=0, t=0, pad=10),
    )

    if savefig:
        assert project_dir is not None, fill("The `savefig` option requires a `project_dir`")
        save_path = os.path.join(project_dir, f"pcs.html")
        fig.write_html(save_path)
        print(f"Saved interactive plot to {save_path}")

    fig.show()


def plot_trajectories_3D(
    Xs,
    titles,
    edges,
    output_dir,
    keypoint_colormap="autumn",
    keypoint_colors=None,
    node_size=50.0,
    line_width=3.0,
    height=500,
    skiprate=1,
):
    """
    Visualize a set of 3D trajectories.

    Parameters
    ----------
    Xs : list of ndarrays (num_syllables, num_frames, num_bodyparts, 3)
        Trajectories to visualize.

    titles : list of str
        Title for each trajectory.

    edges : list of index pairs
        Skeleton edges.

    output_dir : str
        Path to save the interactive plot.

    keypoint_colormap : str, default='autumn'
        Name of a matplotlib colormap to use for coloring the keypoints.

    keypoint_colors : array-like, shape=(num_keypoints,3), default=None
        Color for each keypoint. If None, the keypoint colormap is used.
        If the dtype is int, the values are assumed to be in the range 0-255,
        otherwise they are assumed to be in the range 0-1.

    node_size : float, default=50.0
        Size of the keypoints in the figure.

    line_width: float, default=3.0
        Width of edges in skeleton

    height : int, default=500
        Height of the figure in pixels.

    skiprate : int, default=1
        Plot every `skiprate` frames.
    """
    from plotly.subplots import make_subplots

    if keypoint_colors is None:
        cmap = plt.colormaps[keypoint_colormap]
        keypoint_colors = np.array(cmap(np.linspace(0, 1, Xs.shape[2])))[:, :3]

    fig = make_subplots(rows=1, cols=1, specs=[[{"type": "scatter3d"}]])
    Xs = Xs[:, ::skiprate]

    def visibility_mask(i):
        n = (len(edges) + 1) * len(Xs[1])
        visible = np.zeros(n * len(Xs))
        visible[n * i : n * (i + 1)] = 1
        return visible > 0

    steps = []
    for i, X in enumerate(Xs):
        opacities = np.linspace(0.3, 1, len(X) + 1)[1:] ** 2
        for coords, opacity in zip(X, opacities):
            add_3D_pose_to_plotly_fig(
                fig,
                coords,
                edges,
                keypoint_colors,
                visible=(i == 0),
                node_size=node_size,
                line_width=line_width,
                opacity=opacity,
            )

        steps.append(
            dict(
                method="update",
                label=titles[i],
                args=[{"visible": visibility_mask(i)}],
            )
        )

    fig.update_layout(
        height=height,
        showlegend=False,
        sliders=[dict(steps=steps)],
        scene=dict(
            xaxis=dict(showgrid=False, showbackground=False),
            yaxis=dict(showgrid=False, showbackground=False),
            zaxis=dict(showgrid=False, showline=True, linecolor="black"),
            bgcolor="white",
            aspectmode="data",
        ),
        margin=dict(l=20, r=20, b=0, t=0, pad=10),
    )

    if output_dir is not None:
        save_path = os.path.join(output_dir, f"all_trajectories.html")
        fig.write_html(save_path)
        print(f"Saved interactive trajectories plot to {save_path}")

    fig.show()


def plot_similarity_dendrogram(
    coordinates,
    results,
    project_dir=None,
    model_name=None,
    save_path=None,
    metric="cosine",
    pre=5,
    post=15,
    min_frequency=0.005,
    min_duration=3,
    bodyparts=None,
    use_bodyparts=None,
    density_sample=False,
    sampling_options={"n_neighbors": 50},
    figsize=(6, 3),
    **kwargs,
):
    """Plot a dendrogram showing the similarity between syllable trajectories.

    The dendrogram is saved to `{save_path}` if it is provided, or
    else to `{project_dir}/{model_name}/similarity_dendrogram.pdf`. Plot-
    related parameters are described below. For the remaining parameters
    see (:py:func:`keypoint_moseq.util.get_typical_trajectories`)

    Parameters
    ----------
    coordinates: dict
        Dictionary mapping recording names to keypoint coordinates as
        ndarrays of shape (n_frames, n_bodyparts, [2 or 3]).

    results: dict
        Dictionary containing modeling results for a dataset (see
        :py:func:`keypoint_moseq.fitting.extract_results`).

    project_dir: str, default=None
        Project directory. Required to save figure if `save_path` is None.

    model_name: str, default=None
        Model name. Required to save figure if `save_path` is None.

    save_path: str, default=None
        Path to save the dendrogram plot (do not include an extension).
        If None, the plot will be saved  to
        `{project_dir}/{name}/similarity_dendrogram.[pdf/png]`.

    metric: str, default='cosine'
        Distance metric to use. See :py:func:`scipy.spatial.pdist` for options.

    figsize: tuple of float, default=(10,5)
        Size of the dendrogram plot.
    """
    save_path = _get_path(project_dir, model_name, save_path, "similarity_dendrogram")

    distances, syllable_ixs = syllable_similarity(
        coordinates,
        results,
        metric,
        pre,
        post,
        min_frequency,
        min_duration,
        bodyparts,
        use_bodyparts,
        density_sample,
        sampling_options,
    )

    Z = linkage(squareform(distances), "complete")

    fig, ax = plt.subplots(1, 1)
    labels = [f"Syllable {s}" for s in syllable_ixs]
    dendrogram(Z, labels=labels, leaf_font_size=10, ax=ax, leaf_rotation=90)

    ax.set_yticks([])
    for spine in ax.spines.values():
        spine.set_color("lightgray")
    ax.set_title("Syllable similarity")
    fig.set_size_inches(figsize)

    print(f"Saving dendrogram plot to {save_path}")
    for ext in ["pdf", "png"]:
        plt.savefig(save_path + "." + ext)


def matplotlib_colormap_to_plotly(cmap):
    """
    Convert a matplotlib colormap to a plotly colormap.

    Parameters
    ----------
    cmap: str
        Name of a matplotlib colormap.

    Returns
    -------
    pl_colorscale: list
        Plotly colormap.
    """
    cmap = plt.colormaps[cmap]
    pl_entries = 255
    h = 1.0 / (pl_entries - 1)
    pl_colorscale = []
    for k in range(pl_entries):
        C = (np.array(cmap(k * h)[:3]) * 255).astype(np.uint8)
        pl_colorscale.append([k * h, "rgb" + str((C[0], C[1], C[2]))])
    return pl_colorscale


def initialize_3D_plot(height=500):
    """Create an empty 3D plotly figure."""
    fig = make_subplots(rows=1, cols=1, specs=[[{"type": "scatter3d"}]])
    fig.update_layout(
        height=height,
        showlegend=False,
        scene=dict(
            xaxis=dict(showgrid=False, showbackground=False),
            yaxis=dict(showgrid=False, showbackground=False),
            zaxis=dict(showgrid=False, showline=True, linecolor="black"),
            bgcolor="white",
            aspectmode="data",
        ),
        margin=dict(l=20, r=20, b=0, t=0, pad=10),
    )
    return fig


def add_3D_pose_to_fig(
    fig,
    coords,
    edges,
    keypoint_colormap="autumn",
    node_size=6.0,
    linewidth=3.0,
    visible=True,
    opacity=1,
):
    """Add a 3D pose to a plotly figure.

    Parameters
    ----------
    fig: plotly figure
        Figure to which the pose should be added.

    coords: ndarray (N,3)
        3D coordinates of the pose.

    edges: list of index pairs
        Skeleton edges

    keypoint_colormap: str, default='autumn'
        Colormap to use for coloring keypoints.

    node_size: float, default=6.0
        Size of keypoints.

    linewidth: float, default=3.0
        Width of skeleton edges.

    visibility: bool, default=True
        Initial visibility state of the nodes and edges

    opacity: float, default=1
        Opacity of the nodes and edges (0-1)
    """
    marker = {
        "size": node_size,
        "color": np.linspace(0, 1, len(coords)),
        "colorscale": matplotlib_colormap_to_plotly(keypoint_colormap),
        "line": dict(color="black", width=0.5),
        "opacity": opacity,
    }

    line = {"width": linewidth, "color": f"rgba(0,0,0,{opacity})"}

    fig.add_trace(
        plotly.graph_objs.Scatter3d(
            x=coords[:, 0],
            y=coords[:, 1],
            z=coords[:, 2],
            mode="markers",
            visible=visible,
            marker=marker,
        )
    )

    for e in edges:
        fig.add_trace(
            plotly.graph_objs.Scatter3d(
                x=coords[e, 0],
                y=coords[e, 1],
                z=coords[e, 2],
                mode="lines",
                visible=visible,
                line=line,
            )
        )


def plot_pcs_3D(
    ymean,
    ypcs,
    edges,
    keypoint_colormap,
    project_dir=None,
    node_size=6,
    linewidth=2,
    height=400,
    mean_pose_opacity=0.2,
):
    """
    Visualize the components of a fitted PCA model based on 3D components.

    For each PC, a subplot shows the mean pose (semi-transparent) along
    with a perturbation of the mean pose in the direction of the PC.

    Parameters
    ----------
    ymean : ndarray (num_bodyparts, 3)
        Mean pose.

    ypcs : ndarray (num_pcs, num_bodyparts, 3)
        Perturbations of the mean pose in the direction of each PC.

    edges : list of index pairs
        Skeleton edges.

    keypoint_colormap : str
        Name of a matplotlib colormap to use for coloring the keypoints.

    project_dir : str, default=None
        Path to the project directory. Required if `savefig` is True.

    node_size : float, default=30.0
        Size of the keypoints in the figure.

    linewidth: float, default=2.0
        Width of edges in skeleton

    height : int, default=400
        Height of the figure in pixels.

    mean_pose_opacity: float, default=0.4
        Opacity of the mean pose
    """
    fig = initialize_3D_plot(height)

    def visibility_mask(i):
        visible = np.zeros((len(edges) + 1) * (len(ypcs) + 1))
        visible[-(len(edges) + 1) :] = 1
        visible[(len(edges) + 1) * i : (len(edges) + 1) * (i + 1)] = 1
        return visible > 0

    steps = []
    for i, coords in enumerate(ypcs):
        add_3D_pose_to_fig(
            fig,
            coords,
            edges,
            visible=(i == 0),
            node_size=node_size,
            linewidth=linewidth,
            keypoint_colormap=keypoint_colormap,
        )

        steps.append(
            dict(
                method="update",
                label=f"PC {i+1}",
                args=[{"visible": visibility_mask(i)}],
            )
        )

    add_3D_pose_to_fig(
        fig,
        ymean,
        edges,
        opacity=mean_pose_opacity,
        node_size=node_size,
        linewidth=linewidth,
        keypoint_colormap=keypoint_colormap,
    )

    fig.update_layout(sliders=[dict(steps=steps)])

    if project_dir is not None:
        save_path = os.path.join(project_dir, f"pcs.html")
        fig.write_html(save_path)
        print(f"Saved interactive plot to {save_path}")

    fig.show()


def plot_trajectories_3D(
    Xs,
    titles,
    edges,
    output_dir,
    keypoint_colormap="autumn",
    node_size=8,
    linewidth=3,
    height=500,
    skiprate=1,
):
    """
    Visualize a set of 3D trajectories.

    Parameters
    ----------
    Xs : list of ndarrays (num_syllables, num_frames, num_bodyparts, 3)
        Trajectories to visualize.

    titles : list of str
        Title for each trajectory.

    edges : list of index pairs
        Skeleton edges.

    output_dir : str
        Path to save the interactive plot.

    keypoint_colormap : str, default='autumn'
        Name of a matplotlib colormap to use for coloring the keypoints.

    node_size : float, default=8.0
        Size of the keypoints in the figure.

    linewidth: float, default=3.0
        Width of edges in skeleton

    height : int, default=500
        Height of the figure in pixels.

    skiprate : int, default=1
        Plot every `skiprate` frames.
    """
    fig = initialize_3D_plot(height)

    def visibility_mask(i):
        n = (len(edges) + 1) * len(Xs[1])
        visible = np.zeros(n * len(Xs))
        visible[n * i : n * (i + 1)] = 1
        return visible > 0

    steps = []
    Xs = Xs[:, ::skiprate]
    for i, X in enumerate(Xs):
        opacities = np.linspace(0.3, 1, len(X) + 1)[1:] ** 2
        for coords, opacity in zip(X, opacities):
            add_3D_pose_to_fig(
                fig,
                coords,
                edges,
                visible=(i == 0),
                node_size=node_size,
                linewidth=linewidth,
                keypoint_colormap=keypoint_colormap,
                opacity=opacity,
            )

        steps.append(
            dict(
                method="update",
                label=titles[i],
                args=[{"visible": visibility_mask(i)}],
            )
        )

    fig.update_layout(sliders=[dict(steps=steps)])

    if output_dir is not None:
        save_path = os.path.join(output_dir, f"all_trajectories.html")
        fig.write_html(save_path)
        print(f"Saved interactive trajectories plot to {save_path}")

    fig.show()


def plot_poses_3D(
    poses,
    edges,
    keypoint_colormap="autumn",
    node_size=6.0,
    linewidth=3.0,
):
    """Plot a sequence of 3D poses.

    Parameters
    ----------
    poses: array of shape (num_poses, num_bodyparts, 3)
        3D poses to plot.

    edges: list of index pairs
        Skeleton edges.

    keypoint_colormap: str, default='autumn'
        Colormap to use for coloring keypoints.

    node_size: float, default=6.0
        Size of keypoints.

    linewidth: float, default=3.0
        Width of skeleton edges.
    """
    fig = initialize_3D_plot()

    def visibility_mask(i):
        n = len(edges) + 1
        visible = np.zeros(n * len(poses))
        visible[n * i : n * (i + 1)] = 1
        return visible > 0

    steps = []

    for i, pose in enumerate(poses):
        add_3D_pose_to_fig(
            fig,
            pose,
            edges,
            visible=(i == 0),
            keypoint_colormap=keypoint_colormap,
            node_size=node_size,
            linewidth=linewidth,
        )

        steps.append(
            dict(
                method="update",
                label=f"Pose {i+1}",
                args=[{"visible": visibility_mask(i)}],
            )
        )

    fig.update_layout(sliders=[dict(steps=steps)])
    fig.show()


def hierarchical_clustering_order(X, dist_metric="euclidean", linkage_method="ward"):
    """Linearly order a set of points using hierarchical clustering.

    Parameters
    ----------
    X: ndarray of shape (num_points, num_features)
        Points to order.

    dist_metric: str, default='euclidean'
        Distance metric to use.

    linkage_method: str, default='ward'
        Linkage method to use.

    Returns
    -------
    ordering: ndarray of shape (num_points,)
        Linear ordering of the points.
    """
    D = pdist(X, dist_metric)
    Z = linkage(D, linkage_method)
    ordering = leaves_list(Z)
    return ordering


def plot_confusion_matrix(results1, results2, min_frequency=0.005, sort=True, normalize=True):
    """Plot a confusion matrix that compares syllables across two models.

    Parameters
    ----------
    results1: dict
        Dictionary containing modeling results for the first model (see
        :py:func:`keypoint_moseq.fitting.extract_results`).

    results2: dict
        Dictionary containing modeling results for the second model (see
        :py:func:`keypoint_moseq.fitting.extract_results`).

    min_frequency: float, default=0.005
        Minimum frequency of a syllable to include in the confusion matrix.

    sort: bool, default=True
        Whether to sort the syllables from each model to emphasize the diagonal.

    normalize: bool, default=True
        Whether to row-normalize the confusion matrix.

    Returns
    -------
    fig: matplotlib figure
        Figure containing the confusion matrix.

    ax: matplotlib axis
        Axis containing the confusion matrix.
    """
    syllables1 = np.concatenate([results1[k]["syllable"] for k in sorted(results1.keys())])
    syllables2 = np.concatenate([results2[k]["syllable"] for k in sorted(results2.keys())])

    C = np.zeros((np.max(syllables1) + 1, np.max(syllables2) + 1))
    np.add.at(C, (syllables1, syllables2), 1)

    if normalize:
        C = C / np.sum(C, axis=1, keepdims=True)

    ix1 = (get_frequencies(syllables1) > 0.005).nonzero()[0]
    ix2 = (get_frequencies(syllables2) > 0.005).nonzero()[0]
    C = C[ix1, :][:, ix2]

    if sort:
        row_order = hierarchical_clustering_order(C)
        C = C[row_order, :]
        ix1 = ix1[row_order]

        col_order = np.argsort(np.argmax(C, axis=0))
        C = C[:, col_order]
        ix2 = ix2[col_order]

    fig, ax = plt.subplots(1, 1)
    im = ax.imshow(C)
    ax.set_xticks(np.arange(len(ix2)))
    ax.set_xticklabels(ix2)
    ax.set_yticks(np.arange(len(ix1)))
    ax.set_yticklabels(ix1)
    ax.set_xlabel("Model 2")
    ax.set_ylabel("Model 1")
    ax.set_title("Confusion matrix")
    cbar = fig.colorbar(im, ax=ax)
    cbar.set_label("Probability")
    fig.tight_layout()
    return fig, ax


def plot_eml_scores(eml_scores, eml_std_errs, model_names):
    """Plot expected marginal likelihood scores for a set of models.

    Parameters
    ----------
    eml_scores: ndarray of shape (num_models,)
        EML score for each model.

    eml_std_errs: ndarray of shape (num_models,)
        Standard error of the EML score for each model.

    model_names: list of str
        Name of each model.
    """
    num_models = len(eml_scores)
    ordering = np.argsort(eml_scores)
    eml_scores = eml_scores[ordering]
    eml_std_errs = eml_std_errs[ordering]
    model_names = [model_names[i] for i in ordering]

    err_low = eml_scores - eml_std_errs
    err_high = eml_scores + eml_std_errs

    fig, ax = plt.subplots(1, 1, figsize=(4, 3.5))
    for i in range(num_models):
        ax.plot([i, i], [err_low[i], err_high[i]], c="k", linewidth=1)
    ax.scatter(range(num_models), eml_scores, c="k")
    ax.set_xticks(range(num_models))
    ax.set_xticklabels(model_names, rotation=90)
    ax.set_ylabel("EML score")
    plt.tight_layout()
    return fig, ax


def plot_pose(coordinates, bodyparts, skeleton, cmap="autumn", node_size=6, linewidth=3, ax=None):
    """
    Plot a single pose using matplotlib.

    Parameters
    ----------
    coordinates: ndarray of shape (num_bodyparts, 2)
        2D coordinates of the pose.

    bodyparts: list of str
        Bodypart names.

    skeleton: list of tuples
        Skeleton edges as pairs of bodypart names.

    cmap: str, default='autumn'
        Colormap to use for coloring keypoints.

    node_size: float, default=6
        Size of keypoints.

    linewidth: float, default=3
        Width of skeleton edges.

    ax: matplotlib axis, default=None
        Axis to plot on. If None, a new axis is created.

    Returns
    -------
    ax: matplotlib axis
        Axis containing the plot.
    """
    if ax is None:
        fig, ax = plt.subplots(1, 1)

    cmap = plt.get_cmap(cmap)
    colors = cmap(np.linspace(0, 1, len(bodyparts)))
    edges = get_edges(bodyparts, skeleton)

    for i, (x, y) in enumerate(coordinates):
        ax.scatter(x, y, s=node_size, c=[colors[i]])

    for i, j in edges:
        x = [coordinates[i, 0], coordinates[j, 0]]
        y = [coordinates[i, 1], coordinates[j, 1]]
        ax.plot(x, y, c=colors[i], linewidth=linewidth)

    ax.set_aspect("equal")
    return ax


--- File: keypoint_moseq/calibration.py ---
import numpy as np
import tqdm
import os
from textwrap import fill
from vidio.read import OpenCVReader
from keypoint_moseq.io import update_config
from keypoint_moseq.util import find_matching_videos, get_edges


def sample_error_frames(
    confidences,
    bodyparts,
    use_bodyparts,
    num_bins=10,
    num_samples=100,
    conf_pseudocount=1e-3,
):
    """Randomly sample frames, enriching for those with low confidence keypoint
    detections.

    Parameters
    ----------
    confidences: dict
        Keypoint detection confidences for a collection of recordings

    bodyparts: list
        Label for each keypoint represented in `confidences`

    use_bodyparts: list
        Ordered subset of keypoint labels to be used for modeling

    num_bins: int, default=10
        Number of bins to use for enriching low-confidence keypoint
        detections. Confidence values for all used keypoints are
        divided into log-spaced bins and an equal number of instances
        are sampled from each bin.

    num_samples: int, default=100
        Total number of frames to sample

    conf_pseudocount: float, default=1e-3
        Pseudocount used to augment keypoint confidences.

    Returns
    -------
    sample_keys: list of tuples
        List of sampled frames as tuples with format
        (key, frame_number, bodypart)
    """
    confidences = {k: v + conf_pseudocount for k, v in confidences.items()}
    all_confs = np.concatenate([v.flatten() for v in confidences.values()])
    min_conf, max_conf = np.nanmin(all_confs), np.nanmax(all_confs)
    thresholds = np.logspace(np.log10(min_conf), np.log10(max_conf), num_bins)
    mask = np.array([bp in use_bodyparts for bp in bodyparts])[None, :]

    sample_keys = []
    for low, high in zip(thresholds[:-1], thresholds[1:]):
        samples_in_bin = []
        for key, confs in confidences.items():
            for t, k in zip(*np.nonzero((confs >= low) * (confs < high) * mask)):
                samples_in_bin.append((key, t, bodyparts[k]))

        if len(samples_in_bin) > 0:
            n = min(num_samples // num_bins, len(samples_in_bin))
            for i in np.random.choice(len(samples_in_bin), n, replace=False):
                sample_keys.append(samples_in_bin[i])

    sample_keys = [sample_keys[i] for i in np.random.permutation(len(sample_keys))]
    return sample_keys


def load_sampled_frames(
    sample_keys,
    video_dir,
    video_frame_indexes,
    video_extension=None,
):
    """Load sampled frames from a directory of videos.

    Parameters
    ----------
    sample_keys: list of tuples
        List of sampled frames as tuples with format
        (key, frame_number, bodypart)

    video_dir: str
        Path to directory containing videos

    video_frame_indexes: dict
        Dictionary mapping recording names to arrays of video frame indexes.
        This is useful when the original keypoint coordinates used for modeling
        corresponded to a subset of frames from each video (i.e. if videos were
        trimmed or coordinates were downsampled).

    video_extension: str, default=None
        Preferred video extension (passed to :py:func:`keypoint_moseq.util.find_matching_videos`)

    Returns
    -------
    sample_keys: dict
        Dictionary mapping elements from `sample_keys` to the
        corresponding videos frames.
    """
    keys = sorted(set([k[0] for k in sample_keys]))
    videos = find_matching_videos(keys, video_dir, video_extension=video_extension)
    key_to_video = dict(zip(keys, videos))
    readers = {key: OpenCVReader(video) for key, video in zip(keys, videos)}
    pbar = tqdm.tqdm(
        sample_keys,
        desc="Loading sample frames",
        position=0,
        leave=True,
        ncols=72,
    )
    sampled_keys = {}
    for key, frame, bodypart in pbar:
        frame_ix = video_frame_indexes[key][frame]
        sampled_keys[(key, frame, bodypart)] = readers[key][frame_ix]
    return sampled_keys


def load_annotations(project_dir):
    """Reload saved calibration annotations.

    Parameters
    ----------
    project_dir: str
        Load annotations from `{project_dir}/error_annotations.csv`

    Returns
    -------
    annotations: dict
        Dictionary mapping sample keys to annotated keypoint
        coordinates. (See :py:func:`keypoint_moseq.calibration.sample_error_frames`
        for format of sample keys)
    """
    annotations = {}
    annotations_path = os.path.join(project_dir, "error_annotations.csv")
    if os.path.exists(annotations_path):
        for l in open(annotations_path, "r").read().split("\n")[1:]:
            key, frame, bodypart, x, y = l.split(",")
            sample_key = (key, int(frame), bodypart)
            annotations[sample_key] = (float(x), float(y))
    return annotations


def save_annotations(project_dir, annotations):
    """Save calibration annotations to a csv file.

    Parameters
    ----------
    project_dir: str
        Save annotations to `{project_dir}/error_annotations.csv`

    annotations: dict
        Dictionary mapping sample keys to annotated keypoint
        coordinates. (See :py:func:`keypoint_moseq.calibration.sample_error_frames`
        for format of sample keys)
    """
    output = ["key,frame,bodypart,x,y"]
    for (key, frame, bodypart), (x, y) in annotations.items():
        output.append(f"{key},{frame},{bodypart},{x},{y}")
    path = os.path.join(project_dir, "error_annotations.csv")
    open(path, "w").write("\n".join(output))
    print(fill(f"Annotations saved to {path}"))


def save_params(project_dir, estimator):
    """Save config parameters learned via calibration.

    Parameters
    ----------
    project_dir: str
        Save parameters `{project_dir}/config.yml`

    estimator: :py:func:`holoviews.streams.Stream`
        Stream object with fields `conf_threshold`, `slope`, `intercept`
    """
    update_config(
        project_dir,
        conf_threshold=float(estimator.conf_threshold),
        slope=float(estimator.slope),
        intercept=float(estimator.intercept),
    )


def _confs_and_dists_from_annotations(coordinates, confidences, annotations, bodyparts):
    confs, dists = [], []
    for (key, frame, bodypart), xy in annotations.items():
        if key in coordinates and key in confidences:
            k = bodyparts.index(bodypart)
            confs.append(confidences[key][frame][k])
            dists.append(np.sqrt(((coordinates[key][frame][k] - np.array(xy)) ** 2).sum()))
    return confs, dists


def _noise_calibration_widget(
    project_dir,
    coordinates,
    confidences,
    sample_keys,
    sample_images,
    annotations,
    *,
    keypoint_colormap,
    bodyparts,
    skeleton,
    error_estimator,
    conf_threshold,
    **kwargs,
):
    from scipy.stats import linregress
    from holoviews.streams import Tap, Stream
    import holoviews as hv
    import panel as pn
    from bokeh.models import GlyphRenderer, ImageRGBA, Scatter, GraphRenderer

    hv.extension("bokeh")

    max_height = np.max([sample_images[k].shape[0] for k in sample_keys])
    max_width = np.max([sample_images[k].shape[1] for k in sample_keys])

    edges = np.array(get_edges(bodyparts, skeleton))
    conf_vals = np.hstack([v.flatten() for v in confidences.values()])
    min_conf, max_conf = np.nanpercentile(conf_vals, 0.01), np.nanmax(conf_vals)

    annotations_stream = Stream.define("Annotations", annotations=annotations)()
    current_sample = Stream.define("Current sample", sample_ix=0)()
    estimator = Stream.define(
        "Estimator",
        slope=float(error_estimator["slope"]),
        intercept=float(error_estimator["intercept"]),
        conf_threshold=float(conf_threshold),
    )()

    img_tap = Tap(transient=True)
    vline_tap = Tap(transient=True)

    def update_scatter(x, y, annotations):
        confs, dists = _confs_and_dists_from_annotations(
            coordinates, confidences, annotations, bodyparts
        )

        log_dists = np.log10(np.array(dists) + 1)
        log_confs = np.log10(np.maximum(confs, min_conf))
        max_dist = np.log10(np.sqrt(max_height**2 + max_width**2) + 1)

        xspan = np.log10(max_conf) - np.log10(min_conf)
        xlim = (
            np.log10(min_conf) - xspan / 10,
            np.log10(max_conf) + xspan / 10,
        )
        ylim = (-max_dist / 50, max_dist)

        if len(log_dists) > 1:
            m, b = linregress(log_confs, log_dists)[:2]
            estimator.event(slope=m, intercept=b)
        else:
            m, b = estimator.slope, estimator.intercept

        if x is None:
            x = np.log10(conf_threshold)
        else:
            estimator.event(conf_threshold=10**x)
        passing_percent = (conf_vals > 10**x).mean() * 100

        scatter = hv.Scatter(zip(log_confs, log_dists)).opts(
            color="k",
            size=6,
            xlim=xlim,
            ylim=ylim,
            axiswise=True,
            frame_width=250,
            default_tools=[],
        )

        curve = hv.Curve([(xlim[0], xlim[0] * m + b), (xlim[1], xlim[1] * m + b)]).opts(
            xlim=xlim, ylim=ylim, axiswise=True, default_tools=[]
        )

        vline_label = hv.Text(
            x - (xlim[1] - xlim[0]) / 50,
            ylim[1] - (ylim[1] - ylim[0]) / 100,
            f"confidence\nthreshold\n{10**x:.5f}\n({passing_percent:.1f}%)",
        ).opts(
            axiswise=True,
            text_align="right",
            text_baseline="top",
            text_font_size="8pt",
            default_tools=[],
        )

        vline = hv.VLine(x).opts(
            axiswise=True,
            line_dash="dashed",
            color="lightgray",
            default_tools=[],
        )

        return (scatter * curve * vline * vline_label).opts(
            toolbar=None,
            default_tools=[],
            xlabel="log10(confidence)",
            ylabel="log10(error)",
        )

    def enforce_z_order_hook(plot, element):
        bokeh_figure = plot.state
        graph, scatter, rgb = None, None, None
        for r in bokeh_figure.renderers:
            if isinstance(r, GlyphRenderer):
                if isinstance(r.glyph, ImageRGBA):
                    rgb = r
                if isinstance(r.glyph, Scatter):
                    scatter = r
            if isinstance(r, GraphRenderer):
                graph = r
        bokeh_figure.renderers = [rgb, graph, scatter]

    def update_img(sample_ix, x, y):
        key, frame, bodypart = sample_key = sample_keys[sample_ix]
        image = sample_images[sample_key]
        h, w = image.shape[:2]

        keypoint_ix = bodyparts.index(bodypart)
        xys = coordinates[key][frame].copy()
        crop_size = np.sqrt(((xys - xys[keypoint_ix]) ** 2).sum(1)).max() * 2.5
        xys[:, 1] = h - xys[:, 1]
        masked_nodes = np.nonzero(~np.isnan(xys).any(1))[0]
        confs = confidences[key][frame]

        if x and y:
            annotations_stream.annotations.update({sample_key: (x, h - y)})
            annotations_stream.event()

        if sample_key in annotations_stream.annotations:
            point = np.array(annotations_stream.annotations[sample_key])
            point[1] = h - point[1]
        else:
            point = xys[keypoint_ix]

        colorvals = np.linspace(0, 1, len(bodyparts))
        pt_data = np.append(point, colorvals[keypoint_ix])[None]
        hv_point = hv.Points(pt_data, vdims=["bodypart"]).opts(
            color="bodypart",
            cmap="autumn",
            size=15,
            framewise=True,
            marker="x",
            line_width=3,
        )

        label = f"{bodypart}, confidence = {confs[keypoint_ix]:.5f}"
        rgb = hv.RGB(image, bounds=(0, 0, w, h), label=label).opts(
            framewise=True, xaxis="bare", yaxis="bare", frame_width=250
        )

        xlim = (
            xys[keypoint_ix, 0] - crop_size / 2,
            xys[keypoint_ix, 0] + crop_size / 2,
        )
        ylim = (
            xys[keypoint_ix, 1] - crop_size / 2,
            xys[keypoint_ix, 1] + crop_size / 2,
        )

        edge_data = ((), (), ())
        if len(edges) > 0:
            masked_edges = edges[np.isin(edges, masked_nodes).all(1)]
            if len(masked_edges) > 0:
                edge_data = (*masked_edges.T, colorvals[masked_edges[:, 0]])

        sizes = np.where(np.arange(len(xys)) == keypoint_ix, 10, 6)[masked_nodes]
        masked_bodyparts = [bodyparts[i] for i in masked_nodes]
        nodes = hv.Nodes(
            (*xys[masked_nodes].T, masked_nodes, masked_bodyparts, sizes),
            vdims=["name", "size"],
        )
        graph = hv.Graph((edge_data, nodes), vdims="ecolor").opts(
            node_color="name",
            node_cmap=keypoint_colormap,
            tools=[],
            edge_color="ecolor",
            edge_cmap=keypoint_colormap,
            node_size="size",
        )

        return (rgb * graph * hv_point).opts(
            data_aspect=1,
            xlim=xlim,
            ylim=ylim,
            toolbar=None,
            hooks=[enforce_z_order_hook],
        )

    def update_estimator_text(*, slope, intercept, conf_threshold):
        lines = [
            f"slope: {slope:.6f}",
            f"intercept: {intercept:.6f}",
            f"conf_threshold: {conf_threshold:.6f}",
        ]
        estimator_textbox.value = "<br>".join(lines)

    prev_button = pn.widgets.Button(name="\u25c0", width=50, align="center")
    next_button = pn.widgets.Button(name="\u25b6", width=50, align="center")
    save_button = pn.widgets.Button(name="Save", width=100, align="center")
    estimator_textbox = pn.widgets.StaticText(align="center")

    def next_sample(event):
        if current_sample.sample_ix < len(sample_keys) - 1:
            current_sample.event(sample_ix=int(current_sample.sample_ix) + 1)

    def prev_sample(event):
        if current_sample.sample_ix > 0:
            current_sample.event(sample_ix=int(current_sample.sample_ix) - 1)

    def save_all(event):
        save_annotations(project_dir, annotations_stream.annotations)
        save_params(project_dir, estimator)

    prev_button.on_click(prev_sample)
    next_button.on_click(next_sample)
    save_button.on_click(save_all)
    estimator.add_subscriber(update_estimator_text)
    estimator.event()

    img_dmap = hv.DynamicMap(
        update_img,
        streams=[current_sample, img_tap],
    ).opts(framewise=True)

    scatter_dmap = hv.DynamicMap(
        update_scatter,
        streams=[annotations_stream, vline_tap],
    ).opts(framewise=True, axiswise=True)

    controls = pn.Row(
        prev_button,
        next_button,
        pn.Spacer(width=50),
        save_button,
        pn.Spacer(width=50),
        estimator_textbox,
    )
    plots = pn.Row(img_dmap, scatter_dmap)
    return pn.Column(controls, plots)


def noise_calibration(
    project_dir,
    coordinates,
    confidences,
    *,
    bodyparts,
    use_bodyparts,
    video_dir,
    video_extension=None,
    conf_pseudocount=0.001,
    video_frame_indexes=None,
    **kwargs,
):
    """Perform manual annotation to calibrate the relationship between keypoint
    error and neural network confidence.

    This function creates a widget for interactive annotation in jupyter lab.
    Users mark correct keypoint locations for a sequence of frames, and a
    regression line is fit to the `log(confidence), log(error)` pairs obtained
    through annotation. The regression coefficients are used during modeling to
    set a prior on the noise level for each keypoint on each frame.

    Follow these steps to use the widget:
        - After executing this function, a widget should appear with a
          video frame in the center.
        - Annotate the labeled bodypart in each frame by left-clicking
          at the correct location. An "X" should appear there.
        - Use the arrow buttons to annotate additional frames.
        - Each annotation adds a point to the right-hand scatter plot.
          Continue until the regression line stabilizes.
        - At any point, adjust the confidence threshold by clicking on
          the scatter plot. The confidence threshold is used to define
          outlier keypoints for PCA and model initialization.
        - Use the "save" button to store your annotations to disk and
          save `slope`, `intercept`, and `confidence_threshold`
          to the config.


    Parameters
    ----------
    project_dir: str
        Project directory. Must contain a `config.yml` file.

    coordinates: dict
        Keypoint coordinates for a collection of recordings. Values
        must be numpy arrays of shape (T,K,2) where K is the number
        of keypoints. Keys can be any unique str, but must start with
        the name of a videofile in `video_dir`.

    confidences: dict
        Nonnegative confidence values for the keypoints in
        `coordinates` as numpy arrays of shape (T,K).

    bodyparts: list
        Label for each keypoint represented in `coordinates`

    use_bodyparts: list
        Ordered subset of keypoint labels to be used for modeling

    video_dir: str
        Path to directory containing videos. Each video should
        correspond to a key in `coordinates`. The key must
        contain the videoname as a prefix.

    video_extension: str, default=None
        Preferred video extension (used in :py:func:`keypoint_moseq.util.find_matching_videos`)

    conf_pseudocount: float, default=0.001
        Pseudocount added to confidence values to avoid log(0) errors.

    video_frame_indexes: dict, default-None
        Dictionary mapping recording names to arrays of video frame indexes.
        This is useful when the original keypoint coordinates used for modeling
        corresponded to a subset of frames from each video (i.e. if videos were
        trimmed or coordinates were downsampled).
    """
    if video_frame_indexes is None:
        video_frame_indexes = {k: np.arange(len(v)) for k, v in coordinates.items()}
    else:
        assert set(video_frame_indexes.keys()) == set(
            coordinates.keys()
        ), "The keys of `video_frame_indexes` must match the keys of `results`"
        for k, v in coordinates.items():
            assert len(v) == len(video_frame_indexes[k]), (
                "There is a mismatch between the length of `video_frame_indexes` "
                f"and the length of `coordinates` results for key {k}."
                f"\n\tLength of video_frame_indexes = {len(video_frame_indexes[k])}"
                f"\n\tLength of coordinates = {len(v)}"
            )

    dim = list(coordinates.values())[0].shape[-1]
    assert dim == 2, "Calibration is only supported for 2D keypoints."

    confidences = {k: v + conf_pseudocount for k, v in confidences.items()}
    sample_keys = sample_error_frames(confidences, bodyparts, use_bodyparts)

    annotations = load_annotations(project_dir)
    sample_keys.extend(annotations.keys())

    sample_images = load_sampled_frames(
        sample_keys,
        video_dir,
        video_frame_indexes,
        video_extension,
    )

    return _noise_calibration_widget(
        project_dir,
        coordinates,
        confidences,
        sample_keys,
        sample_images,
        annotations,
        bodyparts=bodyparts,
        **kwargs,
    )


--- File: docs/requirements.txt ---
# docs/requirements.txt
sphinx
sphinx-rtd-theme
autodocsumm
myst-nb
requests>=2.5.0
jax[cpu]==0.4.10
ml_dtypes==0.2.0
scipy==1.11.3

--- File: docs/Makefile ---
# Minimal makefile for Sphinx documentation
#

# You can set these variables from the command line, and also
# from the environment for the first two.
SPHINXOPTS    ?=
SPHINXBUILD   ?= sphinx-build
SOURCEDIR     = source
BUILDDIR      = build

# Put it first so that "make" without argument is like "make help".
help:
	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)

.PHONY: help Makefile

# Catch-all target: route all unknown targets to Sphinx using the new
# "make mode" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).
%: Makefile
	@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)


--- File: docs/README.md ---
# Documentation

To build the sphinx documentation, install requirements:
```
pip install sphinx sphinx-book-theme
```
then run
```
cd docs/
make html
```


--- File: docs/source/install.rst ---
Local installation
==================

- Total installation time is around 10 minutes.
- The first import of keypoint_moseq after installation can take a few minutes.
- If you experience any issues, reach out to us on `slack <https://join.slack.com/t/moseqworkspace/shared_invite/zt-151x0shoi-z4J0_g_5rwJDlO1IfCU34A>`_! We're happy to help.

.. note::

   If using Windows, make sure to run all the commands below from an Anaconda Prompt.

.. note::

   Keypoint moseq supports the same platforms as `jax <https://github.com/jax-ml/jax?tab=readme-ov-file#supported-platforms>`_. That is, it supports CPU and GPU installations on linux systems, and CPU installations on MacOS and Windows systems. GPU on WSL2 is considered 'experimental'.

Create a new conda environment with python 3.10::

   conda create -n keypoint_moseq python=3.10
   conda activate keypoint_moseq

Then use pip to install the version of keypoint moseq that you want::

   pip install keypoint-moseq # CPU only
   pip install keypoint-moseq[cuda] # GPU with CUDA 12

To run keypoint-moseq in jupyter, either launch jupyterlab directly from the ``keypoint_moseq`` environment or register a globally-accessible jupyter kernel as follows::

   python -m ipykernel install --user --name=keypoint_moseq


--- File: docs/source/index.rst ---
Keypoint MoSeq
==============


.. list-table::
   :widths: 30 30 30 30 30
   :header-rows: 0

   * - `GitHub <https://github.com/dattalab/keypoint-moseq/>`_
     - `Colab <https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb>`_
     - `Paper <https://www.nature.com/articles/s41592-024-02318-2>`_
     - `Slack <https://join.slack.com/t/moseqworkspace/shared_invite/zt-151x0shoi-z4J0_g_5rwJDlO1IfCU34A>`_
     - `License <https://github.com/dattalab/keypoint-moseq/blob/main/LICENSE.md>`_

.. image:: _static/logo.jpg
   :align: center

Motion Sequencing (MoSeq) is an unsupervised machine learning method for animal behavior analysis. Given behavioral recordings, MoSeq learns a set of stereotyped movement patterns and when they occur over time. This package provides tools for fitting a MoSeq model to keypoint tracking data and analyzing the results.


.. toctree::
   :caption: Setup
   
   install
   Google colab <https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb>


.. toctree::
   :caption: Tutorials

   modeling
   analysis

.. toctree::
   :caption: FAQs

   FAQs

.. toctree::
   :caption: Advanced topics

   advanced

.. toctree::
   :caption: Developer API

   fitting
   viz
   io
   util
   calibration


--- File: docs/source/FAQs.rst ---
.. raw:: html

   <link rel="stylesheet" href="_static/FAQs_style.css">


Code usage
==========

**Besides the tutorials there are a few ways to learn how to use keypoint-MoSeq:**

- Use the docstrings. All functions in keypoint-MoSeq have docstrings that explain their inputs, outputs and purpose. The docstrings can be accessed on this site using the search bar. They can also be accessed while coding using ``help(function_name)`` or by adding a question mark, as in ``function_name?``.

- Join our `slack workspace <https://join.slack.com/t/moseqworkspace/shared_invite/zt-151x0shoi-z4J0_g_5rwJDlO1IfCU34A>`_. We are happy to answer questions and help troubleshoot issues.

- Search the `github issues <https://github.com/dattalab/keypoint-moseq/issues>`_ to see if anyone else has had a similar question.

Input data
==========

How much data do I need?
------------------------
As a rule of thumb, a few hours (a few hundred thousand frames) of data are needed. More data is better. Since keypoint-MoSeq uses a hierarchical Dirichlet process (HDP) prior, the number of distinct syllables detected will gradually increase with more input data. Therefore a larger dataset may be necessary to detect rare behaviors.

How many/which keypoints?
-------------------------
A fine starting point is 5-10 keypoints. For rodents, we recommend omitting the tail. The most important aspect is that the keypoints are informative and provide a holistic description of the animal's pose. If you are already tracking 4 keypoints along the spine, for example, adding 4 more may not add much new information. Note that it is always possible to exclude keypoints from modeling using the ``use_bodyparts`` setting in the config.

Multiple animals
----------------
- **For multi-animal experiments where the animals are comparable in size and shape** (e.g. same sex and strain), it is best to fit a single model to all the data from both animals, which will result in two or more syllable sequences for each video. To load multi-animal data from SLEAP or DeepLabCut, the same functions can be used as for single-animal data, and each tracked animal will be added as a separate key/value pair in the ``coordinates`` and ``confidences`` dictionaries. In SLEAP, for example, a single file called ``two_mice.h5`` will generate a pair of keys ``'two_mice_track0', 'two_mice_track1'``. In DeepLabCut, the name of each individual will be used as a suffix, e.g. ``'two_mice_mouseA', 'two_mice_mouseB'``. These keys can then be used at the end of modeling to access syllables for each animal.

- **For multi-animal experiments where the animals differ in size** (e.g. adults and pups), it is best to fit separate models. If the tracking data is contained in a single file, the ``use_bodyparts`` config option can be used to limit modeling to the subset of keypoints belonging to each animal respectively. If the tracking data for each type of animal is in separate files, then simply restrict to the appropriate files when loading the data. 


Keypoints are noisy
-------------------
In general, keypoint-MoSeq is tolerant to noise in keypoint tracking. During fitting, the model tries to detect and downweight tracking errors. It also takes advantage of neural network-based confidence estimates when they are available (which is typically the case for DeepLabCut and SLEAP). A good rule of thumb is to watch a video of the tracked keypoints. If you can tell what the animal is doing from the keypoints alone, then they likely provide a good starting point for keypoint-MoSeq.

High proportion of NaNs
-----------------------
If your keypoint tracking data contains a high proportion of NaNs, you may get the following warning when loading it with keypoint-MoSeq:

.. image:: _static/nan_warning.png
   :align: center

.. raw:: html

   <br />


- Check if the NaNs are occuring in a specific subset of recordings. If they are, then it may be useful to exclude them from modeling, or to retrain the keypoint detection network with added training examples from the problematic recordings. For a recording-by-recording breakdown of NaNs, run

.. code-block:: python

   kpms.check_nan_proportions(coordinates, bodyparts, breakdown=True)

- Rerun keypoint detection with a lower threshold for missing data. In general, keypoint tracking algorithms such as SLEAP and DeepLabCut will mark a keypoint as NaN in a given frame if its confidence is below a certain level. In SLEAP, this level can be adjusted using the argument ``--peak_threshold`` when `running inference from the command line <https://sleap.ai/notebooks/Training_and_inference_on_an_example_dataset.html#inference>`_, e.g.

.. code-block:: python

   sleap-track VIDEO [other_args] --peak_threshold 0.05


Should I preprocess keypoints?
------------------------------
For 2D keypoint tracking we generally don't recommend this. Keypoint-MoSeq is designed to work with raw keypoints. Preprocessing (e.g., smoothing, filtering, etc.) may remove important information.

Head-fixed animals
------------------
We have only tested keypoint-MoSeq on freely moving animals, using either 2D keypoint detections from a top-down/bottom-up camera, or 3D keypoint detections inferred from multiple camera angles. But head-fixed animals could work in principle. In that case, one may wish to prevent keypoint-MoSeq from inferring heading angle and performing egocentric alignment. This can be done by setting ``fix_heading=True`` in the config.

Non-rodents
-----------
Keypoint-MoSeq has only been validated on rodents (mice, rats, and anecdotal success with naked mole rats), but there is no reason in principle that it wouldn't work on other species such as insects. If you try it on another species, please let us know how it goes! A key consideration for non-rodents is setting the target syllable duration, which may differ from the 400ms, which we recommend for rodents. For additional information, see :ref:`Choosing the target syllable duration <target duration>`.

.. _loading data:

Loading keypoint tracking data
------------------------------
Keypoint-MoSeq can be used with any method that produces 2D or 3D keypoint detections. Currently we support SLEAP, DeepLabCut, anipose, SLEAP-anipose, Neurodata Without Borders (NWB), Facemap, FreiPose and DANNCE. For methods not on this list, you can write a custom loading function or get in touch and request it as a new feature. 

- If using one of the supported formats, data can be loaded as follows, optionally replacing ``'deeplabcut'`` with one of the following: ``'sleap', 'anipose', 'sleap-anipose', 'nwb', 'facemap', 'freipose', 'DANNCE'``. The file formats expected in each case are described in the docstring for :py:func:`keypoint_moseq.io.load_keypoints`.

.. code-block:: python

   coordinates, confidences, bodyparts = kpms.load_keypoints(keypoint_data_path, 'deeplabcut')


- If writing your own data loader, the output should be a ``coordinates`` dictionary that maps recording names to arrays of shape ``(num_frames, num_keypoints, num_dimensions)``, where ``num_dimensions`` is 2 or 3. The keypoint axis should correspond to the `bodyparts` list in the config. You can also include a ``confidences`` dictionary that maps recording names to arrays of shape ``(num_frames, num_keypoints)``. If your loader applies to a commonly used keypoint inference method, please let us know! We'd love to add it for others to use.

- We are also happy to help write a loader for your data. Just open a `github issue <https://github.com/dattalab/keypoint-moseq/issues>`_ and describe the method you used for keypoint tracking and the format of the data, including the file format, how it is organized into directories, and how the output files are typically named (especially in relation to the corresponding videos). If possible, also send one or more example files to calebsw@gmail.com. 


Size variation between animals
------------------------------
Substantial size variation between animals may cause syllables to become over-fractionated, i.e. the same behaviors may be split into multiple syllables based on size alone. We plan to address this in a future release. Please get in touch if this is a pressing issue for you, either by opening a `github issue <https://github.com/dattalab/keypoint-moseq/issues>`_, or reaching out through our `Slack workspace <https://join.slack.com/t/moseqworkspace/shared_invite/zt-151x0shoi-z4J0_g_5rwJDlO1IfCU34A>`_.

3D keypoint data
----------------
Keypoint-MoSeq can be used with 3D keypoint data.

- For data loading, we support Anipose and SLEAP-anipose (see :ref:`Loading keypoint tracking data <loading data>`). 

- For visualization, :py:func:`keypoint_moseq.viz.plot_pcs` and :py:func:`keypoint_moseq.viz.generate_trajectory_plots` can be run exactly as described in the tutorial. Both functions will render 2D projections in the x/y and x/z planes and also generate 3D interactive plots. The 3D plots are rendered in the notebook and can also be viewed offline in a browser using the saved .html file. For grid movies, see :ref:`Making grid movies for 3D data <3d grid movies>`.


Modeling
========

Validating model outputs
------------------------
**To confirm that model fitting was successful, you can check the following:**

- Syllables have the target duration. You can check the median duration by inspecting the plots generated during fitting (as shown below). You can also plot the distribution of syllable durations using ``kpms.plot_duration_distribution(project_dir, model_name)``. If the median duration is below/above the target value, adjust the ``kappa`` hyperparameter and re-fit the model. Initially it may be necessary to change `kappa` by a factor of 10 or more. 

- The syllable labels stabilized during the last few iterations of model fitting. This can be checked by inspection of the heatmaps generated during model fitting (e.g. the right-most subplot below).

- The trajectory plots for each syllable are distinct and depict recognizable behaviors.

- The grid movies for each syllable are distinct and internally consistent. 

.. image:: _static/fitting_progress.png
   :align: center

.. raw:: html

   <br />



.. _target duration:

Choosing the target syllable duration
-------------------------------------
For rodents we recommend a target duration of ~400ms (i.e. 12 frames at 30fps), since this timescale has been validated through analyses of behavior and neural activity in previous studies. For other animals or head-fixed setups, the target duration may be different, and depends mainly on the timescale of behavior that you are interested in.


Number of model fitting iterations
----------------------------------
It may be necessary to re-run the fitting process a few times to choose a good value for the `kappa` hyperparameter. During these initial runs, fitting need only be run until the syllable durations stabilize. This typically takes <10 for the initial (AR only) stage of fitting, and 10-50 iterations for the second (full model) stage. After setting ``kappa``, continue fitting until the syllable sequence stabilizes, e.g. 200-500 iterations. In our experience, the model fit improves somewhat from 200 to 500 iterations, but not after that.


Detecting existing syllables in new data
----------------------------------------
If you already have a trained a MoSeq model and would like to apply it to new data, you can do so using the ``apply_model`` function.

.. code-block:: python

   # load the most recent model checkpoint and pca object
   model = kpms.load_checkpoint(project_dir, model_name)[0]
   pca = kpms.load_pca(project_dir)

   # load new data (e.g. from deeplabcut)
   new_data = 'path/to/new/data/' # can be a file, a directory, or a list of files
   coordinates, confidences, bodyparts = kpms.load_keypoints(new_data, 'deeplabcut')
   data, metadata = kpms.format_data(coordinates, confidences, **config())

   # apply saved model to new data
   results = kpms.apply_model(model, data, metadata, project_dir, model_name, **config())


.. note::

   Some users have reported systematic differences in the way syllables are assigned when applying a model to new data. To control for this, we recommend running `apply_model` to both the new and original data and using these new results instead of the original model output. To save the original results, simply rename the original `results.h5` file or save the new results to a different filename using `results_path="new_file_name.h5"`.


Continue model fitting but with new data
----------------------------------------
If you already trained keypoint MoSeq model, but would like to improve it using newly collected data (without starting from scratch), then follow the recipe below. Briefly, the code shows how to load model parameters from a saved checkpoint and then use them as the starting point for a new round of model fitting.

.. code-block:: python

   import keypoint_moseq as kpms

   project_dir = 'project/directory'
   config = lambda: kpms.load_config(project_dir)
   model_name = 'name_of_model' (e.g. '2023_03_16-15_50_11')
   
   # load and format new data (e.g. from DeepLabCut)
   new_data = 'path/to/new/data/' # can be a file, a directory, or a list of files
   coordinates, confidences,bodyparts = kpms.load_keypoints(new_data, 'deeplabcut')
   data, metadata = kpms.format_data(coordinates, confidences, **config())

   # load previously saved PCA and model checkpoint
   pca = kpms.load_pca(project_dir)
   model = kpms.load_checkpoint(project_dir, model_name)[0]

   # initialize a new model using saved parameters
   model = kpms.init_model(
      data, pca=pca, params=model['params'], 
      hypparams=model['hypparams'], **config())
   
   # continue fitting, now with the new data
   model, model_name = kpms.fit_model(
      model, data, metadata, project_dir, ar_only=False, num_iters=200)[0]
      

Interpreting model outputs
--------------------------
The final output of keypoint MoSeq is a results .h5 file (and optionally a directory of .csv files) that contain the following information:

- Syllables
   The syllable label assigned to each frame (i.e. the state indexes assigned by the model).

- Centroid and heading
   The centroid and heading of the animal in each frame, as estimated by the model. 

- Latent state
   Low-dimensional representation of the animal's pose in each frame. These are similar to PCA scores, are modified to reflect the pose dynamics and noise estimates inferred by the model. 


Validating results when applying a model to new data
----------------------------------------------------
When applying a model to new data, it may be useful to generate new grid movies and trajectory plots so you can confirm that the meaning of the syllables has been preserved. Let's say you've already applied the model to new data as follows:

   .. code-block:: python

      # load new data (e.g. from deeplabcut)
      coordinates, confidences, bodyparts = kpms.load_keypoints(new_data_path, 'deeplabcut')
      data, metadata = kpms.format_data(coordinates, confidences, **config())

      # apply saved model to new data
      results = kpms.apply_model(model, data, metadata, project_dir, model_name, **config())

By default, the `results` dictionary above contains results for both the new and old data. To generate grid movies and trajectory plots for the new data only, we can subset the `results` dictionary to include only the new data. We will also need to specify alternative paths for saving the new movies and plots so the original ones aren't overwritten.

   .. code-block:: python
      
      import os 

      # only include results for the new data
      new_results = {k:v for k,v in results.items() if k in coordinates}

      # save trajectory plots for the new data
      output_dir = os.path.join(project_dir, model_name, "new_trajectory_plots")
      kpms.generate_trajectory_plots(
         coordinates, new_results, project_dir,model_name, output_dir=output_dir, **config()
      )

      # save grid movies for the new data
      output_dir = os.path.join(project_dir, model_name, "new_grid_movies")
      kpms.generate_grid_movies(
         new_results, project_dir, model_name, coordinates=coordinates, output_dir=output_dir, **config()
      );



Visualization
=============

.. _3d grid movies:

Making grid movies for 3D data
------------------------------

Grid movies show examples of each syllable. For 2D keypoints, these clips are cropped from the original video recordings and rotated so that the animal faces in a consistent direction. Doing the same thing for 3D data is complicated because:

   - there are usually multiple videos (from different angles) associated with each recording
   - 3D keypoints alone don't provide enough information to crop videos around the animal
   - rotating videos to change the heading only makes sense for top-down or bottom-up views
   
Below we provide two code recipes to get around these issues. The first recipe is simpler and recommended for people without much programming experience. 

1) Make grid movies that just show the keypoints (i.e., without showing clips from original videos). This can be done by setting ``keypoints_only=True`` when calling :py:func:`keypoint_moseq.viz.generate_grid_movies`, as shown below. It may be necessary to adjust ``keypoints_scale``, which determines the number of pixels per 3D unit (the default value ``keypoints_scale=1.0`` means that 1 unit in 3D space corresponds to 1 pixel in the grid movie).

   .. code-block:: python

      kpms.generate_grid_movies(
         results, 
         project_dir, 
         model_name, 
         coordinates=coordinates, 
         keypoints_only=True, 
         keypoints_scale=1,
         use_dims=[0,1], # controls projection plane
         **config());


2) Pick a camera angle and load the 2D keypoint detections from that camera. The exact code for this will depend on the format of the 2D keypoints and the way that the 3D keypoint files, 2D keypoint files, and video files are organized. To take a simple example, let's say you filmed a mouse from the top and the side, performed 2D keypoint detection using SLEAP, and now have the following files for each recording:

   .. code-block:: bash

      <video_dir>/
      ├──<recording_name>.h5        # 3D keypoints
      ├──top-<recording_name>.h5    # 2D keypoints from top camera
      ├──top-<recording_name>.mp4   # video from top camera
      ├──side-<recording_name>.h5   # 2D keypoints from side camera
      ├──side-<recording_name>.mp4  # video from side camera

   To make grid movies using the top-camera, you'd need to load the top-camera 2D keypoints and match them up with the modeling results (which were most likely named using the 3D keypoints files), then compute 2D centroids and headings, and finally pass everything to :py:func:`keypoint_moseq.viz.generate_grid_movies`.

   .. code-block:: python

      video_dir = ... # insert path to video directory

      coordinates_2D,_,_ = kpms.load_keypoints(f'{video_dir}/top-*', 'sleap')
      video_paths = kpms.find_matching_videos(coordinates_2D.keys(), video_dir, as_dict=True)

      # rename keys to match the results dictionary
      coordinates_2D = {k.replace('top-', ''): v for k, v in coordinates_2D.items()}
      video_paths    = {k.replace('top-', ''): v for k, v in video_paths.items()}

      # compute the 2D centroid and heading
      centroids, headings = kpms.get_centroids_headings(coordinates_2D, **config())

      # make the grid movies
      kpms.generate_grid_movies(
         results, 
         project_dir, 
         model_name, 
         video_paths=video_paths,
         coordinates=coordinates_2D, 
         centroids=centroids,
         headings=headings,
         **config());

   You could follow a similar procedure for the side camera, but adding an extra line to zero-out the heading so the video clips aren't rotated.

   .. code-block:: python

      heading = {k: np.zeros_like(v) for k in heading.items()}


Why are there only trajectory plots for a subset of syllables?
--------------------------------------------------------------

There are two reasons why a syllable might be excluded from the trajectory plots:

1) It's frequency is below ``min_frequency``. By default ``min_frequency=0.005``, meaning that the syllable must make up at least 0.5% of all syllable instances. Lowering ``min_frequency`` may result in more syllables being included in the trajectory plots.

2) There aren't enough usable instances of the syllable. The number of required instances (50 by default) is set by the ``n_neighbors`` key of the ``sampling_options`` parameter. If you want to lower this number, (e.g. to 20) then you could call ``generate_trajectory_plots`` as follows.

   .. code-block:: python

      kpms.generate_trajectory_plots(..., sampling_options={"mode": "density", "n_neighbors": 20})

   Note that the number of *usable* syllable instances may be less than the total number of instances. Three criteria determine whether an instance is usable:

   - ``pre``: the number of frames prior to syllable onset that are included in the trajectory. By default, ``pre=5``, meaning that the trajectory will include the 5 frames prior to syllable onset. If a particular syllable instance starts within the first 5 frames of the video, then it is excluded.

   - ``post``: the number of frames after syllable onset that are included in the trajectory. By default, ``post=15``, meaning that the trajectory will include the 15 frames after syllable onset. If a particular syllable instance starts within the last 15 frames of the video, then it is excluded.

   - ``min_duration``: the minimum duration of a syllable instance. By default, ``min_duration=3``, meaning that syllable instances lasting less than 3 frames are excluded.

In summary, the following parameter changes will tend to increase the number of syllables included in the trajectory plots: 

- Lowering ``min_frequency`` (e.g. to 0.001)

- Lowering ``n_neighbors`` (e.g. to 20)

- Lowering ``pre`` (at this point you're scraping the bottom of the barrel)

- Lowering ``post`` (again, scraping the bottom of the barrel here)

- Lowering ``min_duration`` (this should be avoided; why are your syllables so short?)


Why are there only grid movies for a subset of syllables?
---------------------------------------------------------

There are two reasons why a syllable might not have a grid movie:

1) It's frequency is below ``min_frequency``. By default ``min_frequency=0.005``, meaning that the syllable must make up at least 0.5% of all syllable instances. Lowering ``min_frequency`` may result in more syllables being included among the grid movies.

2) There aren't enough usable instances of the syllable. There have to be at least enough instances to fill up every cell of the grid. The number of grid cells is determined by the ``rows`` and ``cols`` parameters. Note that the number of *usable* syllable instances may be less than the total number of instances. Three criteria determine whether an instance is usable:

   - ``pre``: the number of frames prior to syllable onset that are included in the grid movie. By default, ``pre=30``, meaning that movie in each grid cell starts 30 frames prior to syllable onset. So if a particular syllable instance starts within the first 30 frames of the experiment, then it is excluded.

   - ``post``: the number of frames after syllable onset that are included in the grid movie. By default, ``post=60``, meaning that the movie in each grid cell ends 60 frames after syllavle onset. If a particular syllable instance starts within the last 60 frames of the experiment, then it is excluded.

   - ``min_duration``: the minimum duration of a syllable instance. By default, ``min_duration=3``, meaning that syllable instances lasting less than 3 frames are excluded.

In summary, the following parameter changes will tend to increase the number of syllables included in the grid movies:

- Lowering ``min_frequency`` (e.g. to 0.001)

- Lowering ``pre`` (at this point you're scraping the bottom of the barrel)

- Lowering ``post`` (again, scraping the bottom of the barrel here)

- Lowering ``min_duration`` (this should be avoided; why are your syllables so short?)


Why do my trajectory plots and grid movies disagree?
----------------------------------------------------

Users occasionally find that the trajectory plot and grid movie for a given syllable don't match up. For example the animal might turn left in the trajectory plot but not consistently do so in the grid movie. Similarly, trajectory plots can occasionally change dramatically when a trained keypoint-MoSeq model is applied to new data. In most cases, these inconsistencies are caused by **density sampling of syllable instances**. Turning this feature off may result in more stable trajectory plots.

.. code-block:: python

   kpms.generate_trajectory_plots(..., density_sample=False)

Density sampling is a way of selecting syllable instances that are most representative relative to the full dataset. Specifically, for each syllable, a syllable-specific density function is computed in trajectory space and compared to the overall density across all syllables. An exemplar instance that maximizes the ratio between these densities is chosen for each syllable, and its nearest neighbors are randomly sampled. When the distribution of trajectories for a syllable is multimodal (i.e., it represents a mixture of distinct behaviors), the examplar syllable may not capture the full range of behaviors, or it may jump from one mode to another when an existing model is applied to new data. In these cases, it may be better to sample syllable instances uniformly by setting turning off density sampling as shown above.


Troubleshooting
===============

We are contiually updating the keypoint MoSeq code in response to user feedback and issues, so please make sure you are using the latest version. You can check the version by running ``kpms.__version__`` (note that for versions ≤0.0.5, the latter command will cause an error). To update to the latest version, run the following in a command terminal in an environment with keypoint-moseq installed (not inside a jupyter notebook!).
   
.. code-block:: python

    pip install --U keypoint_moseq 

Note that for any already open notebooks, you will need to restart the kernel to use the updated version. If your problem remains after troubleshooting, please open a `github issue <https://github.com/dattalab/keypoint-moseq/issues>`_. 


Dead kernel
-----------

On Windows, GPU out of memory (OOM) errors may cause silent kernel failure. To determine whether this is the likely cause, try re-fitting the model using a small subset of the data. If the kernel still dies, then it is likely a different issue. If the kernel does not die, then it is likely an OOM error. Some workarounds for OOM errors are described below.


Out of memory
-------------

There are two main causes of GPU out of memory (OOM) errors:

1. **Multiple instances of keypoint MoSeq are running on the same GPU.** 

  This can happen if you're running multiple notebooks or scripts at the same time. Since JAX preallocates 75% of the GPU when it is first initialized (i.e. after running ``import keypoint_moseq``), there is very little memory left for the second notebook/script. To fix this, you can either shutdown the kernels of the other notebooks/scripts or use a different GPU.


2. **Large datasets.** 

  Required GPU memory scales roughly linearly with the size of the dataset and the number of latent dimensions used. For example, a dataset with 4 latent dimensions will require roughly ~3MB GPU memory for each 100 frames of data during model fitting. If your GPU isn't big enough, try one of the following:

  - Use `Google colab <https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb>`_. 

    - Colab provides free access to GPUs with 16GB of VRAM.
    
    - Larger GPUs can be accessed using colab pro. 


  - Disable parallel message passing. This results in a large (4-6 fold) reduction in memory usage, but will also slow down model fitting by a similar factor. To disable parallel message passing, pass ``parallel_message_passing=False`` to :py:func:`keypoint_moseq.fit_model` or :py:func:`keypoint_moseq.apply_model`. For example

   .. code-block:: python

      kpms.fit_model(
         model, data, metadata, project_dir, 
         model_name, parallel_message_passing=False)


  - Partially serialize the computations. By default, modeling is parallelized across the full dataset. We also created an option for mixed parallel/serial computation where the data is split into batches that are processed serially. To enable this option, run the following code *before fitting the model* (if you have already initiated model fitting the kernel must be restarted).

   .. code-block:: python

      from jax_moseq.utils import set_mixed_map_iters
      set_mixed_map_iters(4)

   This will split the data into 4 batches, which should reduce the memory requirements about 4-fold but also result in a 4-fold slow-down. The number of batches can be adjusted as needed.


  - Use multiple GPUs if they are available. To split the computation across GPUs, run the following code *before fitting the model* (if you have already initiated model fitting the kernel must be restarted).

   .. code-block:: python

      from jax_moseq.utils import set_mixed_map_gpus
      set_mixed_map_gpus(2)

   This will split the computation across two GPUs. The number should be adjusted according to your hardware setup. 


  - Switch to single-precision computing by running the code below immediarely after importing keypoint MoSeq. Note that this may result in numerical instability which will cause NaN values to appear during fitting. Keypoint MoSeq will abort fitting if this occurs.

  .. code-block:: python
   
      import jax
      jax.config.update('jax_enable_x64', False)

    
  - Fit to a subset of the data, then apply the model to the rest of the data. 

    - To fit a subset of the data, specify the subset as a list of paths during data loading

      .. code-block:: python

        initial_data = ['path/to/file1.h5', 'path/to/file2.h5']
        coordinates, confidences, bodyparts = kpms.load_keypoints(initial_data, 'deeplabcut')

    - After model fitting, apply the model serially to the old and new data as follows

      .. code-block:: python

        model = kpms.load_checkpoint(project_dir, model_name)[0]
        pca = kpms.load_pca(project_dir)

        new_data_batch1 = ['path/to/file3.h5', 'path/to/second/file4.h5']
        new_data_batch2 = ['path/to/file5.h5', 'path/to/second/file6.h5']

        for batch in [initial_data, new_data_batch1, new_data_batch2]:

            coordinates, confidences, bodyparts = kpms.load_keypoints(batch, 'deeplabcut')
            data, metadata = kpms.format_data(coordinates, confidences, **config())
            results = kpms.apply_model(model, data, metadata, project_dir, model_name, **config())


NaNs during fitting
-------------------

The following actions may help resolve NaNs during model fitting. If they don't, please contact calebsw@gmail.com and include the data, config file, and code used for fitting, as well as the most recent model checkpoint. 

- Make sure you are using double-precision computing. Check the precision using

.. code-block:: python

    import jax
    jax.config.read('jax_enable_x64')


- Try increasing adjusting the `jitter` parameter, which controls the amount of regularization used to prevent singular matrices. The default value is 1e-3, but it may be necessary to increase this to 1e-2 or 1e-1 using the `jitter` keyword argument in `fit_model`.

- Enable parallel Kalman sampling. By default, it is only enabled when fittin with a GPU. You can override this, however, using the argument `parallel_message_passing=True` when running `fit_model`.


Installation errors
-------------------

- ``UNKNOWN: no kernel image is available for execution on the device``

  If you're running into issues when trying to use the GPU-accelerated version, you might see this error message::

     jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: no kernel image is available for execution on the device

  First, check if jax can detect your GPU::

     python -c "import jax; print(jax.default_backend())

  The result should be "gpu". If it isn't, then you might not be using the right version of ``cudatoolkit`` or ``cudnn``. If you installed these via ``conda``, you can check by doing a ``conda list | grep cud``. If you are on the right versions, try `updating your GPU driver to the latest version <https://nvidia.com/drivers>`_.


--- File: docs/source/viz.rst ---
Visualization
=============

.. automodule:: keypoint_moseq.viz
   :members:

--- File: docs/source/conf.py ---
# Configuration file for the Sphinx documentation builder.
#
# This file only contains a selection of the most common options. For a full
# list see the documentation:
# https://www.sphinx-doc.org/en/master/usage/configuration.html

# -- Path setup --------------------------------------------------------------

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
import os
import sys

sys.path.insert(0, os.path.abspath("../.."))

# -- Project information -----------------------------------------------------

project = "Keypoint MoSeq"
author = "Caleb Weinreb"

# -- General configuration ---------------------------------------------------

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    "sphinx.ext.viewcode",
    "sphinx.ext.autodoc",
    "sphinx.ext.autosummary",
    "sphinx.ext.napoleon",
    "sphinx.ext.intersphinx",
    "sphinx.ext.mathjax",
    "autodocsumm",
    "myst_nb",
]

intersphinx_mapping = {
    "holoviews": ("https://holoviews.org/", None),
    "jax_moseq": ("https://jax-moseq.readthedocs.io/en/latest/", None),
    "sklearn": ("https://scikit-learn.org/stable/", None),
}

source_suffix = {".rst": "restructuredtext", ".ipynb": "myst-nb"}

autodoc_default_options = {
    "autosummary": True,
}

# Add any paths that contain templates here, relative to this directory.
templates_path = ["_templates"]

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
# This pattern also affects html_static_path and html_extra_path.
exclude_patterns = ["_build"]
html_static_path = ["_static"]

nb_execution_mode = "off"

# -- Options for HTML output -------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#
html_theme = "sphinx_rtd_theme"
html_show_sourcelink = True

html_context = {
    "display_github": True,  # Integrate GitHub
    "github_user": "dattalab",  # Username
    "github_repo": "keypoint-moseq",  # Repo name
    "github_version": "main",  # Version
    "conf_py_path": "/docs/source/",  # Path in the checkout to the docs root
}


autosummary_generate = True
autodoc_typehints = "description"
autodoc_member_order = "bysource"


--- File: docs/source/io.rst ---
Input/Output
============

.. automodule:: keypoint_moseq.io
   :members:

--- File: docs/source/fitting.rst ---
Model fitting
=============

.. automodule:: keypoint_moseq.fitting
   :members:

--- File: docs/source/calibration.rst ---
Error Calibration
=================

.. automodule:: keypoint_moseq.calibration
   :members:

--- File: docs/source/util.rst ---
Utilities
=========

.. automodule:: keypoint_moseq.util
   :members:



--- File: docs/source/advanced.rst ---
Exporting pose estimates
------------------------

During fitting, keypoint-MoSeq tries to estimate the "true" pose trajectory of the animal, discounting anomolous or low-confidence keypoints. The pose trajectory is stored in the model as a variable "x" that encodes a low-dimensional representation of the keypoints (similar to PCA). The code below shows how to project the pose trajectory back into the original coordinate space. This is useful for visualizing the estimated pose trajectory.

.. code-block:: python

    import os
    import h5py
    import numpy as np
    import jax.numpy as jnp
    from jax_moseq.utils import unbatch
    from jax_moseq.models.keypoint_slds import estimate_coordinates

    # load the model (change project_dir and model_name as needed)
    project_dir = 'demo_project'
    model_name = '2023_08_01-10_16_25'
    model, _, metadata, _ = kpms.load_checkpoint(project_dir, model_name)

    # compute the estimated coordinates
    Y_est = estimate_coordinates(
        jnp.array(model['states']['x']),
        jnp.array(model['states']['v']),
        jnp.array(model['states']['h']),
        jnp.array(model['params']['Cd'])
    )

    # generate a dictionary with reconstructed coordinates for each recording
    coordinates_est = unbatch(Y_est, *metadata)


The following code generates a video showing frames 0-3600 from one recording with the reconstructed keypoints overlaid.

.. code-block:: python

    config = lambda: kpms.load_config(project_dir)
    keypoint_data_path = 'dlc_project/videos' # can be a file, a directory, or a list of files
    coordinates, confidences, bodyparts = kpms.load_keypoints(keypoint_data_path, 'deeplabcut')

    recording_name = '21_11_8_one_mouse.top.irDLC_resnet50_moseq_exampleAug21shuffle1_500000'
    video_path = 'dlc_project/videos/21_11_8_one_mouse.top.ir.mp4'

    output_path = os.path.splitext(video_path)[0]+'.reconstructed_keypoints.mp4'
    start_frame, end_frame = 0, 3600

    kpms.overlay_keypoints_on_video(
        video_path,
        coordinates_est[recording_name],
        skeleton = config()['skeleton'],
        bodyparts = config()['use_bodyparts'],
        output_path = output_path,
        frames = range(start_frame, end_frame)
    )



Automatic kappa scan
--------------------

Keypoint-MoSeq includes a hyperparameter called ``kappa`` that determines the rate of transitions between syllables. Higher values of kappa lead to longer syllables and smaller values lead to shorter syllables. Users should choose a value of kappa based their desired distribution of syllable durations. The code below shows how to automatically scan over a range of kappa values and choose the optimal value.

.. note::

    The following code reduces ``kappa`` by a factor of 10 (``decrease_kappa_factor``) before fitting the full model. You will need to recapitulate this step when fitting your own final model.
    

.. code-block:: python

    import numpy as np

    kappas = np.logspace(3,7,5)
    decrease_kappa_factor = 10
    num_ar_iters = 50
    num_full_iters = 200

    prefix = 'my_kappa_scan'

    for kappa in kappas:
        print(f"Fitting model with kappa={kappa}")
        model_name = f'{prefix}-{kappa}'
        model = kpms.init_model(data, pca=pca, **config())
        
        # stage 1: fit the model with AR only
        model = kpms.update_hypparams(model, kappa=kappa)
        model = kpms.fit_model(
            model, 
            data, 
            metadata, 
            project_dir, 
            model_name, 
            ar_only=True, 
            num_iters=num_ar_iters, 
            save_every_n_iters=25
        )[0];

        # stage 2: fit the full model
        model = kpms.update_hypparams(model, kappa=kappa/decrease_kappa_factor)
        kpms.fit_model(
            model, 
            data, 
            metadata, 
            project_dir, 
            model_name, 
            ar_only=False, 
            start_iter=num_ar_iters,
            num_iters=num_full_iters, 
            save_every_n_iters=25
        );

    kpms.plot_kappa_scan(kappas, project_dir, prefix)


.. image:: _static/kappa_scan.jpg
   :align: center




Model selection and comparison
------------------------------

Keypoint-MoSeq uses a stochastic fitting procedure, and thus produces slightly different syllable segmentations when run multiple times with different random seeds. Below, we show how to fit multiple models, compare the resulting syllables, and then select an optimal model for further analysis. It may also be useful in some cases to show that downstream analyses are robust to the choice of model.


.. _fitting-multiple-models:

Fitting multiple models
~~~~~~~~~~~~~~~~~~~~~~~

The code below shows how to fit multiple models with different random seeds.

.. code-block:: python

    import jax

    num_model_fits = 20
    prefix = 'my_models'

    ar_only_kappa = 1e6
    num_ar_iters = 50

    full_model_kappa = 1e4
    num_full_iters = 500

    for restart in range(num_model_fits):
        print(f"Fitting model {restart}")
        model_name = f'{prefix}-{restart}'
        
        model = kpms.init_model(
            data, pca=pca, **config(), seed=jax.random.PRNGKey(restart)
        )

        # stage 1: fit the model with AR only
        model = kpms.update_hypparams(model, kappa=ar_only_kappa)
        model = kpms.fit_model(
            model,
            data, 
            metadata, 
            project_dir, 
            model_name,
            ar_only=True, 
            num_iters=num_ar_iters
        )[0]

        # stage 2: fit the full model
        model = kpms.update_hypparams(model, kappa=full_model_kappa)
        kpms.fit_model(
            model, 
            data, 
            metadata, 
            project_dir, 
            model_name,
            ar_only=False, 
            start_iter=num_ar_iters,
            num_iters=num_full_iters
        );

        kpms.reindex_syllables_in_checkpoint(project_dir, model_name);
        model, data, metadata, current_iter = kpms.load_checkpoint(project_dir, model_name)
        results = kpms.extract_results(model, metadata, project_dir, model_name)
        
        

Comparing syllables
~~~~~~~~~~~~~~~~~~~

To get a sense of the variability across model runs, it may be useful to compare syllables produced by each model. The code below shows how to load results from two models runs (e.g., produced by the code above) and plot a confusion matrix showing the overlap between syllable labels.

.. code-block:: python

    model_name_1 = 'my_models-0'
    model_name_2 = 'my_models-1'

    results_1 = kpms.load_results(project_dir, model_name_1)
    results_2 = kpms.load_results(project_dir, model_name_2)

    kpms.plot_confusion_matrix(results_1, results_2);


.. image:: _static/confusion_matrix.jpg


Selecting a model
~~~~~~~~~~~~~~~~~

We developed a matric called the expected marginal likelihood (EML) score that can be used to rank models. To calculate EML scores, you must first fit an ensemble of models to a given dataset, as shown in :ref:`Fitting multiple models <fitting-multiple-models>`. The code below loads this ensemble and then calculates the EML score for each model. The model with the highest EML score can then be selected for further analysis.

.. code-block:: python

    # change the following line as needed
    model_names = ['my_models-{}'.format(i) for i in range(20)]

    eml_scores, eml_std_errs = kpms.expected_marginal_likelihoods(project_dir, model_names)
    best_model = model_names[np.argmax(eml_scores)]
    print(f"Best model: {best_model_name}")

    kpms.plot_eml_scores(eml_scores, eml_std_errs, model_names)


.. image:: _static/EML_scores.jpg


Model averaging
~~~~~~~~~~~~~~~

Keypoint-MoSeq is probabilistic. So even once fitting is complete and the syllable parameters are fixed, there is still a distribution of possible syllable sequences given the observed data. In the default pipeline, one such sequence is sampled from this distribution and used for downstream analyses. Alternatively, one can estimate the marginal probability distribution over syllable labels at each timepoint. The code below shows how to do this. It can be applied to new data or the same data that was used for fitting (or a combination of the two).

.. code-block:: python

    burnin_iters = 200
    num_samples = 100
    steps_per_sample = 5

    # load the model (change `project_dir` and `model_name` as needed)
    model = kpms.load_checkpoint(project_dir, model_name)[0]

    # load data (e.g. from deeplabcut)
    data_path = 'path/to/data/' # can be a file, a directory, or a list of files
    coordinates, confidences, bodyparts = kpms.load_keypoints(data_path, 'deeplabcut')
    data, metadata = kpms.format_data(coordinates, confidences, **config())

    # compute the marginal probabilities of syllable labels
    marginal_probs = kpms.estimate_syllable_marginals(
        model, data, metadata, burnin_iters, num_samples, steps_per_sample, **config()
    )


Location-aware modeling
-----------------------

Because keypoint-MoSeq uses centered and aligned pose estimates to define syllables, it is effectively blind to absolute movements of the animal in space. The only thing that keypoint-MoSeq normally cares about is change in pose -- defined here as the relative location of each keypoint. For example, if an animal were capable of simply sliding forward without otherwise moving, this would fail to show up in the syllable segmentation. To address this gap, we developed an experimental version of keypoint-MoSeq that leverages location and heading dynamics (in addition to pose) when defining syllables. To use this "location-aware" model, simply pass ``location_aware=True`` as an additional argument when calling the following functions.

- :py:func:`keypoint_moseq.init_model`
- :py:func:`keypoint_moseq.fit_model`
- :py:func:`keypoint_moseq.apply_model`
- :py:func:`keypoint_moseq.estimate_syllable_marginals`

Note that the location-aware model was not tested in the keypoint-MoSeq paper remains experimental. We welcome feedback and suggestions for improvement.


Mathematical details
~~~~~~~~~~~~~~~~~~~~

In the published version of keypoint-MoSeq, the animal's location :math:`v_t` and heading :math:`h_t` at each timepoint are conditionally independent of the current syllable :math:`z_t`. In particular, we assume

.. math::
    v_{t+1} & \sim \mathcal{N}(v_t, \sigma^2_\text{loc} I_2) \\
    h_{t+1} & \sim \text{Uniform}(-\pi, \pi)


In the location-aware model, we relax this assumption and allow the animal's location and heading to depend on the current syllable. Specifically, each syllable is associated with a pair of normal distributions that specify the animal's expected rotation and translation at each timestep. This can be expressed formally as follows:

.. math::
    h_{t+1} = h_t + \Delta h_{z_t} + \epsilon_h,
    & \ \text{ where } \ 
    \epsilon_h \mid z_t \sim \mathcal{N}(0, \sigma^2_{h,z_t}) \\
    v_{t+1} = v_t + R(h_t)^\top \Delta v_{z_t} + \epsilon_v, 
    & \ \text{ where } \ 
    \epsilon_v \mid z_t \sim \mathcal{N}(0, \sigma^2_{v, z_t} I_2)

where :math:`R(h)` is a rotation matrix that rotates a vector by angle :math:`h`. The parameters :math:`\Delta h_i`, :math:`\Delta v_i`, :math:`\sigma^2_{h,i}`, and :math:`\sigma^2_{v,i}` for each syllable :math:`i` have a normal-inverse-gamma prior:

.. math::
    \sigma^2_{v,i} & \sim \text{InverseGamma}(\alpha_v, \beta_v), \ \ \ \  \Delta v_i \sim \mathcal{N}(0, \sigma^2_{v,i} I_2 / \lambda_v) \\
    \sigma^2_{h,i} & \sim \text{InverseGamma}(\alpha_h, \beta_h), \ \ \ \  \Delta h_i \sim \mathcal{N}(0, \sigma^2_{h,i} / \lambda_h)


Temporal downsampling
---------------------

Sometimes it's useful to downsample a dataset, e.g. if the original recording has a much higher framerate than is needed for modeling. To downsample, run the following lines right after loading the keypoints.

.. code-block:: python

    downsample_rate = 2 # keep every 2nd frame
    coordinates, video_frame_indexes = kpms.downsample_timepoints(
        coordinates, downsample_rate
    )
    confidences, video_frame_indexes = kpms.downsample_timepoints(
        confidences, downsample_rate
    ) # skip if `confidences=None`

After this, the pipeline can be run as usual, except for steps that involve reading the original videos, in which case ``video_frame_indexes`` should be passed as an additional argument.

.. code-block:: python

    # Calibration step
    kpms.noise_calibration(..., video_frame_indexes=video_frame_indexes)

    # Making grid movies
    kpms.generate_grid_movies(..., video_frame_indexes=video_frame_indexes)

    # Overlaying keypoints
    kpms.overlay_keypoints_on_video(..., video_frame_indexes=video_frame_indexes)


Trimming inputs
---------------

In some datasets, the animal is missing at the beginning and/or end of each video. In these cases, the easiest solution is to trim the videos before running keypoint detection. However, it's also possible to directly trim the inputs to keypoint-MoSeq. Let's assume that you already have a dictionary called ``bounds`` that has the same keys as ``coordinates`` and contains the desired start/end times for each recording. The next step would be to trim ``coordinates`` and ``confindences``

.. code-block:: python

    coordinates = {k: coords[bounds[k][0]:bounds[k][1]] for k,coords in coordinates.items()}
    confidences = {k: confs[bounds[k][0]:bounds[k][1]] for k,confs in confidences.items()}
 
    

You'll also need to generate a dictionary called ``video_frame_indexes`` that maps the timepoints of ``coordinates`` and ``confindences`` to frame indexes from the original videos.

.. code-block:: python

    import numpy as np
    video_frame_indexes = {k : np.arange(bounds[k][0], bounds[k][1]) for k in bounds}


After this, the pipeline can be run as usual, except for steps that involve reading the original videos, in which case ``video_frame_indexes`` should be passed as an additional argument.

.. code-block:: python

    # Calibration step
    kpms.noise_calibration(..., video_frame_indexes=video_frame_indexes)

    # Making grid movies
    kpms.generate_grid_movies(..., video_frame_indexes=video_frame_indexes)

    # Overlaying keypoints
    kpms.overlay_keypoints_on_video(..., video_frame_indexes=video_frame_indexes)





--- File: docs/source/_static/FAQs_style.css ---
h2 {
    font-size: 1.3em;
  }


